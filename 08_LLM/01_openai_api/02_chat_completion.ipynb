{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMEEE0TKKU8P9yOhokm9A7s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Chat Completion"],"metadata":{"id":"uAZUidrGdJl5"}},{"cell_type":"markdown","source":["### 환경 설정\n","- .env 파일"],"metadata":{"id":"LdtK2VrKdloJ"}},{"cell_type":"code","source":["# .env : only 내 로컬에서만. (공유대상이 아님)\n","# 환경파일 내에서 = 양옆에 공백 X (붙여서 작성)\n","# 민감 정보(API 키, 비밀번호 등)를 코드에 직접 쓰지 않고 분리\n","# 설정을 한 곳에 모아두고, 쉽게 수정 가능\n","# 개발/테스트/운영 환경에 따라 변수만 바꿔서 유연하게 실행 가능\n","# 깃헙에 안 올림 (보안 유지)\n","# Google Colab은 클라우드 환경이라, 노트북 코드에 API 키나 토큰을 바로 적으면 노출될 위험이 있어서 .env 파일을 따로 만들고, 안전하게 불러오는 식으로 사용"],"metadata":{"id":"C9XG-oZKe32Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38fPmVfic-L-","executionInfo":{"status":"ok","timestamp":1744771172422,"user_tz":-540,"elapsed":2517,"user":{"displayName":"JS B","userId":"14406863337187805558"}},"outputId":"7e41db8f-24a6-42d9-a15f-c7a0abb664f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-dotenv\n","  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Installing collected packages: python-dotenv\n","Successfully installed python-dotenv-1.1.0\n"]}],"source":["!pip install python-dotenv"]},{"cell_type":"code","source":["from dotenv import load_dotenv\n","\n","load_dotenv() # 시스템 환경변수로 일종의 등록을 한다고 보면 됨. True -> .env가 존재를 하고, 로드를 해서 시스템 환경변수로 등록했다는 것을 True가 뜨는 것으로 확인할 수 있다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5oExezBrfcM8","executionInfo":{"status":"ok","timestamp":1744772939064,"user_tz":-540,"elapsed":8,"user":{"displayName":"JS B","userId":"14406863337187805558"}},"outputId":"b2d98841-2344-4d9a-dbd1-221672abd01b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import os\n","\n","OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n"],"metadata":{"id":"b8-8SPc9jy5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chat Completion"],"metadata":{"id":"TK-iwEMYlDcS"}},{"cell_type":"code","source":["from openai import OpenAI\n","\n","client = OpenAI(api_key=OPENAI_API_KEY)\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[  # 배열형태인 이유는 이전에 대화가 있었던 것처럼 모델에 전달하기 위해서 (모델이 문맥을 이해하게 하기 위해서)\n","        {\"role\": \"system\", \"content\":\"당신은 친절하고 상세한 설명을 잘하는 챗봇입니다.\"},\n","        {\"role\": \"user\", \"content\":\"안녕하세요. 저는 토끼 선생님입니다.\"},\n","        {\"role\": \"assistant\", \"content\":\"안녕하세요. 토끼 선생님, 무엇을 도와드릴까요?\"},\n","        {\"role\": \"user\", \"content\": \"제 이름이 뭐라구요?\"}\n","    ],\n","    temperature=1,\n","    max_tokens=4096,\n","    top_p=1\n",")\n","\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcI9dHvClGCU","executionInfo":{"status":"ok","timestamp":1744773730214,"user_tz":-540,"elapsed":2455,"user":{"displayName":"JS B","userId":"14406863337187805558"}},"outputId":"fa7c7b0d-7ad4-4c15-d49e-8d5e6336df7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["토끼 선생님이라고 말씀하셨습니다! 맞나요? 다른 이름이 있으신가요?\n"]}]},{"cell_type":"markdown","source":["### stream 처리"],"metadata":{"id":"_oCxXanbn3kM"}},{"cell_type":"code","source":["client = OpenAI() # 응? api-key가 없네? -> 넣지 않으면 환경변수(.env를 만들고 인스톨, 임포트 했기 때문에)에서 우리가 가져왔던 api-key변수를 자동으로 찾아서 넣어주기 때문에 문제가 생기지 않는다.\n","\n","stream_response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[\n","        {\"role\": \"user\", \"content\": \"stream 테스트를 할건데, 아주 긴 응답 메세지를 보내주세요.\"}  # 왜 user밖에 없지?\n","    ],\n","    stream=True # 만들어지는 과정을 chatgpt가 응답해줄때처럼 생성해나가는대로 출력하는것 (청크 단위로 끊어서 가져옴)\n",")\n","\n","for chunk in stream_response:\n","  if chunk.choices[0].delta.content is not None:  # delta.content : streaming된 조각을 뜻한다\n","    print(chunk.choices[0].delta.content, end='') # 청크, 조각단위로 출력하기 때문에 end='' 지정안해주면 개행없이 이어져서 나오게된다.\n","\n","print('👌응답 완료👌')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MXovtXscn9PD","executionInfo":{"status":"ok","timestamp":1744774246133,"user_tz":-540,"elapsed":10992,"user":{"displayName":"JS B","userId":"14406863337187805558"}},"outputId":"c8da509a-c1f9-4d15-f7d5-5e9a92f0c64c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["물론입니다! 아래에 긴 응답 메시지를 작성해 보겠습니다. 특정 주제나 내용을 원하신다면 말씀해 주시면 그에 맞춰 조정할 수 있습니다. 여기서는 일반적인 정보 주제로 긴 메시지를 작성해 보겠습니다.\n","\n","---\n","\n","### 인공지능(AI)의 발전과 미래\n","\n","인공지능(AI)은 최근 몇 년 간 눈부신 발전을 이루어 왔습니다. 1950년대 처음 개념이 등장한 이후, AI는 여러 분야에서 혁신적인 변화를 이끌고 있습니다. 초기 AI 연구는 주로 기초적인 알고리즘과 규칙 기반 시스템에 초점을 맞추었으나, 현재는 머신러닝과 딥러닝 기술의 발전에 힘입어 더욱 정교하고 강력한 시스템으로 진화했습니다.\n","\n","#### 1. AI의 역사\n","\n","인공지능의 역사는 크게 몇 가지 단계로 나눌 수 있습니다. 첫 번째 단계는 1950년대와 1960년대 초반으로, 이 시기에는 기본적인 문제 해결 기법과 기계 학습의 원초적인 형태가 개발되었습니다. 그 후 1970년대와 1980년대에는 전문가 시스템이 등장하며 특정 분야에서의 문제 해결에 활용되기 시작했습니다. 1990년대에는 AI 연구가 한동안 침체기를 겪었지만, 2000년대 들어서는 데이터와 컴퓨팅 파워의 비약적인 발전 덕분에 다시 빠르게 성장하게 됩니다.\n","\n","#### 2. 현재의 AI 기술\n","\n","현재의 AI는 주로 머신러닝, 딥러닝, 자연어 처리(NLP), 컴퓨터 비전 등 다양한 범주로 나눌 수 있습니다. 머신러닝은 데이터를 통해 스스로 학습하고 예측할 수 있는 모델을 만드는 기술입니다. 그중 딥러닝은 인공신경망을 활용해 보다 복잡한 패턴을 인식하는 데 중점을 두고 있습니다. 자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하도록 돕는 기술로, 번역기, 챗봇, 음성 인식 시스템 등 다양한 애플리케이션에 활용됩니다. 컴퓨터 비전은 이미지와 비디오에서 의미 있는 정보를 추출하는 기술로, 자율주행차, 의료 영상 분석 등에서 중요한 역할을 하고 있습니다.\n","\n","#### 3. AI의 응용 분야\n","\n","AI의 활용 분야는 무궁무진하며, 매일 새롭고 혁신적인 방법으로 다양한 산업에 적용되고 있습니다. 예를 들어, 의료 분야에서는 AI를 활용한 진단 시스템이 개발되어, 환자의 데이터를 분석하고 정확한 진단을 도출해내는 데 도움을 주고 있습니다. 금융에서는 AI가 시장 예측, 투자 전략 수립, 사기 탐지 등에 활용되고 있으며, 이를 통해 효율성과 정확성을 높이고 있습니다. 제조업에서는 스마트 팩토리 구축을 통해 생산 공정의 최적화와 효율성을 극대화하고 있습니다.\n","\n","#### 4. AI의 윤리적 이슈\n","\n","AI의 발전이 가져오는 이점만큼이나 윤리적 문제도 함께 제기되고 있습니다. 특히, 프라이버시 문제, 편향된 데이터로 인한 차별, 그리고 AI 결정 과정의 투명성 부족 문제가 논의되고 있습니다. AI 시스템이 잘못된 결정을 내리거나 특정 그룹에 대한 차별적인 결과를 초래할 수 있는 가능성은 심각한 문제로, 이를 해결하기 위한 정책과 기술적 노력이 필요합니다. 여러 연구자들과 기업들이 이러한 문제를 해결하기 위해 AI의 윤리를 연구하고 있으며, 다양한 가이드라인이 제정되고 있습니다.\n","\n","#### 5. 미래의 AI\n","\n","앞으로의 AI는 더욱 발전하고, 우리 생활의 많은 부분에 깊숙이 통합될 것으로 예상됩니다. 자율주행차, 스마트 홈, 개인 비서 AI 등이 이미 상용화되고 있으며, 미래에는 이러한 기술들이 더욱 진화하여 우리의 생활 방식을 근본적으로 변화시킬 것입니다. 그러나 이러한 발전과 함께 기술의 안전성과 윤리적 기준 강화를 위한 노력이 따라야 할 것이며, 모든 이해관계자들이 함께 협력하여 안전하고 포용적인 AI 생태계를 구축해 나가야 합니다.\n","\n","결론적으로, AI는 우리 사회에 많은 기회를 제공하고 있지만, 동시에 많은 책임도 부여하고 있습니다. 따라서 기술의 발전과 함께 윤리적, 사회적 문제에 대한 지속적인 논의와 대처가 필요하다고 할 수 있습니다.\n","\n","---\n","\n","이 메시지가 도움이 되었으면 좋겠습니다! 필요하시면 더 긴 내용이나 다른 주제를 요청해 주세요.👌응답 완료👌\n"]}]},{"cell_type":"markdown","source":["### Token Counting\n","\n","- 한번의 프롬프트 입출력 토큰과 서비스 호출 빈도를 고려해 서비스 제공 비용을 산정할 수 있음"],"metadata":{"id":"Mr9aTnoNrOHa"}},{"cell_type":"code","source":["!pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Sh2F6QArRBP","executionInfo":{"status":"ok","timestamp":1744774781358,"user_tz":-540,"elapsed":2774,"user":{"displayName":"JS B","userId":"14406863337187805558"}},"outputId":"f0e4a7b0-88c4-4d34-bc9c-cb7b76ef1827"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tiktoken\n","  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n","Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken\n","Successfully installed tiktoken-0.9.0\n"]}]},{"cell_type":"code","source":["import tiktoken\n","\n","gpt35_tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n","gpt4o_tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")\n","\n","text=\"\"\"\n","KT가 태국 ‘자스민(Jasmine)’ 그룹의 IT 전문 기업 ‘자스민 테크놀로지 솔루션(Jasmine Technology Solutions, 이하 JTS)’과 추진한 태국어 대형언어모델(LLM) 플랫폼 구축 프로젝트를 성공적으로 마무리했다고 15일 밝혔다.\n","\n","KT는 자체 모델 개발 경험과 노하우를 토대로 국내 LLM 전문 기업 업스테이지(대표 김성훈)와 태국어 전용 LLM을 공동 개발했다. 이 모델은 태국어, 영어, 한국어 등을 지원한다. 태국의 방대한 고유 데이터를 학습해 태국 정치, 역사, 문화 관련 질문에도 정확하게 응대할 수 있다.\n","\n","KT는 지난해 3월 JTS와 태국어 LLM 플랫폼 개발 프로젝트를 위한 계약을 체결하고 1년여간 프로젝트를 수행해왔다. 이 프로젝트는 LLM 운영 관리 환경 ‘LLM 옵스(Ops)’와 AI 서비스 인프라 ‘GPU 팜(Farm)’을 구축하고 ‘태국어 전용 ‘LLM 모델’까지 개발하는 원스톱 프로젝트다. 해외에 종합 AI 인프라를 구축해 생성형 AI 서비스의 개발과 운영, 확장 환경을 마련한 것은 국내 기업 중 KT 그룹이 처음이다.\n","\n","LLM 옵스는 다양한 LLM 모델의 학습·배포·운영 전 과정을 관리할 수 있는 환경이다. KT는 이를 고객사 맞춤형으로 구축해 JTS는 복잡한 생성형 AI 운영 환경을 보다 효율적, 안정적으로 운용할 수 있게 됐다.\n","\n","더불어 KT는 클라우드 자회사 KT Cloud와 함께 GPU 자원 관리를 위한 GPU 팜도 태국 현지에 조성했다. 여기에 기반해 JTS는 태국 기업과 기관에 GPU 구독 서비스(GPU as a Service, GPUaaS)를 공급하고 본격적으로 태국 내 AI 생태계 확장을 촉진할 계획이다.\n","\n","한편, KT는 대한민국 AX 생태계 발전을 위해 지난 2023년 업스테이지에 투자했다. 이번 프로젝트는 대기업과 스타트업이 공동으로 글로벌 AX 사업을 성공한 사례로서 의미를 더했다.\n","\n","KT는 앞으로도 JTS의 전문 기술 파트너로서 AI 플랫폼 고도화, GPU 인프라 확장 및 유지 보수, AI 기반 신규 서비스 발굴 등 다분야에서 지속적인 협력을 이어 나간다. 또한 양 사는 태국 AX 시장을 겨냥한 AI 서비스를 단계적으로 선보일 계획이다..\n","\n","KT는 이번 프로젝트로 성공적인 글로벌 AX 사업 레퍼런스를 확보했다. 이를 통해 한층 고도화된 AI 사업 역량을 확보하고 동남아 시장뿐만 아니라 중동, 유럽 등 다른 글로벌 시장까지 AX 사업 영역을 본격적으로 확대해 나갈 방침이다.\n","\n","KT 전략·사업컨설팅부문 AI사업전략담당 이진형 상무는 “태국어 특화 LLM 플랫폼 개발과 상용화는 KT의 AI 기술력과 글로벌 사업 역량을 다시 한번 입증한 성과”라며 “이번 프로젝트에서 얻은 경험과 노하우를 포함해 KT는 마이크로소프트, 팔란티어와의 전략적 제휴를 기반으로 AI, 클라우드의 서비스형 상품 라인업도 다각화해 나갈 계획이다”라고 밝혔다.\n","\n","\"\"\"\n","# gpt35_tokenizer.encode(text) : 인덱스로 반환해줌\n","print(len(gpt35_tokenizer.encode(text)))\n","print(len(gpt4o_tokenizer.encode(text)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ppn4bF8wrnBf","executionInfo":{"status":"ok","timestamp":1744775168163,"user_tz":-540,"elapsed":2409,"user":{"displayName":"JS B","userId":"14406863337187805558"}},"outputId":"1024ff06-a071-461a-b75b-2ae51a3ea4ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1286\n","731\n"]}]}]}