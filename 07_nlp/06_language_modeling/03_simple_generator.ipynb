{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17707809",
   "metadata": {},
   "source": [
    "# ngram 기반의 간단한 텍스트 생성기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0985896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_bigram(seed, unigram_freq, bigram_freq, max_len=10):  # 빈도수를 인자로 넣어줄 함수\n",
    "    current_word = seed\n",
    "    generated = [current_word]\n",
    "\n",
    "    for _ in range(max_len - 1):    # max_len에서 이미 current_word 하나가 들어가있기 때문에 -1 \n",
    "        candidates = [(bigram, freq) for bigram, freq in bigram_freq.items() if bigram[0] == current_word]  # 현시점에 bigram의 0번째 인덱스와 같은 것에 대해 후보군을 셋팅\n",
    "        if not candidates:  # 내가 학습한 내용이 그 문맥에 없을 경우\n",
    "            break           # 반복문을 탈출 -> 더이상 생성하지 않고 멈춤\n",
    "        words, freqs = zip(*[(bigram[1], freq) for bigram, freq in candidates]) # 다음에 이어질 단어, 빈도수를 받아 시퀀스로.\n",
    "        total = sum(freqs)  # 빈도수 총합\n",
    "        probs = [f / total for f in freqs]  # 각각의 확률에 대한 것을 probs에 저장\n",
    "\n",
    "        next_word = random.choices(words, weights=probs)[0]  # 그 확률을 가중치로 줌 / choices로 나온 여러개의 words중 0번째 것을 next_word로 지정.\n",
    "        generated.append(next_word)     # 그 것을 generated에 append\n",
    "        current_word = next_word        # append해준 것이 새로운 seed ( current_word )\n",
    "    \n",
    "    return \" \".join(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1409cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = \"자연어 처리는 재미있다. 자연어 처리는 어렵지만 도전하고 싶다. 오늘은 날씨가 좋다.\"\n",
    "\n",
    "# 단어 토큰화\n",
    "train_tokens =  nltk.word_tokenize(train_text)\n",
    "\n",
    "# 유니그램\n",
    "unigrams = train_tokens\n",
    "\n",
    "# 바이그램(리스트로 변환)\n",
    "bigrams = list(ngrams(train_tokens, 2))\n",
    "\n",
    "# 카운터로 빈도수 카운트(유니그램)\n",
    "unigram_freq = Counter(unigrams)\n",
    "\n",
    "# 카운터로 빈도수 카운트(바이그램)\n",
    "bigram_freq = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51775aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'자연어 처리는 어렵지만 도전하고 싶다'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text_bigram(\"자연어\", unigram_freq, bigram_freq, max_len=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
