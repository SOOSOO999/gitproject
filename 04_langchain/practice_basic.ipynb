{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327b9bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í™˜ê²½ì„¤ì •\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86453ff0",
   "metadata": {},
   "source": [
    "### Chainì„ ì´ìš©í•œ Simple LLM\n",
    "1. PromptTemplate\n",
    "2. LLM\n",
    "3. OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb629f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PromptTemplate\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    ('system', 'ë„ˆëŠ” ì• ë‹ˆë©”ì´ì…˜ì„ ì˜ ì•„ëŠ” ì±—ë´‡ì´ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•  ìˆ˜ ìˆì–´.'), \n",
    "    ('user', '{question}')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa6476a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Model\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name='gpt-4o-mini',\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff56fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. OutputParser (StrOutputParser)\n",
    "from langchain_core.output_parsers import StrOutputParser   # ì¶œë ¥ìœ¼ë¡œ ì˜¤ëŠ” ê²ƒì„ ë¬¸ìì—´ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” íŒŒì„œ \n",
    "\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca91760e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'í¬ì¼“ëª¬ì˜ ê°•í•¨ì€ ì—¬ëŸ¬ ìš”ì†Œì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œëŠ” ì „íˆ¬ ëŠ¥ë ¥, íƒ€ì… ìƒì„±, ê¸°ìˆ  ì¡°í•©, ê·¸ë¦¬ê³  ì „ëµì ì¸ ì‚¬ìš© ë“±ì´ ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. \\n\\ní˜„ì¬ê¹Œì§€ì˜ í¬ì¼“ëª¬ ê²Œì„ì—ì„œ ê°€ì¥ ê°•ë ¥í•˜ë‹¤ê³  í‰ê°€ë°›ëŠ” í¬ì¼“ëª¬ ì¤‘ í•˜ë‚˜ëŠ” **ì•„ë¥´ì„¸ìš°ìŠ¤**ì…ë‹ˆë‹¤. ì•„ë¥´ì„¸ìš°ìŠ¤ëŠ” \"ì‹ ì˜ í¬ì¼“ëª¬\"ìœ¼ë¡œ ë¶ˆë¦¬ë©°, ëª¨ë“  íƒ€ì…ìœ¼ë¡œ ë³€ì‹ í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ìœ ë¦¬í•œ ì „íˆ¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\në˜í•œ, **ë©”ê°€ ë ˆì¿ ì**ë‚˜ **í”„ë¦¬ì¦˜ ë ˆì¿ ì**ì™€ ê°™ì€ ë©”ê°€ ì§„í™” í¬ì¼“ëª¬ë“¤ë„ ë§¤ìš° ê°•ë ¥í•œ ì„±ëŠ¥ì„ ìë‘í•©ë‹ˆë‹¤. ì´ë“¤ì€ ë†’ì€ ìŠ¤íƒ¯ê³¼ ê°•ë ¥í•œ ê¸°ìˆ ì„ ê°€ì§€ê³  ìˆì–´ ë§ì€ íŠ¸ë ˆì´ë„ˆë“¤ì—ê²Œ ì‚¬ë‘ë°›ê³  ìˆìŠµë‹ˆë‹¤.\\n\\nê²°êµ­, ì–´ë–¤ í¬ì¼“ëª¬ì´ ê°€ì¥ ê°•í•œì§€ëŠ” ì‚¬ìš©ìì˜ ì „ëµê³¼ íŒ€ êµ¬ì„±ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ, ìì‹ ë§Œì˜ ì¡°í•©ì„ ì°¾ì•„ë³´ëŠ” ê²ƒë„ ì¬ë¯¸ìˆì„ ê²ƒì…ë‹ˆë‹¤!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Chain -> ì§ˆì˜\n",
    "# question: ì–´ë–¤ í¬ì¼“ëª¬ì´ ê°€ì¥ ê°•í•´?\n",
    "\n",
    "chain = prompt_template | model | output_parser\n",
    "\n",
    "chain.invoke({'question': 'ì–´ë–¤ í¬ì¼“ëª¬ì´ ê°€ì¥ ê°•í•´?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82d9d5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'í¬ì¼“ëª¬ì˜ ê°•í•¨ì€ ì—¬ëŸ¬ ìš”ì†Œì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œëŠ” ì „íˆ¬ ëŠ¥ë ¥, íƒ€ì… ìƒì„±, ê¸°ìˆ  ì¡°í•©, ê·¸ë¦¬ê³  ì „ëµì ì¸ ì‚¬ìš© ë“±ì´ ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. \\n\\ní˜„ì¬ê¹Œì§€ì˜ í¬ì¼“ëª¬ ê²Œì„ì—ì„œ ê°€ì¥ ê°•ë ¥í•˜ë‹¤ê³  í‰ê°€ë°›ëŠ” í¬ì¼“ëª¬ ì¤‘ í•˜ë‚˜ëŠ” **ì•„ë¥´ì„¸ìš°ìŠ¤**ì…ë‹ˆë‹¤. ì•„ë¥´ì„¸ìš°ìŠ¤ëŠ” \"í¬ì¼“ëª¬ì˜ ì‹ \"ìœ¼ë¡œ ë¶ˆë¦¬ë©°, ëª¨ë“  íƒ€ì…ìœ¼ë¡œ ë³€ì‹ í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ìœ ë¦¬í•œ ì „íˆ¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\në˜í•œ, **ë©”ê°€ ë ˆì¿ ì**ë‚˜ **í”„ë¦¬ì¦˜ ë ˆì¿ ì**ì™€ ê°™ì€ ë©”ê°€ ì§„í™” í¬ì¼“ëª¬ë“¤ë„ ë§¤ìš° ê°•ë ¥í•œ ì„±ëŠ¥ì„ ìë‘í•©ë‹ˆë‹¤. ì´ë“¤ì€ ë†’ì€ ìŠ¤íƒ¯ê³¼ ê°•ë ¥í•œ ê¸°ìˆ ì„ ê°€ì§€ê³  ìˆì–´ ì „íˆ¬ì—ì„œ í° ìœ„ë ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\ní•˜ì§€ë§Œ, í¬ì¼“ëª¬ì˜ ê°•í•¨ì€ ê°œì¸ì˜ ì „ëµê³¼ íŒ€ êµ¬ì„±ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìì‹ ì—ê²Œ ë§ëŠ” í¬ì¼“ëª¬ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì–´ë–¤ í¬ì¼“ëª¬ì„ ì‚¬ìš©í•˜ëŠëƒì— ë”°ë¼ ì „íˆ¬ì˜ ê²°ê³¼ê°€ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "chain = RunnableSequence(prompt_template, model, output_parser)\n",
    "chain.invoke({'question': 'ì–´ë–¤ í¬ì¼“ëª¬ì´ ê°€ì¥ ê°•í•´?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c62669c",
   "metadata": {},
   "source": [
    "### ë‹¨ê³„ë³„ Chatbot\n",
    "- ì²« ëŒ€í™”ì—ì„œ ë‚´ ì´ë¦„ì„ ì•Œë ¤ì£¼ê³ , ë‹¤ìŒ ëŒ€í™”ì—ì„œ ë‚´ ì´ë¦„ ê¸°ì–µí•˜ëŠ”ì§€ ë¬¼ì–´ë³´ê¸°!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b397ff",
   "metadata": {},
   "source": [
    "1. ê·¸ëƒ¥ Chat\n",
    "- langchain_openaiì˜ ChatOpenAI\n",
    "- langchain_core.messagesì˜ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ca2e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=0.5\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83264adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì•ˆë…•í•˜ì„¸ìš”, ì•„ë¬´ê°œë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage('ì•ˆë…•! ë‚´ ì´ë¦„ì€ ì•„ë¬´ê°œì•¼')\n",
    "]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68683a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì£„ì†¡í•˜ì§€ë§Œ, ë‹¹ì‹ ì˜ ì´ë¦„ì„ ì•Œ ìˆ˜ ìˆëŠ” ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê·¸ì— ë§ì¶° ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([\n",
    "    HumanMessage('ë‚´ ì´ë¦„ì´ ë­ì•¼?')\n",
    "]).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae288a8",
   "metadata": {},
   "source": [
    "2. ì§ì ‘ ëŒ€í™” ë§¥ë½ ìœ ì§€\n",
    "- langchain_openaiì˜ ChatOpenAI\n",
    "- langchain_core.messagesì˜ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cfae079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•, í† ë¼ì•¼! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ! ì–´ë–»ê²Œ ì§€ë‚´ê³  ìˆì–´?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model2 = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "\n",
    "first_response = model2.invoke([\n",
    "    HumanMessage('ì•ˆë…•! ë‚´ ì´ë¦„ì€ í† ë¼ì•¼!')\n",
    "]).content\n",
    "print(first_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f75fca70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë„ˆì˜ ì´ë¦„ì€ í† ë¼ì•¼! ë§ì§€?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.invoke([\n",
    "    HumanMessage('ì•ˆë…•! ë‚´ ì´ë¦„ì€ í† ë¼ì•¼!'),\n",
    "    AIMessage(first_response),\n",
    "    HumanMessage('ë‚´ ì´ë¦„ì´ ë­ë¼ê³  í–ˆì§€?')\n",
    "]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bac401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# messages = [\n",
    "#     SystemMessage(content=\"ë„ˆëŠ” ì¹œì ˆí•œ AI ë¹„ì„œì•¼.\"),\n",
    "#     HumanMessage(content=\"ë‚´ ì´ë¦„ì€ ì² ìˆ˜ì•¼.\"),\n",
    "# ]\n",
    "\n",
    "# # ì²« ì‘ë‹µ\n",
    "# response = chat.invoke(messages)\n",
    "# print(\"AI:\", response.content)\n",
    "\n",
    "# # ğŸŸ¡ ì‘ë‹µì„ ë‹¤ì‹œ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€í•´ì•¼ ë§¥ë½ ìœ ì§€ë¨!\n",
    "# messages.append(AIMessage(content=response.content))\n",
    "\n",
    "# # ë‹¤ìŒ ì§ˆë¬¸ ì¶”ê°€\n",
    "# messages.append(HumanMessage(content=\"ë‚´ ì´ë¦„ì´ ë­ì•¼?\"))\n",
    "\n",
    "# # ë‹¤ìŒ ì‘ë‹µ\n",
    "# response2 = chat.invoke(messages)\n",
    "# print(\"AI:\", response2.content)\n",
    "\n",
    "# for msg in response:\n",
    "#     print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84cb4016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„ˆëŠ” AIì•¼.\n",
      "ì•ˆë…•! ë‚´ ì´ë¦„ì€ ì•„ë¬´ê°œì•¼\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ì€ ë§‘ê³  ë”°ëœ»í•œ ë‚ ì”¨ì˜ˆìš”.\n",
      "ì•„ë‹Œë°? ì§€ê¸ˆ ë¹„ ì˜¤ê³  ìˆì–´.\n",
      "ì•„, ê·¸ë ‡êµ°ìš”! ë¹„ ì˜¤ëŠ” ë‚ ì€ ë¶„ìœ„ê¸°ê°€ ë‹¤ë¥´ì£ . ë¹„ì†Œë¦¬ ë“£ëŠ” ê²ƒë„ ì¢‹ê³ , ë”°ëœ»í•œ ìŒë£Œ í•œ ì”ê³¼ í•¨ê»˜ ì±…ì„ ì½ê¸°ì—ë„ ì¢‹ì€ ì‹œê°„ì´ì£ . ì˜¤ëŠ˜ì€ ì–´ë–¤ ê³„íšì´ ìˆìœ¼ì‹ ê°€ìš”?\n",
      "ë‚´ ì´ë¦„ì´ ë­ì•¼?\n"
     ]
    }
   ],
   "source": [
    "# for msg in response:\n",
    "#     print(msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be44b1d",
   "metadata": {},
   "source": [
    "3. Memoryë¡œ ëŒ€í™”ì˜ ë§¥ë½ ìœ ì§€\n",
    "- langchain_openaiì˜ ChatOpenAI\n",
    "- langchain_core.messagesì˜ í´ë˜ìŠ¤\n",
    "- langchain_core.runnablesì˜ í´ë˜ìŠ¤\n",
    "- langchain_core.promptsì˜ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bded68e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "# ì¶”ìƒí™” : ê³µí†µì ì¸ ë¬´ì–¸ê°€ë¥¼ ë„ì§‘ì–´ë‚¸ë‹¤ (??????) \n",
    "class InMemoryHistory(BaseChatMessageHistory):\n",
    "    def __init__(self):\n",
    "        self.messages = []  # ì¸ìŠ¤í„´ìŠ¤ ì†ì„±ìœ¼ë¡œ\n",
    "\n",
    "    def add_messages(self, messages):   # ë©”ì‹œì§€ ì¶”ê°€\n",
    "        self.messages.extend(messages)\n",
    "\n",
    "    def clear(self):                    # ë©”ì‹œì§€ ì´ˆê¸°í™”\n",
    "        self.messages = []\n",
    "\n",
    "    def __repr__(self): # \n",
    "        return str(self.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b4b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}  # item(key=session_id, value=InMemoryHistory_ì¸ìŠ¤í„´ìŠ¤)\n",
    "\n",
    "def get_by_session_id(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fd5498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory # ì´ì „ ëŒ€í™” ê¸°ë¡ì„ í™œìš©í• ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” Wrapper í´ë˜ìŠ¤. (ê»ë°ê¸° í´ë˜ìŠ¤)\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    SystemMessage('ë‹¹ì‹ ì€ ëª¹ì‹œ ì¹œì ˆí•˜ê³  ìƒëƒ¥í•˜ê³  ì¹œê·¼í•œ ì±—ë´‡ì…ë‹ˆë‹¤.'),\n",
    "    MessagesPlaceholder('history'),\n",
    "    HumanMessage('{query}')\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o-mini', temperature=0.5)\n",
    "chain = prompt | model\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_by_session_id,\n",
    "    input_messages_key='query',\n",
    "    history_messages_key='history'  # ì´ì „ ëŒ€í™”ë‚´ìš©ì„ ë¬´ìŠ¨ ì´ë¦„ìœ¼ë¡œ ì „ë‹¬í• ê±´ì§€\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8491a484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•„, ì œê°€ ì˜ëª» ì´í•´í–ˆë„¤ìš”! `{query}`ëŠ” íŠ¹ì •í•œ ì˜ë¯¸ê°€ ì—†ëŠ” ê²ƒ ê°™ì•„ìš”. í˜¹ì‹œ ë‹¤ë¥¸ ì§ˆë¬¸ì´ë‚˜ ì´ì•¼ê¸°í•˜ê³  ì‹¶ì€ ê²Œ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”! ì–¸ì œë“ ì§€ ë„ì™€ë“œë¦´ ì¤€ë¹„ê°€ ë˜ì–´ ìˆì–´ìš”!\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_history.invoke(\n",
    "    {'query': 'ì•ˆë…•! ë‚´ ì´ë¦„ì€ ì•„ë¬´ê°œì•¼!'},\n",
    "    config={'configurable': {'session_id': 'me'}}\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20b5d8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì£„ì†¡í•´ìš”, ì œê°€ ì˜ëª» ì´í•´í–ˆë„¤ìš”! ë‹¹ì‹ ì˜ ì´ë¦„ì€ \"ì•„ë¬´ê°œ\"ë¼ê³  í•˜ì…¨ì£ ? ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ë‹¤ë¥¸ ì§ˆë¬¸ì´ë‚˜ ì´ì•¼ê¸°í•˜ê³  ì‹¶ì€ ê²ƒì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_history.invoke(\n",
    "    {'query': 'ë‚´ ì´ë¦„ì´ ë­ë¼ê³  í–ˆì§€? ë‚´ ì´ë¦„ì„ ë§í•´ë´'},\n",
    "    config={'configurable': {'session_id': 'me'}}\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27aab6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â­: ì•ˆë…•! ë‚´ ì´ë¦„ì€ ì•„ë¬´ê°œì•¼!\n",
      "ğŸ¤–: ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ê¶ê¸ˆí•œ ì ì´ë‚˜ í•„ìš”í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "â­: ë‚´ ì´ë¦„ì´ ë­ì•¼?\n",
      "ğŸ¤–: ì£„ì†¡í•˜ì§€ë§Œ, `{query}`ê°€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ì˜ ëª¨ë¥´ê² ì–´ìš”. ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œë©´ ë„ì™€ë“œë¦¬ê¸° ë” ì‰¬ìš¸ ê²ƒ ê°™ì•„ìš”! ì–´ë–¤ ì •ë³´ë¥¼ ì°¾ê³  ê³„ì‹ ê°€ìš”?\n",
      "â­: ë‚´ ì´ë¦„ì´ ë­ë¼ê³  í–ˆì§€? ë‚´ ì´ë¦„ì„ ë§í•´ë´\n",
      "ğŸ¤–: ì•„, ì£„ì†¡í•´ìš”! `{query}`ëŠ” ì œê°€ ì´í•´í•  ìˆ˜ ì—†ëŠ” ë¶€ë¶„ì´ì—ˆì–´ìš”. ë‹¹ì‹ ì˜ ì´ë¦„ì€ \"ì•„ë¬´ê°œ\"ë¼ê³  í•˜ì…¨ì£ ? ê·¸ëŸ¼ ì•„ë¬´ê°œë‹˜ê³¼ ì´ì•¼ê¸° ë‚˜ëˆ„ëŠ” ê²Œ ì •ë§ ì¦ê±°ì›Œìš”! ê¶ê¸ˆí•œ ì ì´ë‚˜ ì´ì•¼ê¸°í•˜ê³  ì‹¶ì€ ì£¼ì œê°€ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# ì±„íŒ…ë‚´ì—­ ë½‘ì•„ë³´ê¸°\n",
    "for message in store['me'].messages:\n",
    "    if isinstance(message, HumanMessage):\n",
    "        print(f'â­: {message.content}')\n",
    "    elif isinstance(message, AIMessage):\n",
    "        print(f'ğŸ¤–: {message.content}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
