{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d342ed",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96950394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bea0bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "# 추상화 : 공통적인 무언가를 끄집어낸다 (??????) \n",
    "class InMemoryHistory(BaseChatMessageHistory):\n",
    "    def __init__(self):\n",
    "        self.messages = []  # 인스턴스 속성으로\n",
    "\n",
    "    def add_messages(self, messages):   # 메시지 추가\n",
    "        self.messages.extend(messages)\n",
    "\n",
    "    def clear(self):                    # 메시지 초기화\n",
    "        self.messages = []\n",
    "\n",
    "    def __repr__(self): # \n",
    "        return str(self.messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c490a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}  # item(key=session_id, value=InMemoryHistory_인스턴스)\n",
    "\n",
    "def get_by_session_id(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "    return store[session_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3eaabd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'good morning', 'how are you?', 'I am fine', 'Thank you']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_test = get_by_session_id('test')\n",
    "history_test.add_messages(['hello', 'good morning', 'how are you?'])\n",
    "history_test.add_messages(['I am fine', 'Thank you'])\n",
    "\n",
    "history_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d3116bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory # 이전 대화 기록을 활용할수 있게 해주는 Wrapper 클래스. (껍데기 클래스)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '너는 {skill}을 잘 하는 AI 어시스턴트야.'),\n",
    "    MessagesPlaceholder(variable_name='history'),   # 이전 대화를 저장할 수 있는 공간을 확보해 놓았다 라고 보면 된다.\n",
    "    ('human', '{query}')\n",
    "])\n",
    "model = ChatOpenAI(model='gpt-4o-mini', temperature=0.5)\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0aaa7955",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_by_session_id,\n",
    "    input_messages_key='query',\n",
    "    history_messages_key='history'  # 이전 대화내용을 무슨 이름으로 전달할건지\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edf87b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='토끼가 농장에서 나무를 세 그루 키우고 있다니 귀엽고 재미있는 상황이네요! 어떤 종류의 나무를 키우고 있는지 궁금합니다. 혹시 토끼가 나무를 키우는 이유나 특별한 이야기가 있나요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 42, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BOgzSEt66PNpSacZ2MjfHMCflY8LQ', 'finish_reason': 'stop', 'logprobs': None} id='run-cd849389-6411-4b92-9d1a-8cb2d1ad5403-0' usage_metadata={'input_tokens': 42, 'output_tokens': 62, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_history.invoke(\n",
    "    {'skill': '대화', 'query': '토끼는 농장에서 나무를 세 그루 키우고 있습니다.'},\n",
    "    config={'configurable': {'session_id': 'rabbit'}}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be5cc294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': ['hello', 'good morning', 'how are you?', 'I am fine', 'Thank you'],\n",
       " 'rabbit': [HumanMessage(content='토끼는 농장에서 나무를 세 그루 키우고 있습니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='토끼가 농장에서 나무를 세 그루 키우고 있다니 귀엽고 재미있는 상황이네요! 어떤 종류의 나무를 키우고 있는지 궁금합니다. 혹시 토끼가 나무를 키우는 이유나 특별한 이야기가 있나요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 42, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BOgzSEt66PNpSacZ2MjfHMCflY8LQ', 'finish_reason': 'stop', 'logprobs': None}, id='run-cd849389-6411-4b92-9d1a-8cb2d1ad5403-0', usage_metadata={'input_tokens': 42, 'output_tokens': 62, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19e8272e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='다람쥐가 사과 나무를 다섯 그루 키운다면, 그곳에서 사과를 수확하는 모습이 상상되네요! 다람쥐는 사과를 좋아할 테니, 나무에서 맛있는 사과를 따는 모습이 그려집니다. 혹시 다람쥐가 사과를 가지고 어떤 특별한 일을 하거나, 친구들과 나누는 이야기가 있을까요? 아니면 다람쥐의 농장에서 일어나는 다른 재미있는 일들이 있나요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 245, 'total_tokens': 363, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BOgzeuS70C3HQUzCVrcsUliny7APG', 'finish_reason': 'stop', 'logprobs': None} id='run-3cd2cb9b-8d96-4e7e-b250-d62abd111392-0' usage_metadata={'input_tokens': 245, 'output_tokens': 118, 'total_tokens': 363, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_history.invoke(\n",
    "    {'skill': '대화', 'query': '다람쥐는 사과 나무를 다섯 그루 키우고 있습니다.'},\n",
    "    config={'configurable': {'session_id': 'rabbit'}}\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain_with_history.invoke(\n",
    "    {'skill': '대화', 'query': '토끼와 다람쥐는 합해서 몇 그루의 나무를 키우고 있나요?'},\n",
    "    config={'configurable': {'session_id': 'rabbit'}}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a6fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지금까지 메모리에 대한 내용을 살펴봄."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
