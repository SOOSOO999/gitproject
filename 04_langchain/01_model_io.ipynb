{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b94eb0",
   "metadata": {},
   "source": [
    "# Component: Model I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c953c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37d95c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473fb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.getenv(\"OPENAI_API_KEY\")\n",
    "# os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d236666",
   "metadata": {},
   "source": [
    "### PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694800f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카메라를 홍보하기 위한 재미있고, 신선한 광고문구를 작성해 주세요.\n"
     ]
    }
   ],
   "source": [
    "# prompttemplate\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template=\"{product}를 홍보하기 위한 재미있고, 신선한 광고문구를 작성해 주세요.\"   # product가 동적변수. f-string과는 다름. 동적변수로 만들려면 중괄호를 씌워주면 됨.\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['product'] # 동적변수(변경이 될 동적인 요소.) / 입력변수를 동적변수로 받아올 수 있게끔\n",
    ")\n",
    "\n",
    "print(prompt.format(product='카메라'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa786a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 계산 문제를 해결하세요.\n",
      "\n",
      "Q: 2 + 2는 무엇인가요?\n",
      "A: 2 + 2 = 4\n",
      "\n",
      "Q: 3 + 4는 무엇인가요?\n",
      "A: 3 + 4 = 7\n",
      "\n",
      "Q: 34 + 78은 무엇인가요?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "# FewShotPromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "\n",
    "# 예시 데이터 \n",
    "examples = [\n",
    "    {\"question\": \"2 + 2는 무엇인가요?\", \"answer\": \"2 + 2 = 4\"}, \n",
    "    {\"question\": \"3 + 4는 무엇인가요?\", \"answer\": \"3 + 4 = 7\"}\n",
    "]\n",
    "\n",
    "# 예시를 어떻게 출력할지 포맷 지정\n",
    "example_prompt = PromptTemplate(\n",
    "    template=\"Q: {question}\\nA: {answer}\",\n",
    "    input_variables=['question', 'answer']\n",
    ")\n",
    "\n",
    "# FewShotPromptTemplate 생성\n",
    "fewshot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"다음 계산 문제를 해결하세요.\",          # 앞에 붙는 설명\n",
    "    suffix=\"Q: {question}은 무엇인가요?\\nA:\",       # 실제 사용자 입력\n",
    "    input_variables=['question']\n",
    ") \n",
    "\n",
    "# 사용자 질문으로 프롬프트 생성 \n",
    "print(fewshot_prompt.format(question='34 + 78'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71f715c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 친절한 챗봇입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='질문: {question}'), additional_kwargs={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 친절한 챗봇입니다.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='질문: AI를 배우려면 무엇부터 해야 하나요?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatPromptTemplate - System, Human, AI 유형별 메세지 작성\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "sys_msg = SystemMessagePromptTemplate.from_template('당신은 친절한 챗봇입니다.')\n",
    "hm_msg = HumanMessagePromptTemplate.from_template('질문: {question}')\n",
    "msg = ChatPromptTemplate.from_messages([sys_msg, hm_msg])   # 여러개의 메세지 템플릿을 조합\n",
    "print(msg)\n",
    "\n",
    "msg.format_messages(question='AI를 배우려면 무엇부터 해야 하나요?')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5addb3",
   "metadata": {},
   "source": [
    "### OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf08696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OutputParser 인스턴트 및 PromptTemplate 인스턴스 생성\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions() # 파싱해주는 형식 정보에 대한 내용을 가지고 온다.\n",
    "# 프롬프트를 날려줄때부터 사용 가능 -> PromptTemplate 안에 구성해야한다\n",
    "\n",
    "prompt_tpl = PromptTemplate(\n",
    "    template=\"{subject} 5개의 팀을 알려주세요.\\n형식 지정: {format}\",   # 파싱을 하려면 형식이 맞아야하기 때문에 그 형식을 맞춰주기 위함\n",
    "    input_variables=['subject'],                        # input_variables : 사용자 입력 변수\n",
    "    partial_variables={'format': format_instructions}   # partial_variables : 고정 설정 변수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "244115b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국의 프로야구팀 5개의 팀을 알려주세요.\n",
      "형식 지정: Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 생성\n",
    "query = \"한국의 프로야구팀\"\n",
    "prompt = prompt_tpl.format(subject=query)\n",
    "print(prompt)   # format_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f627097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open ai api를 사용하기 위한 인스턴스 생성 및 요청 처리\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=2048\n",
    ")\n",
    "\n",
    "response = model.invoke(prompt) # 질의를 보내는 메서드 / prompt의 질의를 보냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f876e369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두산 베어스, LG 트윈스, 삼성 라이온즈, 키움 히어로즈, NC 다이노스\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(response.content)         # response의 content 안에 우리가 원하는 답변이 있어서 꺼내옴\n",
    "print(type(response.content))   # response의 type은 기본적으로 str이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a8083f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['두산 베어스', 'LG 트윈스', '삼성 라이온즈', '키움 히어로즈', 'NC 다이노스']\n",
      "<class 'list'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(output_parser.parse(response.content))        # 문자열인 상태를 parsing하여 리스트의 형태로 변환\n",
    "print(type(output_parser.parse(response.content)))  # 리스트\n",
    "print(type(response.content))                       # 문자열"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9a1d6",
   "metadata": {},
   "source": [
    "### HuggingFace Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb0b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307a33d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\vectordb_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='आ침에 사과를 먹었습니다.', additional_kwargs={}, response_metadata={'token_usage': ChatCompletionOutputUsage(completion_tokens=11, prompt_tokens=98, total_tokens=109), 'model': '', 'finish_reason': 'stop'}, id='run-c11cbc19-2318-4085-af2c-04e35abd65f0-0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "end_point = HuggingFaceEndpoint(\n",
    "    repo_id=\"Bllossom/llama-3.2-Korean-Bllossom-3B\",    # 허깅페이스에 저장된 모델의 repositoy\n",
    "    task='text-generation',                             # 수행하고자하는 작업의 유형\n",
    "    max_new_tokens=1024,                                # 생성할 최대 토큰 수\n",
    "    huggingfacehub_api_token=''\n",
    ")\n",
    "\n",
    "hf_model = ChatHuggingFace(\n",
    "    llm=end_point,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "hf_model.invoke('저는 아침으로 사과를 먹었습니다. 저는 아침에 뭘 먹었을까요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4bc3b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.model_laboratory import ModelLaboratory\n",
    "\n",
    "# model_lab = ModelLaboratory.from_llms([model, hf_model])\n",
    "# model_lab.compare('아침에 사과를 먹는 것의 효과를 알려주세요.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3bc75e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
