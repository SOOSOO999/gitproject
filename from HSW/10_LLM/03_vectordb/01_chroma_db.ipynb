{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15ac4c9",
   "metadata": {},
   "source": [
    "# Chroma DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8229734",
   "metadata": {},
   "source": [
    "- 설치 패키지 목록: numpy pandas datasets chromadb sentence_transformers huggingface_hub[hf_xet] PyPDF2\n",
    "- Python 3.9 버전이랑 호환성이 제일 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b22e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()   # 임시 데이터베이스 클라이언트, 데이터를 메모리에만 저장함 → 세션 종료 시 모든 데이터가 사라짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bea4b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"my_collection\")  # collection 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598ab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swhong/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:08<00:00, 10.1MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 추가\n",
    "collection.add(\n",
    "    documents=[                     # 데이터 문장\n",
    "        'This is a document about pineapple',\n",
    "        'This is a document about mango',\n",
    "        'This is a document about strawberry'\n",
    "    ],\n",
    "    ids=['id1', 'id2', 'id3']       # 문장을 구분할 id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b28bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"This is a query document about vietnam\"],     # 검색할 문자열\n",
    "    n_results=1     # 유사도가 높은 문장 몇개를 찾을지\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75052db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id1']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['This is a document about pineapple']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None]],\n",
       " 'distances': [[1.2225853204727173]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbab1c5",
   "metadata": {},
   "source": [
    "### SciQ dataset 활용 ChromaDB 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb68a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support'],\n",
       "    num_rows: 10481\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SciQ 데이터셋 로드 : 과학적인 질문과 답변이 있는 데이터셋\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"sciq\", split=\"train\")\n",
    "dataset = dataset.filter(lambda x: x[\"support\"] != \"\")  # support가 공백인 것 제외\n",
    "\n",
    "dataset     # distractor: 보기(틀린답) | correct_answer: 정답 | support: 정답에 대한 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43558353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma db 클라이언트 객체 및 collection 생성\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"sciq_support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d575d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swhong/.conda/envs/vectordb_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 임베딩 모델 로드\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")   # 경량화된 임베딩 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a664c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "supports = dataset[\"support\"][:100]     # 데이터가 너무 길어서 실습용으로 100개만 잘라서 사용\n",
    "support_embeddings = embedding_model.encode(supports).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86d558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(support_embeddings[0])  # 384 차원으로 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0e7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    ids=[str(i) for i in range(0, 100)],\n",
    "    embeddings=support_embeddings,\n",
    "    metadatas=[{\"type\":\"support\", \"text\":text} for text in supports]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe92cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = dataset[\"question\"][:3]     # 질문 뽑아옴\n",
    "question_embeddings = embedding_model.encode(questions).tolist()\n",
    "\n",
    "results = collection.query(             # 검색\n",
    "    query_embeddings=question_embeddings,\n",
    "    n_results=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c18a04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['36'], ['1'], ['2']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[None], [None], [None]],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'text': 'Agents of Decomposition The fungus-like protist saprobes are specialized to absorb nutrients from nonliving organic matter, such as dead organisms or their wastes. For instance, many types of oomycetes grow on dead animals or algae. Saprobic protists have the essential function of returning inorganic nutrients to the soil and water. This process allows for new plant growth, which in turn generates sustenance for other organisms along the food chain. Indeed, without saprobe species, such as protists, fungi, and bacteria, life would cease to exist as all organic carbon became “tied up” in dead organisms.',\n",
       "    'type': 'support'}],\n",
       "  [{'text': 'Without Coriolis Effect the global winds would blow north to south or south to north. But Coriolis makes them blow northeast to southwest or the reverse in the Northern Hemisphere. The winds blow northwest to southeast or the reverse in the southern hemisphere.',\n",
       "    'type': 'support'}],\n",
       "  [{'type': 'support',\n",
       "    'text': 'Summary Changes of state are examples of phase changes, or phase transitions. All phase changes are accompanied by changes in the energy of a system. Changes from a more-ordered state to a less-ordered state (such as a liquid to a gas) areendothermic. Changes from a less-ordered state to a more-ordered state (such as a liquid to a solid) are always exothermic. The conversion of a solid to a liquid is called fusion (or melting). The energy required to melt 1 mol of a substance is its enthalpy of fusion (ΔHfus). The energy change required to vaporize 1 mol of a substance is the enthalpy of vaporization (ΔHvap). The direct conversion of a solid to a gas is sublimation. The amount of energy needed to sublime 1 mol of a substance is its enthalpy of sublimation (ΔHsub) and is the sum of the enthalpies of fusion and vaporization. Plots of the temperature of a substance versus heat added or versus heating time at a constant rate of heating are calledheating curves. Heating curves relate temperature changes to phase transitions. A superheated liquid, a liquid at a temperature and pressure at which it should be a gas, is not stable. A cooling curve is not exactly the reverse of the heating curve because many liquids do not freeze at the expected temperature. Instead, they form a supercooled liquid, a metastable liquid phase that exists below the normal melting point. Supercooled liquids usually crystallize on standing, or adding a seed crystal of the same or another substance can induce crystallization.'}]],\n",
       " 'distances': [[1.1048442125320435],\n",
       "  [0.4666747450828552],\n",
       "  [0.9318019151687622]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7beb1193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions: What type of organism is commonly used in preparation of foods such as cheese and yogurt?\n",
      "Support: Agents of Decomposition The fungus-like protist saprobes are specialized to absorb nutrients from nonliving organic matter, such as dead organisms or their wastes. For instance, many types of oomycetes grow on dead animals or algae. Saprobic protists have the essential function of returning inorganic nutrients to the soil and water. This process allows for new plant growth, which in turn generates sustenance for other organisms along the food chain. Indeed, without saprobe species, such as protists, fungi, and bacteria, life would cease to exist as all organic carbon became “tied up” in dead organisms.\n",
      "\n",
      "Questions: What phenomenon makes global winds blow northeast to southwest or the reverse in the northern hemisphere and northwest to southeast or the reverse in the southern hemisphere?\n",
      "Support: Without Coriolis Effect the global winds would blow north to south or south to north. But Coriolis makes them blow northeast to southwest or the reverse in the Northern Hemisphere. The winds blow northwest to southeast or the reverse in the southern hemisphere.\n",
      "\n",
      "Questions: Changes from a less-ordered state to a more-ordered state (such as a liquid to a solid) are always what?\n",
      "Support: Summary Changes of state are examples of phase changes, or phase transitions. All phase changes are accompanied by changes in the energy of a system. Changes from a more-ordered state to a less-ordered state (such as a liquid to a gas) areendothermic. Changes from a less-ordered state to a more-ordered state (such as a liquid to a solid) are always exothermic. The conversion of a solid to a liquid is called fusion (or melting). The energy required to melt 1 mol of a substance is its enthalpy of fusion (ΔHfus). The energy change required to vaporize 1 mol of a substance is the enthalpy of vaporization (ΔHvap). The direct conversion of a solid to a gas is sublimation. The amount of energy needed to sublime 1 mol of a substance is its enthalpy of sublimation (ΔHsub) and is the sum of the enthalpies of fusion and vaporization. Plots of the temperature of a substance versus heat added or versus heating time at a constant rate of heating are calledheating curves. Heating curves relate temperature changes to phase transitions. A superheated liquid, a liquid at a temperature and pressure at which it should be a gas, is not stable. A cooling curve is not exactly the reverse of the heating curve because many liquids do not freeze at the expected temperature. Instead, they form a supercooled liquid, a metastable liquid phase that exists below the normal melting point. Supercooled liquids usually crystallize on standing, or adding a seed crystal of the same or another substance can induce crystallization.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, q in enumerate(questions):\n",
    "    print(\"Questions:\", q)\n",
    "    print(\"Support:\", results['metadatas'][i][0]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc06a5d",
   "metadata": {},
   "source": [
    "### Chroma DB를 활용한 키워드 기반 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eecb3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "  \"인공지능은 인간의 작업을 자동화하는 기술이다.\",\n",
    "  \"기계 학습은 패턴을 학습하여 예측하는 기술이다.\",\n",
    "  \"벡터 데이터베이스는 유사도를 기반으로 데이터를 검색하는 DB이다.\",\n",
    "  \"자연어 처리는 인간의 언어를 컴퓨터가 이해하게 하는 기술이다.\",\n",
    "  \"딥러닝은 신경망을 기반으로 한 기계 학습 기법이다.\",\n",
    "  \"강화학습은 보상을 통해 최적의 행동을 학습하는 방식이다.\",\n",
    "  \"컴퓨터 비전은 이미지나 영상을 분석하여 정보를 추출하는 기술이다.\",\n",
    "  \"토큰화는 문장을 단어 또는 형태소 단위로 나누는 작업이다.\",\n",
    "  \"임베딩은 텍스트나 데이터를 고정된 크기의 벡터로 변환하는 과정이다.\",\n",
    "  \"LLM은 대규모 텍스트 데이터를 학습한 언어 모델이다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7308fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ChromaDB 클라이언트, 컬렉션 생성\n",
    "client = chromadb.PersistentClient(path='./chroma_db')  # 영구 저장용 클라이언트, 데이터를 지정된 디렉토리에 영구 저장함 → 다시 실행해도 데이터 유지\n",
    "collection = client.get_or_create_collection(name='ai_documents')   # .get_or_create_collection: 있으면 가져오고, 없으면 생성\n",
    "\n",
    "# 텍스트 임베딩 모델 로드\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08af24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(documents):\n",
    "    embedding = model.encode(doc).tolist()\n",
    "    collection.add(\n",
    "        ids=[str(i)],\n",
    "        embeddings=[embedding],\n",
    "        metadatas=[{\"text\":doc}]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f16d6fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['7', '3']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[None, None]],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'text': '토큰화는 문장을 단어 또는 형태소 단위로 나누는 작업이다.'},\n",
       "   {'text': '자연어 처리는 인간의 언어를 컴퓨터가 이해하게 하는 기술이다.'}]],\n",
       " 'distances': [[0.9062471389770508, 1.0535051822662354]]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_keyword = '비전'\n",
    "\n",
    "query_embedding = model.encode(query_keyword).tolist()\n",
    "\n",
    "results = collection.query(query_embeddings=query_embedding, n_results=2)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c3d4ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서: 토큰화는 문장을 단어 또는 형태소 단위로 나누는 작업이다.\n",
      "검색된 문서: 자연어 처리는 인간의 언어를 컴퓨터가 이해하게 하는 기술이다.\n"
     ]
    }
   ],
   "source": [
    "for result in results[\"metadatas\"][0]:\n",
    "    print('검색된 문서:', result['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ce188",
   "metadata": {},
   "source": [
    "### 영화 추천 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0d4154",
   "metadata": {},
   "source": [
    "- overview(줄거리) 임베딩 -> 저장\n",
    "- 메타데이터 title 포함해서 저장\n",
    "- 영화 제목을 입력 -> 유사한 영화 추천\n",
    "\n",
    "- title 입력 받음 -> 입력받은 title로 overview 찾기 -> 단어 embedding -> vector db에서 검색 -> 추천 영화 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f100ac3",
   "metadata": {},
   "source": [
    "#### 내 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c617b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swhong/.conda/envs/vectordb_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "df = pd.read_csv('./data/tmdb_5000_movies.csv')\n",
    "df = df[['overview', 'title']]\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "overview_df = df['overview']\n",
    "title_df = df['title']\n",
    "title_search_df = df['title'].apply(lambda x: x.lower().replace(\" \", \"\"))\n",
    "\n",
    "# 텍스트 임베딩 모델 로드\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "chroma_client = chromadb.PersistentClient(path='./chroma_db')\n",
    "collection = chroma_client.create_collection(name=\"movie_overview\")  # collection 객체 생성\n",
    "\n",
    "\n",
    "for i, doc in enumerate(overview_df):\n",
    "    embedding_overview = model.encode(str(doc)).tolist()\n",
    "    collection.add(\n",
    "        ids=[f'id{i}'],\n",
    "        embeddings=[embedding_overview],\n",
    "        metadatas=[{\"text\":title_df[i]}]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c19f43",
   "metadata": {},
   "source": [
    "##### 제목 입력해서 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b42cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천 영화: Alien: Resurrection\n",
      "추천 영화: The Black Hole\n",
      "추천 영화: Serenity\n",
      "추천 영화: Aliens\n"
     ]
    }
   ],
   "source": [
    "input_ = input(\"영화 제목: \")\n",
    "input_ = input_.lower().replace(\" \", \"\")\n",
    "query_text = overview_df[title_search_df==input_]\n",
    "distance_threshold = 0.01\n",
    "\n",
    "\n",
    "while len(query_text)==0: \n",
    "    input_ = input('없는 영화입니다. 다시 입력하세요: ')\n",
    "    input_ = input_.lower().replace(\" \", \"\")\n",
    "    query_text = overview_df[title_search_df==input_]\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=query_text.iloc[0],     # 검색할 문자열\n",
    "    n_results=5     # 유사도가 높은 문장 몇개를 찾을지\n",
    ")\n",
    "\n",
    "for distance, metadata in zip(results[\"distances\"][0], results[\"metadatas\"][0]):\n",
    "    if distance > distance_threshold:\n",
    "        print(f\"추천 영화 {i}:\", metadata[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37991197",
   "metadata": {},
   "source": [
    "##### 줄거리 입력해서 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e68d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천 영화: Equilibrium\n",
      "추천 영화: Thr3e\n",
      "추천 영화: The Act of Killing\n",
      "추천 영화: Contagion\n",
      "추천 영화: River's Edge\n"
     ]
    }
   ],
   "source": [
    "query_text = input(\"영화 줄거리: \")\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=query_text,     # 검색할 문자열\n",
    "    n_results=5     # 유사도가 높은 문장 몇개를 찾을지\n",
    ")\n",
    "\n",
    "for i, metadata in enumerate(results[\"metadatas\"][0]):\n",
    "    print(f\"추천 영화 {i}:\", metadata[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e31a8",
   "metadata": {},
   "source": [
    "##### 강사님 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5edbba",
   "metadata": {},
   "source": [
    "### 논문 pdf 내용 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a20285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "client = chromadb.PersistentClient(path='./chroma_db')\n",
    "# client.delete_collection('papers')  # 컬렉션 삭제 -> 없으면 error 발생\n",
    "collection = client.get_or_create_collection(name='papers')\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b41b3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = [\n",
    "    {'id':'1', 'title':'내논문', 'path':'./data/my_paper.pdf'},\n",
    "    {'id':'2', 'title':'NLP', 'path':'./data/nlp_paper.pdf'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9565c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        # .extract_text(): 페이지에서 텍스트 추출 | reader.pages: 페이지 추출\n",
    "        text = \" \".join([page.extract_text() for page in reader.pages if page.extract_text()]) # 페이지에서 추출한 내용이 있을 때 공백으로 .join\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32d22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in papers:\n",
    "    text = extract_text_from_pdf(paper['path']) # 텍스트 추출\n",
    "    embedding = model.encode(text).tolist()     # embedding\n",
    "    collection.add(\n",
    "        ids=[paper['id']],\n",
    "        embeddings=[embedding],\n",
    "        metadatas=[{'title':paper['title']}],\n",
    "        documents=[text]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856097a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['1', '2'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['Cement and Concrete Composites 152 (2024) 105646\\nAvailable online 8 July 2024\\n0958-9465/© 2024 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC license ( http://creativecommons.org/licenses/by-\\nnc/4.0/ ).\\nContents lists available at ScienceDirect\\nCement and Concrete Composites\\njournal homepage: www.elsevier.com/locate/cemconcomp\\nMechanical property evaluation of 3D multi-phase cement paste\\nmicrostructures reconstructed using generative adversarial networks\\nSung-Wook Honga, Se-Yun Kima, Kyoungsoo Parka, Kenjiro Teradab, Hoonhee Leec,\\nTong-Seok Hana,∗\\naDepartment of Civil and Environmental Engineering, Yonsei University, Seoul 03722, Republic of Korea\\nbInternational Research Institute of Disaster Science, Tohoku University, Sendai 980-8572, Japan\\ncHalla Cement Corp., Gangneung, Gangwon 25645, Republic of Korea\\nA R T I C L E I N F O\\nKeywords:\\nCement paste\\nMicrostructure\\nGenerative adversarial networks\\nMechanical properties\\nPhase-field fracture model\\nMicro-CTA B S T R A C T\\nThis study proposes an artificial intelligence based framework for reconstructing the 3D multi-phase cement\\npaste microstructure to evaluate its mechanical properties using simulation. The reconstruction of cement paste\\nmicrostructures is performed using modified generative adversarial networks (GANs) based on microstructural\\nimages from micro-CT. For computational efficiency, 2D microstructures are first reconstructed and then\\nextended to 3D microstructures. The reconstructed microstructures exhibit the same microstructural features\\nas the original microstructures when characterized by probability functions. Mechanical properties such as\\nstiffness and tensile strength are evaluated for the original and reconstructed specimens using a phase-\\nfield fracture model, and similar behaviors are observed. The results confirm that the reconstructed virtual\\nmicrostructures can be used to supplement the real microstructures in evaluating the mechanical properties\\nof 3D multi-phase cement paste. This approach thus provides a critical element of a data-driven approach to\\ncorrelating its microstructure and properties.\\n1. Introduction\\nProperty evaluation of cementitious materials through experiments\\nis time and effort-intensive. Simulating material properties that can\\nsupplement the experimental results can accelerate the analysis of\\nnew and existing material behaviors. However, due to the complex\\nmicrostructural features of cementitious materials, including cement\\npaste, reconstructing virtual specimens that share similar microstruc-\\ntural characteristics is challenging. More recently, advances in artificial\\nintelligence approaches have enabled the reconstruction of complex\\nmicrostructures. Among the approaches, generative adversarial net-\\nworks (GAN) [ 1–5] are found to be effective for such a task. This\\nstudy proposes a computationally efficient framework for reconstruct-\\ning multi-phase cement paste microstructures from micro-CT and an-\\nalyzes the mechanical properties evaluated from the reconstructed\\nmicrostructures.\\nThe reconstruction of microstructures with complex features has\\nbeen investigated and is used for evaluating properties through vir-\\ntual experiments. Random heterogeneous materials characterized by\\nlow-order probability functions were successfully reconstructed us-\\ning stochastic optimization techniques [ 6–10]. The method was also\\napplied to reconstruct cementitious materials, and the reconstructed\\n∗Corresponding author.\\nE-mail address: tshan@yonsei.ac.kr (T.-S. Han).microstructures were used to evaluate the permeability of porous con-\\ncrete [ 11] and cement paste [ 12], the stiffness and thermal conductivity\\nof the interfacial transition zone (ITZ) [ 13], and to perform a sen-\\nsitivity analysis of the stiffness and strength of cement paste [ 14].\\nAlthough microstructures reconstructed using stochastic optimization\\nwere effective for property evaluation of cementitious materials, the\\nreconstructed microstructures were limited to two phases (pore and\\nsolid) owing to computational cost. For a more accurate analysis of\\nlocalized behaviors such as strength, a more detailed microstructural\\nmodel as proposed in Refs. [ 15–21] is preferable. In these studies,\\ncement paste microstructures were modeled as multiple solid phases,\\nand simulations were performed to demonstrate that cracks propagated\\nthrough the weak solid phase. In particular, Refs. [ 15–18] and relevant\\nworks modeled the multi-phase cement paste incorporating uncertain-\\nties based on micro-CT images, and evaluated its properties using the\\nlattice model. However, the reconstruction of an accurate multiple solid\\nphase microstructure using the conventional stochastic optimization\\nmethod for continuum based simulations requires significant effort;\\ntherefore, alternative approaches are recommended for efficiency.\\nhttps://doi.org/10.1016/j.cemconcomp.2024.105646\\nReceived 11 February 2024; Received in revised form 20 June 2024; Accepted 26 June 2024 Cement and Concrete Composites 152 (2024) 105646\\n2S.-W. Hong et al.\\nFig. 1. Cement paste specimens. (a) Cubic specimen, (b) Nanoindentation specimen, (c) Micro-CT specimen.\\nAs deep learning techniques are widely available, the reconstruc-\\ntion of complex three-dimensional (3D) microstructures from two-\\ndimensional (2D) or 3D microstructural information becomes, and\\nextensive articles have been recently published. For example, 2D to 3D\\nmicrostructure reconstruction approaches using transfer learning [ 22,\\n23] and stochastic optimization with gradient-based or machine learn-\\ning [24,25] were proposed. Microstructure reconstruction using a gen-\\nerative adversarial network (GAN) model can be found including 2D\\nto 3D microstructure reconstruction techniques [ 26–28]. The deep-\\nlearning approach was also applied for reconstructing cementitious\\nmaterials and geomaterials. In Ref. [ 29], 2D concrete three-phase (pore,\\nbinder, and aggregate) microstructures were generated using GAN\\nfrom micro-CT images, and the mechanical properties were estimated.\\nThe characteristics of cement paste microstructures were investigated\\nusing deep learning to obtain insights into microstructure reconstruc-\\ntion [ 30]. Three-dimensional two-phase porous media microstructures\\nwere characterized and reconstructed using an efficient GAN [ 31].\\nThree-dimensional shale and beadpack two-phase (pore and solid)\\nmicrostructures were reconstructed using a multiscale GAN [ 32]. Ad-\\nditionally, a cellular automata approach controlled by deep learning\\nnetworks for reconstructing hydrating 3D multi-phase cement paste\\nmicrostructures was proposed in Ref. [ 33].\\nAmong the deep learning models, variational autoencoder (VAE)\\n[34–36], diffusion model [ 37–39], and the GAN model have been\\nused to reconstruct microstructures with complex geometries. The VAE\\nmodel is relatively easy to train and diverse features can be recon-\\nstructed. However, the VAE model often suffers from low fidelity and\\nblurred microstructural features in reconstructed samples. The diffusion\\nmodel reconstructs high-fidelity samples with diverse features, but it\\ntends to generate samples slowly because it requires multiple passes\\nthrough the neural network compared with the VAE and GAN models.\\nIn addition, the diffusion model is more complex to implement and\\nrequires a higher computational cost than the other models. Although\\nthe GAN model is relatively difficult to train because of the two\\nloss functions (generator and discriminator), the model can generate\\nhigh-fidelity samples with a desired level of diversity. In this study,\\nwe propose an extended GAN method to reconstruct 3D four-phase\\ncement paste microstructures consisting of pore, outer product, inner\\nproduct, and unhydrated phases to validate the method by comparing\\nthe microstructural characteristics and mechanical properties (stiffness\\nand tensile strength) of the original and reconstructed specimens.\\nThe original microstructures of cement paste can be obtained nonde-\\nstructively using micro-CT. The micro-CT has been successfully used to\\ninvestigate the microstructural features of cement paste and its correla-\\ntion to material properties [ 40–43]. The micro-CT-based cement paste\\nimages are characterized as multi-phase microstructures, and their\\nproperties are evaluated using simulation tools such as lattice models\\n(e.g., Refs. [ 15–18,44]) and continuum-based models (e.g., Refs. [ 19,\\n45–48]). In particular, a framework to evaluate the mechanical prop-\\nerties of cement paste using a phase-field fracture model [ 49,50], an\\nextension of a continuum damage model, is proposed in Ref. [ 19] withmulti-phase microstructures obtained from synchrotron X-ray micro-\\nCT and nanoindentation test results. In Ref. [ 19], the differences in\\nmechanical responses between multi-phase and homogenized models\\nwere compared. It is confirmed that the multi-phase solid model can\\ncapture the realistic crack propagation patterns observed from the\\nexperiments in Ref. [ 21]. In this study, a method for reconstructing\\nvirtual multiple-solid-phase microstructures is investigated. The char-\\nacteristics and mechanical properties of the reconstructed specimens\\nare compared with those of the original microstructures to confirm that\\nthe reconstructed microstructures can supplement the microstructures\\nobtained from the micro-CT measurements.\\nIn the next section, materials for the analysis are described. Then,\\nmethods for investigating microstructural characteristics, performance\\nevaluation tools, and deep learning techniques are briefly presented.\\nThe procedure for reconstructing cement paste microstructures is de-\\nscribed next, followed by the mechanical performance evaluation and\\nanalysis section. Finally, further works are discussed, and conclusions\\nare summarized.\\n2. Materials and methods\\n2.1. Specimens\\nThe cement paste specimens were prepared using ordinary Portland\\ncement with a water/cement ratio (w/c) of 0.4. The specimens were\\ncast in cubic 5 ×5×5 mm3silicon molds and were demolded after 24 h\\n(Fig. 1a). The specimens were cured in water at room temperature for\\n28 days. The samples were then submerged in isopropanol to prevent\\nfurther hydration. A specimen for the nanoindentation test is presented\\nin Fig. 1b. The 5 mm cubic specimen was sliced, impregnated with\\nepoxy resin in a vacuum chamber to remove pores and prevent damage,\\nand cured for 8 h, followed by grinding and polishing. Specimens\\nfor obtaining high-resolution microstructures from micro-CT scans are\\nprepared by carefully breaking each specimen to a width of 1 mm\\n(Fig. 1c) shortly before measurements. The shape of the specimens\\nfor CT measurements was irregular, but the largest width of the cross\\nsection in the direction of the X-ray was approximately 1 mm. The\\nspecimen height did not affect the X-ray CT image quality; therefore,\\nit was not reduced to be comparable with the cross-sectional width,\\nbut was maintained large enough to handle the specimen conveniently.\\nThe specimen preparation procedure used in Refs. [ 20,21,51] was used.\\nMore details can be found in the references.\\n2.2. Nanoindentation\\nThe nanoindentation test with Berkovich tip was conducted for\\nidentifying the input modeling parameters of the cement paste mi-\\ncrostructure. The load control was used to conduct the test (a maximum\\nload: 20 mN) . The loading time was 20 s, held for 2 s at the maximum\\nload, and unloaded for 20 s. Indentation probes were conducted on a\\n10×10 grid with 20 μm spacing, so the measurement domain was Cement and Concrete Composites 152 (2024) 105646\\n3S.-W. Hong et al.\\nFig. 2. Correlation between Young’s modulus ( 𝐸𝑠) and hardness ( 𝐻𝑠) for solid phases\\nfrom nanoindentation results.\\n180× 180 μm2. The 100 indentation points were confirmed to be\\nsufficient for phase distribution characterization and input material\\nmodeling parameter identification for cement paste microstructures\\nwith four phases, which are pore and three solid phases (outer, inner\\nproduct, and unhydrated phases) [ 19,20,52]. From the indentation\\ntest, Young’s modulus distribution and the correlation between Young’s\\nmodulus (𝐸𝑠) and hardness ( 𝐻𝑠) (Fig. 2) of the solid phases are ob-\\ntained and used to identify the material parameters combined with the\\ncharacteristics of micro-CT images.\\n2.3. Micro-CT\\nThe three dimensional cement paste microstructures with a voxel\\nsize of0.65 μm were obtained from specimens less than 1 mm wide\\nusing a synchrotron X-ray micro-CT (energy level: 25 keV) at Pohang\\nAccelerator Laboratory in the Republic of Korea ( Fig. 3a). Each voxel\\nis assigned a grayscale value in image format ( Fig. 3b). The value can\\nbe linearly transformed to linear attenuation coefficient (LAC), which\\ncan be considered as a material characteristic [ 53]. The distribution of\\ngrayscale or LAC value ( 𝜒) in correlation with nanoindentation results\\nis used to determine the threshold values for phase segmentation. The\\nLAC value is normalized ( ̄ 𝜒) so that the pore threshold is assigned to\\n0, and the peak LAC of unhydrated phase is set to 1 [ 20].\\n2.4. Lineal-path function\\nIn this study, microstructural features are characterized by the\\nlineal-path ( 𝐿) function [ 10] (Fig. 4), which is used to characterizecement paste microstructure. The lineal-path function was found to\\nbe effective for identifying phase characteristics, such as continuity, of\\nrandom heterogeneous materials, including cement paste, and for con-\\nfirming the similarity or statistical identity of the microstructures [ 51,\\n54–58]. In a domain with side length 𝐷, the lineal-path function\\n𝐿𝛼(𝑟)is a probability of placing a line of length 𝑟entirely within\\na phase𝛼. Phase𝛼can be one of the four phases for the cement\\npaste microstructure. However, the evaluation of the multi-phase ce-\\nment paste microstructures obtained from micro-CT using simulations\\nconfirmed that the weaker hydrated phase and pore microstructural\\nfeatures dominated the material strength (e.g., Refs. [ 16–18]). It was\\nalso demonstrated that simulated cracks tend to propagate through\\nthe weaker hydrated phase (outer product), and this prediction was\\nvalidated experimentally [ 20,21,51]. Therefore, the pore ( 𝑝) and outer\\nproduct (𝑜) phases were characterized because they were the most\\ninfluential phases contributing to the mechanical behavior, considering\\ntheir phase volume fraction and strength.\\nPhase continuity is further characterized by the parameter 𝓁𝐿𝛼[20].\\nFor a random heterogeneous material, an exponential function can be\\nused to approximate the lineal-path function 𝐿𝛼(𝑟)for phase𝛼as\\n𝐿𝛼(𝑟)=𝜙𝛼exp(\\n−𝑟\\n𝓁𝐿𝛼)\\n, (1)\\nwhere𝜙𝛼is the phase volume fraction and 𝑟is the line length. By\\ndefinition,𝓁𝐿𝛼is the intersection between the initial slope of 𝐿𝛼(𝑟)and\\nthe𝑟axis, which is shown in Fig. 4. The parameter 𝓁𝐿𝛼can serve as a\\ncharacteristic scalar parameter for representing 𝐿𝛼(𝑟).\\n2.5. Phase-field fracture model\\nThe phase-field fracture model is used to conduct direct tension tests\\nto obtain the mechanical behaviors of the cement paste microstructures.\\nThe phase-field fracture model, and extension of the damage model,\\nadopted and implemented for this study is based on the formulation\\npresented in Refs. [ 49,50], and only a short summary is described\\nhere. A damage variable 𝑑for the phase-field diffusive crack ranges\\nfrom 0 (no crack) to 1 (complete crack) at each material point. Four\\nparameters are required for the model as input parameters for solid\\nphases [ 20]. The Young’s modulus 𝐸𝑠and Poisson’s ratio ( 𝜈) are related\\nto elasticity, and the peak tensile strength ( 𝜎𝑠) and diffusive crack\\nwidth (𝑙) are related to fracture. 𝐸𝑠and𝜎𝑠are determined from the\\nnanoindentation results and grayscale level (or LAC) of the micro-CT\\nimages as in Refs. [ 20,51]. The value of 0.2 is assumed for the Poisson’s\\nratio𝜈, and twice the element size ( 2ℎ) is selected for the diffusive crack\\nwidth𝑙, the minimum value required for the model [ 49]. More details\\non efficient and effective modeling can be found in Refs. [ 20,21]. The\\nsimulation procedure is described further in Section 4.1.\\nFig. 3. Micro-CT setup and sample microstructure. (a) Micro-CT device at the Pohang Accelerator Laboratory (PAL), (b) Cement paste microstructure with 0.65 μm resolution. Cement and Concrete Composites 152 (2024) 105646\\n4S.-W. Hong et al.\\nFig. 4. Example of microstructure consisting of four phases, and its lineal-path function 𝐿𝑜(𝑟)and parameter 𝓁𝐿𝑜for the outer product.\\n2.6. Generative adversarial network (GAN)\\nThe generative adversarial network (GAN) [ 1] is a framework for\\nestimating generative models using the adversarial process. In the\\nframework, two models are trained. One model, generator 𝐺, gener-\\nates or reconstructs data based on characteristics from the original\\nsamples. The other model, discriminator 𝐷, estimates the probability\\nthat the data is from the original samples. The two models are trained\\nthrough an adversarial process by the interactions between the two\\nmodels, through which the characteristics of the generated data sets\\nbecome similar to those of the original samples. Enhanced from the\\ngeneral GAN, cycle generative adversarial networks (CycleGAN) [ 2]\\nwere proposed to reconstruct images more accurately. A summary of\\nthe algorithm of CycleGAN is presented in Appendix A. The Cycle-\\nGAN algorithm was adopted with modified networks specific to this\\ncurrent study. The network used for reconstructing 3D cement paste\\nmicrostructures from 2D cement paste images is described in detail in\\nthe next section.\\n3. Microstructure reconstruction\\nThe cement paste microstructure reconstruction process using the\\nextended CycleGAN is presented. First, the procedure to obtain the\\ntarget microstructures is described. Then, the reconstruction procedure\\nusing CycleGAN [ 2] and extensions proposed in this study are followed.\\nThe deep learning-based reconstruction process was implemented as an\\nextension of TensorFlow [ 59], and the related terms are consistent with\\nthose used in TensorFlow.\\n3.1. Target microstructure\\nThe target microstructures for reconstruction were segmented into\\nfour phases from the original micro-CT images following the procedure\\nand the data presented in Ref. [ 21]. First, to segment the cement paste\\nmicrostructure, Young’s modulus distribution obtained from nanoin-\\ndentation is fitted by three superposed Gaussian curves ( Fig. 5a). The\\nintersection between the first and second Gaussian curves from the left\\nwas used as the outer and inner product phase thresholds. Likewise,\\nthe intersection between the second and third Gaussian curves deter-\\nmined the threshold value to distinguish the inner product from the\\nunhydrated phases. Then, from the linear attenuation coefficient (LAC,\\n𝜒) distribution from the original micro-CT microstructure ( Fig. 5b), the\\nthreshold value to segment pores from the solid phases is selected by\\nthe intersection between the tangents from the maximum points of the\\nfirst and second derivatives. The threshold between the unhydrated\\nand other solid phases was determined by locating the intersection\\nbetween the two right-most Gaussian curves after approximating the\\nLAC distribution using four Gaussian curves. The threshold to separate\\nthe outer product from the inner product was determined from volume\\nratio of the outer to inner products from nanoindentation. An exampleof an original cement paste microstructure from micro-CT shown in\\nFig. 5c can then be segmented to a four-phase target microstructure\\nshown in Fig. 5d.\\nThe side length of the microstructure was 83.2 μm with the voxel\\nsize of0.65μm , so 128×128×128 voxels constitute each microstruc-\\nture. The side length of 83.2 μm for a cement paste microstructure\\nshould be large enough to evaluate its mechanical properties at the\\nmicroscale based on previous studies [ 17,19,55]. The representative\\nvolume element (RVE) as a binder in concrete could be actually much\\nlarger depending on the additional microstructural features (e.g., void\\nclusters) or even may not exist because of the localized behavior of\\ncementitious materials [ 60]. However, the microstructure size was\\nfound to be adequate when comparing the property evaluation between\\nthe target and reconstructed microstructures.\\n3.2. Reconstructed microstructure\\n3.2.1. Adapted CycleGAN\\nAn extension of the general GAN, CycleGAN [ 2], is used to re-\\nconstruct the cement paste microstructure. We adapted the network\\nto our framework for microstructure reconstruction. The direct con-\\nnections of the autoencoder for convolutional neural networks (CNNs)\\nproposed in Ref. [ 5] were adopted for an effective outcome. A more\\ndetailed description of the adapted network can be found in Ap-\\npendix B. CNNs [ 61] were trained with data through the gradient\\ndescent method. The network is schematically presented in Fig. 6.\\nGAN model for training and reconstructing 3D microstructures re-\\nquires a significant amount of parameters, resulting in huge compu-\\ntational costs. Thus, in this study, a two-step process is proposed.\\nThe first step is a 2D microstructure reconstruction process, and the\\nsecond step is a 2D to 3D microstructure reconstruction process. The\\n2D generator produces a ‘‘fake’’ 2D microstructure from a noise image\\nas an input ( Fig. 6). The noise image comprises randomly distributed\\npixel-based four phases with volume fractions obtained from a target\\nmicrostructure. The ‘‘real’’ images are taken from 2D sections of the\\n3D micro-CT microstructures. The ‘‘fake’’ and ‘‘real’’ 2D microstruc-\\ntural images are provided to the discriminator. The generator and\\ndiscriminator networks are both composed of CNNs. In particular, the\\ndiscriminator utilizes PatchGAN [ 62]. For an effective reconstruction\\nprocess, the direct connections between the encoder and decoder in the\\nautoencoder of 2D and 3D generators are used. Encoder information is\\n‘‘concatenated’’ to the decoder information to incorporate previously\\nmissing features during the transposed convolution process.\\nThe number of 2D images used for the training and test processes\\nwas 491,500 and 500, respectively. For the training dataset of the\\n3D microstructures, 60 microstructures were augmented to 3200 mi-\\ncrostructures through image rotation and reflection. The similarity of\\ntarget and reconstructed specimens of both 2D and 3D microstructures\\nduring the training process ( Fig. 6) were confirmed by comparing the\\nphase volume fractions and phase continuity ( 𝓁𝐿and Eq. (1)) of the Cement and Concrete Composites 152 (2024) 105646\\n5S.-W. Hong et al.\\nFig. 5. Cement paste microstructure phase segmentation. (a) Young’s modulus ( 𝐸𝑠) distribution from nanoindentation, (b) Linear attenuation coefficient (LAC, 𝜒) distribution from\\nmicro-CT, (c) Original microstructure from micro-CT (8-bit grayscale image), (d) Segmented four-phase microstructure. ( 𝜙: volume fraction)\\nFig. 6. Modified training network of CycleGAN for reconstructing 3D cement paste microstructure. (Note: The CycleGAN for 3D microstructure reconstruction consists of two\\nprocesses: the 2D microstructure reconstruction process (green box) and the 2D to 3D microstructure reconstruction process (red box). Each process is equipped with one generator\\nand one discriminator.) (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)\\ntarget and reconstructed microstructures. When the validity of the GAN\\nmodel is tested, the reconstructed images are generally investigated\\nusing indices such as the Frechet Inception Distance (FID) [ 63], which\\ncan check the diverse characteristics of the images. However, the\\nreconstruction in this study primarily aimed to obtain microstructuresthat yield similar mechanical properties and microstructural character-\\nistics. Thus, microstructural characteristics, such as porosity and phase\\ncontinuity, were used for the test, and the microstructural characteris-\\ntics and evaluated material properties of the target and reconstructed\\nmicrostructures were compared to confirm the validity of the proposed Cement and Concrete Composites 152 (2024) 105646\\n6S.-W. Hong et al.\\nFig. 7. Reconstructed four-phase microstructures after specific epochs as training progresses. (Note: Four samples are shown for each epoch, one complete pass of the training\\ndataset through the algorithm. The volume fraction of individual phases is the same in the shuffled microstructure.)\\nreconstruction method. The microstructure generation/reconstruction\\nalgorithm was tested on 20 3D real microstructures from micro-CT.\\nAlthough the number of test samples used in this study could be\\ninsufficient for checking the validity of the method using FID, the\\nindices from microstructural characteristics (phase volume fraction and\\nphase continuity) used to test the model were found to be effective and\\nefficient even with a relatively small number of test samples.\\nThe four phases were mapped to the pixel/voxel values of 0, 0.66,\\n1.33, and 2.0, which represent the pore, outer product, inner product,and unhydrated phases, respectively. The sequence is the same as the\\ngrayscale or LAC values from the micro-CT images, which are generally\\nproportional to the material/phase densities. When the reconstruction\\nprocess yielded a pixel/voxel value between the phase values, the value\\nwas changed to the nearest phase value. The selection of mapped values\\nfor phases can be tuned further, including the non-equal-distance phase\\npixel values; however, this is deferred to a future study. The perfor-\\nmance of the algorithms for 2D and 3D microstructure reconstruction\\nis described next. Cement and Concrete Composites 152 (2024) 105646\\n7S.-W. Hong et al.\\nFig. 8. Examples of reconstructed 2D microstructures. (a) Target microstructures, (b) Reconstructed microstructures. (Sectional images are used for 2D to 3D reconstruction.)\\n3.2.2. 2D microstructure reconstruction\\nOnce the network is trained and tested, it is ready for microstruc-\\nture reconstruction. In reconstructing the 2D microstructure, a target\\nmicrostructure is selected, and volume fractions of the four phases\\nare obtained. A randomly distributed pixel-based (noise) four-phase\\nmicrostructure image is generated using the volume fractions of the\\ntarget image and is fed into the trained network for 2D microstructure\\nreconstruction.\\nThe reconstructed microstructures during the training process from\\nthe 2D generator are illustrated in Fig. 7. The initial generator pro-\\nduces images with noise. Nevertheless, as the training progresses, the\\nfeatures notably transform and gradually acquire the microstructure\\ncharacteristics of cement paste. After 350 epochs (the number of\\ncomplete passes of the training dataset through the algorithm), the re-\\nconstructed microstructures did not exhibit noise and rather exhibited\\nsimilar microstructural features to those of the target microstructure, as\\nconfirmed by the indices phase volume fraction and phase continuity.\\nWhen the training was continued beyond 350 epochs, the reconstructed\\nmicrostructural features did not improve, and the differences increased\\nowing to overfitting. Because the trained network after 350 epochs\\nexhibited superior performance for reconstructing microstructures for\\nthe test data, this network was used for reconstruction. This find-\\ning was consistent with the training of the 2D to 3D microstructure\\nreconstruction network described in the next section.\\nThe reconstructed 2D microstructures for 350 epochs are showcased\\nalongside their target counterparts in Fig. 8. In Fig. 8a, there are three\\ntarget microstructures, labeled samples 1, 2, and 3, each representing\\ndifferent phase cluster sizes. Three microstructures are reconstructed\\nfor each sample, shown in Fig. 8b as examples. Notably, the three\\nmicrostructures reconstructed for one target sample share similar mi-\\ncrostructural features, while noticeable differences are visible between\\nthe microstructures reconstructed for different target samples. In par-\\nticular, sample 2 shows a larger cluster of inner products (light gray\\nin Fig. 8), a characteristic faithfully reproduced in the reconstructed\\nmicrostructures. Compared with the target microstructures, the pore\\nvolume fraction ( 𝜙𝑝) differences were within 2%, and the pore and\\nouter product phase continuity ( 𝓁𝐿) values were within 5% of thosefrom the target images for the 500 tested 2D microstructures. Examples\\nof the lineal-path ( 𝐿) functions of a target and a reconstructed specimen\\n(upper left corner specimens in Fig. 8) are presented in Fig. 9. The\\nlineal-path functions of the 2D microstructure are identified along the\\nx- and𝑦-axis directions, respectively. The results are similar between\\nthe target and reconstructed microstructures, which is also true for all\\nother test specimens.\\n3.2.3. 2D to 3D microstructure reconstruction\\nA 3D cement paste microstructure is reconstructed from the 2D\\nimages ( Fig. 6). Three 2D microstructures, generated from random\\ninput noise images with the same target phase volume fractions, are\\nprovided as the top, middle, and bottom sections for reconstructing\\nthe 3D microstructure. When a 3D microstructure is reconstructed, the\\nvolume fractions of the pore and outer product phase volume frac-\\ntions are evaluated. When the volume fraction differences between the\\ntarget and the reconstructed microstructures are more than 10%, the\\nmicrostructure is discarded, and the reconstruction process is repeated\\nuntil the differences are within 10%. The acceptance rate depends on\\nthe microstructural characteristics. When the porosity of the target\\nmicrostructure was similar to that of the samples used for training,\\nthe reconstructed microstructures were accepted within 10 attempts.\\nThe same behavior was observed in the case of the reconstructed\\nmicrostructures presented in this manuscript. If the target phase volume\\nfractions are far apart from those of the training microstructures, the\\nacceptance rate of the reconstructed microstructures becomes slow,\\nand the differences in the microstructural features increase. Training\\nwith more data possessing a wide range of microstructural features is\\nrequired to generalize the reconstruction approach, which is deferred\\nto future studies. Examples of reconstructed 3D microstructures are\\npresented with the 3D target cement paste microstructures in Fig. 10.\\nBecause the 3D microstructures are reconstructed based on samples\\n1, 2, and 3 in Fig. 8, the microstructural features observed in the\\n2D microstructure of samples in Fig. 8 can be observed in the 3D\\nmicrostructure in Fig. 10. One virtual microstructure was reconstructed\\nfrom a real microstructure obtained from micro-CT was used for the\\nanalysis, resulting in a total of 20 3D virtual microstructures. Cement and Concrete Composites 152 (2024) 105646\\n8S.-W. Hong et al.\\nFig. 9. Lineal-path function for 2D microstructures. (a) Pore phase, (b) Outer product phase. ( 𝑟: line length, 𝐷: sample width)\\nThe differences in the pore and outer product phase volume frac-\\ntions (𝜙) were within 5%, and those in phase continuity ( 𝓁𝐿) were\\nwithin 7%. The lineal-path functions ( 𝐿) for the 3D target and re-\\nconstructed microstructures are presented in Fig. 11. The lineal-path\\nfunctions,𝐿𝑝and𝐿𝑜, curve for the target microstructure and the\\nreconstructed microstructure also align well for the 3D cases as in 2D.\\nThe distributions of porosity ( 𝜙𝑝) and outer product phase continuity\\n(𝓁𝐿𝑜) are presented for all the target and reconstructed specimens (20\\neach) in Fig. 12. Distributions of volume fractions and phase continuity\\nfor other phases were similar. The mean values and standard deviations\\nof𝜙𝑝and𝓁𝐿𝑜between the target and reconstructed microstructures\\nare comparable, which confirms that the target and reconstructed\\nspecimens share the same statistical microstructural characteristics.\\n4. Mechanical property evaluation\\nUsing the reconstructed/virtual microstructures and target/original\\nmicrostructures, mechanical properties (stiffness and tensile strength)\\nwere simulated and compared. The simulation procedure is presented\\nfirst, and evaluated properties from the target and reconstructed mi-\\ncrostructures are presented and analyzed.\\n4.1. Simulation procedure\\nThe mechanical properties of the target and reconstructed mi-\\ncrostructures were evaluated using the phase-field fracture model. The\\ninput parameters were selected following the procedure presented in\\nRef. [20] and were briefly described in Section 2.\\nFrom the nanoindentation results and micro-CT measurements, the\\ncorrelation between Young’s modulus ( 𝐸𝑠) and normalized LAC ( ̄ 𝜒𝑠) for\\nsolid phases was determined as\\n𝐸𝑠=69.2×̄ 𝜒𝑠+1.22 GPa. (2)Table 1\\nPhase characteristics and modeling parameters.\\nParameteraPhase\\nPore Outer product Inner product Unhydrated\\n𝜙target [%] 9.3 70.3 18.2 2.3\\n𝜙reconstructed [%] 9.3 69.7 18.3 2.7\\n̄ 𝜒𝑠[−] – 0.143 0.410 1.077\\n𝐸𝑠[GPa] – 11.1 29.6 75.8\\n𝜎𝑠[MPa] – 31.6 136.3 556.8\\na𝜙is volume fraction; ̄ 𝜒𝑠,𝐸𝑠, and𝜎𝑠are normalized LAC, Young’ modulus, and tensile\\nstrength for solid phase, respectively.\\nData pairs of Young’s modulus ( 𝐸𝑠) and hardness ( 𝐻𝑠) for solid phases\\nfrom the nanoindentation test were approximated using a power law\\n(Fig. 2),\\n𝐻𝑠=0.005178𝐸1.495\\n𝑠GPa. (3)\\nThe hardness value is transformed to the tensile strength for a solid\\nphase (𝜎𝑠) as\\n𝜎𝑠=𝐻𝑠∕𝜉. (4)\\nHere,𝜉is the conversion factor, which depends on materials and varies\\nover a wide range of magnitudes [17]. A 𝜉value of 12 was reported\\nto be reasonable for cement paste on a similar length scale [17,19],\\nso𝜉was set to 12 for the simulations. For each target microstructure,\\nthe mean normalized LAC value for the individual solid phase ( ̄ 𝜒𝑠) is\\ndetermined, and the input modeling parameters are calculated from\\nEqs. (2)–(4). Then, the same material modeling parameter values from\\nthe target microstructures are assigned to the corresponding recon-\\nstructed microstructure. As an example, the phase characteristics and\\ninput material modeling parameters for the microstructure at the upper\\nleft corner in Fig. 10 are presented in Table 1 [21].\\nDirect tension was applied to the microstructure as shown in\\nFig. 13a. The displacement was applied at the top surface while Cement and Concrete Composites 152 (2024) 105646\\n9S.-W. Hong et al.\\nFig. 10. Examples of reconstructed 3D microstructures. (a) Target microstructures, (b) Reconstructed microstructures.\\nthe bottom was fixed, and the side surfaces were traction-free. The\\nsimulations continued over the peak, where multiple crack propagation\\noccurred before the numerical stability was lost. The multiple crack\\npatterns after the peak load and the stress vs. strain curve are shown\\nin Fig. 13b and c, respectively. The simulation time for a model was\\napproximately 7 h using 40 cores of CPUs (Intel Xeon Gold 6148).4.2. Analysis results\\nThe direct tension simulations were conducted for all the target\\nand reconstructed microstructures. The macroscale stress vs. strain re-\\nsponses of the microstructures are presented in Fig. 14. All 20 specimen\\nresponses for each target and reconstructed microstructures are shaded, Cement and Concrete Composites 152 (2024) 105646\\n10S.-W. Hong et al.\\nFig. 11. Lineal-path function for 3D microstructures. (a) Pore phase, (b) Outer product phase. ( 𝑟: line length, 𝐷: sample width)\\nFig. 12. Distributions of microstructural characteristics. (a) Porosity ( 𝜙𝑝), (b) Outer product phase continuity ( 𝓁𝐿𝑜). Cement and Concrete Composites 152 (2024) 105646\\n11S.-W. Hong et al.\\nFig. 13. Simulation setup and responses. (a) Boundary conditions, (b) Crack pattern, (c) Stress vs. strain response.\\nFig. 14. Stress vs. strain responses of target and reconstructed microstructures. (a) Target samples, (b) Reconstructed samples.\\nand their averages are plotted as a thick line. There are variations,\\nbut the response characteristics from both the target and reconstructed\\nmicrostructures are similar. The spread of responses, including the\\nstiffness and peak strength values, can be considered as the outcome\\nof uncertainties in the microstructures.\\nFig. 15 shows the crack patterns after failure for the cement paste\\nmicrostructures in Fig. 10. Because of the variations in microstructural\\nfeatures, the crack patterns are not identical. However, the crack\\npattern characteristics exhibit similarities, such as multiple crack for-\\nmations and crack propagation through the weakest solid phase (outer\\nproduct). The inner product volume fractions along the cracked sur-\\nfaces of the specimens shown in Fig. 15 range from 0.2% to 2.3%,\\nwith the exception of target sample 3 (8.1%). Thus, the outer product\\nvolume fractions on the crack surfaces were generally greater than\\n97% and the crack volume from the unhydrated phase on the crack\\nsurfaces was negligible. Thus, the cracks do not propagate into the\\nstronger phases but rather through the weaker/outer product phase.\\nThe cracks propagated around the stronger phases, as observed in\\nprevious studies [ 19–21,58].\\nThe distributions of stiffness and tensile strength of the target\\nand reconstructed microstructures are presented in Fig. 16. Consis-\\ntent with the porosity and phase continuity distributions, the stiffness\\nand strength distribution characteristics between the target and recon-\\nstructed microstructures are comparable. The average stiffness of the\\ntarget and reconstructed microstructures differs by less than 0.3%, and\\nthe difference in the average strength is less than 4%. The strength has\\na larger error compared to the stiffness because various crack patterns\\ncan occur due to the diverse local microstructural features. However,\\nconsidering that the standard deviation of the target microstructures is\\napproximately 23% relative to the average, it is reasonable to conclude\\nthat the strength of the reconstructed microstructures is also compara-\\nble to that of the target microstructures. The evaluated properties of\\nthe reconstructed microstructures are statistically identical to the target\\nmicrostructures.It is confirmed from the simulation results that reconstructed mi-\\ncrostructures using the proposed adapted CycleGAN approach have\\nmaterial properties similar to those of the target microstructures. Fur-\\nther, all the target and reconstructed microstructures were statistically\\nequivalent [ 10], which indicates that the material characteristics and\\nproperties can be considered the same within tolerance due to the\\nuncertainties inherent to materials with complex microstructures such\\nas cement paste. The reconstructed samples can be treated identi-\\ncally to the target/original microstructures. In this study, only one\\nmicrostructure was reconstructed from a target microstructure, but this\\nmethod can be used to reconstruct as many microstructures as needed.\\nTherefore, the number of real experiments can be reduced to obtain\\nmicrostructures and to evaluate material properties by supplementing\\nreal experiments with virtual experiments. This will reduce the time\\nand effort for material property evaluation, accelerating the develop-\\nment of new materials and increasing the reliability of the performance\\nevaluation of existing materials.\\n5. Summary and discussions\\nEvaluating material properties from real experiments, including\\ncementitious materials, requires considerable effort to develop new\\nmaterials and to evaluate the properties of existing materials. There-\\nfore, methods for supplementing time-consuming real experiments with\\nvirtual experiments have been investigated. However, the reconstruc-\\ntion of realistic microstructures for virtual experiments is a challenging\\nbecause of the complexity of microstructural features of cementitious\\nmaterials. In this study, an artificial-intelligence GAN-based approach\\nwas investigated for complex microstructure reconstruction, including\\nvanilla GAN [ 1] and SliceGAN models [ 27]. Such models were un-\\nable to reconstruct four-phase cement paste microstructures suitable\\nfor property evaluation through simulations; therefore, the CycleGAN\\nmodel [ 2] was extended to propose a reconstruction approach for Cement and Concrete Composites 152 (2024) 105646\\n12S.-W. Hong et al.\\nFig. 15. Examples of crack patterns. (a) Target microstructures, (b) Reconstructed microstructures. (Note: The crack volume from the unhydrated phase is negligible.)\\nvirtual multi-phase cement paste microstructures based on real mi-\\ncrostructures obtained from micro-CT measurements. The actual and\\nreconstructed microstructures from the proposed approach shared sim-\\nilar microstructural characteristics, and the evaluated properties were\\ncomparable, confirming the validity of the proposed framework. How-\\never, the 3D microstructure reconstruction of multi-phase random het-\\nerogeneous materials from 2D microstructural images using scanning\\nelectron microscopy or transmission electron microscopy is expected to\\nincrease the efficiency of the virtual material testing framework. These\\nefforts are planned for future studies.\\nThis study aimed to validate a mechanical property evaluation\\nframework using reconstructed multi-phase cement-paste microstruc-\\ntures. The next step is to calibrate and validate the simulation frame-\\nwork based on the mechanical properties of real experiments. Sub-\\nsequently, using the data pool from the calibrated analysis frame-\\nwork with deep-learning-generated virtual microstructures, data-driven\\nanalysis can be conducted to further confirm the applicability of the\\nframework.\\nThe proposed framework was validated using cement paste spec-\\nimens with a cement/water ratio of 0.4 after 28 days of hydration.\\nFurther confirmation of the robustness of the proposed framework\\nrequires additional studies using different cement/water ratios and\\ndegrees of hydration. Microstructure reconstruction of cement paste\\nunder different conditions can be performed by training the proposed\\nGAN model with the corresponding microstructures. In addition, the\\nproposed reconstruction framework uses a fixed-sized image input and\\nproduces the same output microstructures. To produce larger images\\nwith more pixels/voxels, the network must be modified, followed by\\ntraining. However, data preparation and possible model calibration\\nfor different conditions require considerable effort. Therefore, thesetasks are deferred to future studies. After validating the robustness\\nof the framework, it should be extended to reconstruct cement paste\\nmicrostructures with arbitrary microstructural features. This will help\\nestablish a correlation between the microstructural characteristics and\\nmaterial properties, resulting in an efficient and effective microstruc-\\ntural design that satisfies the performance requirements through the\\naccurate evaluation of material properties.\\nThe applicability of the framework ranges from experimental confir-\\nmation to the statistical data analysis of the evaluated properties. As an\\nexample of a statistical and probabilistic application, material property\\ndistribution can be identified using the Bayesian approach [ 64]. The\\nproperties evaluated using real experiments are generally expensive.\\nOwing to the uncertainties in microstructural features of cement paste,\\nmany microstructures are required to increase reliability. However,\\nstatistically equivalent virtual microstructures reconstructed from ex-\\nisting information can reduce the cost and effort required to obtain\\ncement paste microstructures from micro-CT measurements and to\\nevaluate their properties. After conducting a minimum number of\\nreal experiments (e.g., 10), simulations can be conducted to obtain\\nadditional property data from virtual specimens reconstructed using the\\nproposed framework. The property distributions are then updated using\\nthe simulated results, until adequate properties are obtained. These\\nstudies require significant efforts and will be considered in the future.\\n6. Conclusions\\nThis study proposed a method for reconstructing 3D multi-phase\\ncement paste microstructure using artificial intelligence. Based on the\\nCycleGAN algorithm, networks were modified to accommodate the\\nrequirements and constraints for the reconstruction process. A two-\\nstep process is proposed for efficient and effective reconstruction, in Cement and Concrete Composites 152 (2024) 105646\\n13S.-W. Hong et al.\\nFig. 16. Property distribution. (a) Stiffness, (b) Strength.\\nwhich three 2D sections (top, middle, bottom) of microstructures are\\nreconstructed first, followed by 3D microstructure reconstruction, fill-\\ning the gap between the sections. By comparing the microstructural\\ncharacteristics and properties between the target and reconstructed\\nmulti-phase cement paste microstructures, the following conclusions\\nare drawn:\\n•The microstructures reconstructed by the proposed artificial in-\\ntelligence based method could reproduce the multi-phase cement\\npaste target microstructures from micro-CT and had similar mi-\\ncrostructural characteristics, such as volume fractions and phase\\ncontinuities.\\n•The mechanical properties (stiffness and tensile strength) of the\\ntarget and reconstructed cement paste microstructures evaluated\\nusing the phase-field fracture model confirmed that the adapted\\nCycleGAN approach can generate the statically equivalent mi-\\ncrostructures within uncertainties inherent to the materials.\\n•Compared with conventional reconstruction approaches, the ar-\\ntificial intelligence based reconstruction method rendered the\\nvirtual generation of multi-phase materials with complex mi-\\ncrostructures. As the analysis framework is developed further, the\\nframework using the reconstructed microstructures should help\\nreduce the time and effort in conducting real experiments for\\nproperty evaluation of cementitious materials.\\nCRediT authorship contribution statement\\nSung-Wook Hong: Writing – review & editing, Visualization, Val-\\nidation, Methodology, Formal analysis, Data curation. Se-Yun Kim:Writing – review & editing, Visualization, Validation, Conceptualiza-\\ntion. Kyoungsoo Park: Writing – review & editing, Validation, Concep-\\ntualization. Kenjiro Terada: Validation, Conceptualization. Hoonhee\\nLee: Validation, Resources. Tong-Seok Han: Writing – review & edit-\\ning, Writing – original draft, Validation, Supervision, Methodology,\\nConceptualization.\\nDeclaration of competing interest\\nThe authors declare that they have no known competing finan-\\ncial interests or personal relationships that could have appeared to\\ninfluence the work reported in this paper.\\nData availability\\nData will be made available on request.\\nAcknowledgments\\nThis study was supported by the National Research Foundation\\nof Korea (NRF-2022R1A4A1033925, RS-2022-00144250, and RS-2024-\\n00352182). This research was also supported by the Technology In-\\nnovation Program (RS-2023-00264747, Development of manufacturing\\ntechnology for blended cement that replaces 15% or more of clinker\\nwith calcined clay) funded by the Ministry of Trade, Industry and\\nEnergy (MOTIE, Korea). This work was supported by International Joint\\nResearch Grant by Yonsei Graduate School, South Korea. The micro-\\nCT images were obtained using a synchrotron operated by the Pohang\\nAccelerator Laboratory (PAL) in the Republic of Korea. Cement and Concrete Composites 152 (2024) 105646\\n14S.-W. Hong et al.\\nTable A.1\\nDescriptions of layers and blocks.\\nTermaDescription\\nLayerConv2D Extracts features from the 2D-input data in a convolutional neural network (CNN) through downsampling.\\nReLU Provides nonlinearity to the neural network (activation function) [65].\\nMaxPool2D Extracts the maximum value within a predetermined region to summarize the information of a 2D feature map.\\nFlatten Flattens data into an array (1D vector).\\nDense Connects all neurons from the previous layer to all neurons in the next layer.\\nDropout Disables the operation of randomly selected neurons during the learning process to prevent overfitting.\\nReshape Changes the shape of the data array.\\nConv3D Extracts features from 3D-input data in a CNN through downsampling.\\nConv3DTranspose Extracts features from 3D-input data in a CNN through upsampling.\\nConcat Connects two sets of data with the same dimensionality to preserve the gradients that diminish as they go backward.\\nBlockConv2D block Conv2D - ReLU - Conv2D - ReLU - MaxPool2D\\nConv3D block Conv3D - ReLU - Conv3D - ReLU - Conv3D\\nFC block Dense - Dropout - ReLU\\naLayer name is expressed as the term provided by TensorFlow [59].\\nAppendix A. Algorithm of CycleGAN\\nA framework, Generative adversarial network (GAN) [1], is for\\nestimating generative models using the adversarial process. Here, only\\na brief summary of GAN is presented. The framework comprises two\\nmodels:𝐺(𝑧)and𝐷(𝑥).𝐺(𝑧)is a generator for reconstructing the data\\n(microstructure in this study) 𝑥from a noise variable 𝑧, i.e., a mapping\\n𝑥=𝐺(𝑧).𝐷(𝑥), a discriminator, is the probability of sampling data 𝑥\\nfrom the original data set, but not from the reconstructed data. In other\\nwords,𝐺generates or reconstructs data with characteristics similar to\\nthose of the original samples, and 𝐷estimates the probability that the\\ndata is from the original samples. 𝐷is trained to maximize the probabil-\\nity of identifying the correct source for training data and samples from\\n𝐺. At the same time, 𝐺is trained to minimize log(1−𝐷(𝐺(𝑧))). Then,\\nthe process becomes the optimization problem of the loss or objective\\nfunction \\ue238(𝐺,𝐷):\\nmin\\n𝐺max\\n𝐷\\ue238(𝐺,𝐷)=E𝑥∼𝑝data(𝑥)[log𝐷(𝑥)]+E𝑧∼𝑝𝑧(𝑧)[log(1−𝐷(𝐺(𝑧)))],\\n(A.1)\\nwhere the first term is the expected value of log𝐷(𝑥)when𝑥is sampled\\nfrom distribution of data 𝑥,𝑝data(𝑥), and the second term is the expected\\nvalue oflog(1−𝐷(𝐺(𝑧))). Two models are trained through an adversar-\\nial process by the interactions between the two models, through which\\nthe characteristics of the generated data sets become similar to those\\nof the original samples.\\nEnhanced from general GAN, cycle-consistent generative adversarial\\nnetworks (CycleGAN) [2] was proposed to reconstruct images more\\naccurately and efficiently. In CycleGAN, the log-likelihood objective\\nfrom general GAN, Eq. (A.1), is substituted by a least square loss [3] for\\nmore stability during training and generation of higher quality results.\\nAlso, cycle consistency loss terms are added to improve the image\\nquality by confirming that generated images can inversely generate\\ntarget images [4]. The algorithm of CycleGAN finds the solution of loss\\nor objective function:\\nmin\\n𝐺,𝐹max\\n𝐷𝑋,𝐷𝑌\\ue238(𝐺,𝐹,𝐷𝑋,𝐷𝑌)=\\ue238LSGAN(𝐺,𝐷𝑌,𝑋,𝑌)\\n+\\ue238LSGAN(𝐹,𝐷𝑋,𝑌,𝑋)+𝜆\\ue238cyc(𝐺,𝐹).\\n(A.2)\\nHere,𝐺∶𝑋→𝑌is the generator function that maps the domain 𝑋\\nto𝑌, and𝐷𝑌is its discriminator as in the general GAN. 𝐹∶𝑌→𝑋\\nis the inverse mapping function and 𝐷𝑋is its discriminator. On the\\nright-hand side, the first two terms represent the least square form of\\nloss functions replacing the logform in general GAN, and, for example,\\nthe first term takes the form,\\n\\ue238LSGAN(𝐺,𝐷𝑌,𝑋,𝑌)=E𝑦∼𝑝data(𝑦)[(𝐷𝑌(𝑦)−1)2]\\n+E𝑥∼𝑝data(𝑥)[(𝐷𝑌(𝐺(𝑥)))2]. (A.3)The last term in the loss function of CycleGAN (Eq. (A.2)) is to enforce\\nthe cyclic consistency with the parameter 𝜆for controlling the relative\\nimportance of the term and can be expressed as\\n\\ue238cyc(𝐺,𝐹)=E𝑥∼𝑝data(𝑥)[‖𝐹(𝐺(𝑥))−𝑥‖1]+E𝑦∼𝑝data(𝑦)[‖𝐺(𝐹(𝑦))−𝑦‖1],\\n(A.4)\\nwhere‖⋅‖1is the L1 norm.\\nAppendix B. 3D generator\\nThe details of the proposed 3D generator, which uses three 2D\\nimages to reconstruct a 3D microstructure in the adapted CycleGAN,\\nare presented. The 2D generator is generally used to reconstruct the\\n2D image and is generally used in CycleGAN. However, in this study,\\nwe propose a 3D generator designed to reconstruct 3D microstructures\\nusing 2D images as an extension of the framework provided by Tensor-\\nFlow [59]. The basic structure of the 3D generator is the same as the\\n2D generator used in CycleGAN, using an autoencoder [66] consisting\\nof a convolution (encoder) and a transposed convolution (decoder).\\nThe 2D generator uses an encoder to compress a 2D image into a 2D\\nfeature map, which results from convolutional operation and contains\\ninformation on the image features. The 2D feature map is then decoded\\nand reconstructed into a 2D image by a decoder. In contrast to the\\n2D generator, the 3D generator’s decoder process involves using a 3D\\nfeature map, which is constructed from the encoded 2D feature map.\\nThe encoder and decoder process is shown in Fig. A.1a. Descriptions\\nof all the used layers, as termed in TensorFlow, and the blocks (a set\\nof layers) are shown in Table A.1. The 3D generator is based on an\\nautoencoder structure in CycleGAN. It uses two types of connections\\n(Connections A and B) as in Ref. [5] to convert the different dimensions\\nof feature maps in the encoder and decoder.\\nConnection A\\nIn the encoding process, three 2D images are used as inputs and con-\\nverted into a 2D feature map through a 2D convolution block (Conv2D\\nblock) consisting of five layers in Fig. A.1a. This 2D feature map is\\nfurther encoded through additional Conv2D blocks and converted to a\\n3D feature map connected to the decoder (Connection A). Connection\\nA involves a series of steps: (1) flattening the 2D feature map into a 1D\\nvector; (2) applying a fully connected block (FC block); (3) reshaping\\nthis 1D vector into a 3D feature map; and (4) finally performing 3D\\nconvolution (Conv3D) and ReLU operations, as illustrated in Fig. A.1b.\\nThrough Connection A, the 2D feature map at the last output of the\\nencoder is converted into a 3D feature map, which is then employed\\nin the decoder to reconstruct the 3D microstructure via transposed\\nconvolution. Cement and Concrete Composites 152 (2024) 105646\\n15S.-W. Hong et al.\\nFig. A.1. 3D Generator model for 2D to 3D microstructure reconstruction incorporating two types of connections between encoder and decoder. (a) A schematic of the 3D\\ngenerator, (b) Connection A, bridging the encoder and the decoder by a fully connected layer, (c) Connection B adding the information from the 2D to 3D feature maps. (Note:\\n‘n’ is the size (height, length, and width) of the 2D or 3D feature, and ‘m’ is the number of channels, i.e., the quantity of 2D or 3D features. Indicated numbers in feature maps\\nare the actual dimension sizes used in this study.)\\nConnection B\\nIn CycleGAN, the transposed convolution is the process of decoding\\nthe feature map. However, because some information cannot be incor-\\nporated into the feature map during the encoding process, additional\\ninformation is provided during the decoding via the ‘‘concatenation’’\\nprocess to obtain better reconstructed microstructures. The concatena-\\ntion is performed by adding the feature map of the ‘‘encoder’’ to that of\\nthe ‘‘decoder’’ to compensate for the information lost during the encod-\\ning process. The concatenation is generally the process of combining\\nfeature maps in 2D. However, in the proposed 3D generator, the 2D\\nfeature map of the encoder and the 3D feature map of the decoder\\nare combined using Connection B shown in Fig. A.1c. Connection B\\nis designed so that the 2D feature map of the encoder has the same\\ndimensions as the 3D feature map. The 2D feature map is converted to\\nthe 3D format by a convolution process involving layers using Conv2D\\nand Conv3D. This converted feature map is then concatenated with\\nthe 3D feature map, which is passed through the Conv3DTranspose\\nand ReLU layers in the decoder. The 3D feature map generated by\\nthe concatenation is used as an input for the next step of the decoder.\\nThis process is repeated until the size of the 3D feature map is equal\\nto the size of the 3D microstructure to be reconstructed. Once the\\n3D feature map becomes the intended size, the 3D convolution block\\n(Conv3D block) comprising five layers converts the feature map into a\\n3D microstructure.References\\n[1] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A.\\nCourville, Y. Bengio, Generative adversarial nets, in: Z. Ghahramani, M. Welling,\\nC. Cortes, N. Lawrence, K. Weinberger (Eds.), Advances in Neural Information\\nProcessing Systems, Vol. 27, Curran Associates, Inc., 2014.\\n[2] J.-Y. Zhu, T. Park, P. Isola, A.A. Efros, Unpaired image-to-image translation using\\ncycle-consistent adversarial networks, in: Proceedings of the IEEE International\\nConference on Computer Vision, ICCV, 2017.\\n[3] X. Mao, Q. Li, H. Xie, R.Y. Lau, Z. Wang, S. Paul Smolley, Least squares gener-\\native adversarial networks, in: Proceedings of the IEEE International Conference\\non Computer Vision, ICCV, 2017.\\n[4] M. Zhang, Pore-scale modelling of relative permeability of cementitious materi-\\nalsusing X-ray computed microtomography images, Cem. Concr. Res. 95 (2017)\\n18–29.\\n[5] X. Ying, H. Guo, K. Ma, J. Wu, Z. Weng, Y. Zheng, X2CT-GAN: Reconstructing\\nCT from biplanar X-Rays with generative adversarial networks, in: Proceedings\\nof the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR,\\n2019.\\n[6] C.L.Y. Yeong, S. Torquato, Reconstructing random media, Phys. Rev. E 57 (1998)\\n495–506.\\n[7] C.L.Y. Yeong, S. Torquato, Reconstructing random media. II. Three-dimensional\\nmedia from two-dimensional cuts, Phys. Rev. E 58 (1998) 224–233.\\n[8] D. Cule, S. Torquato, Generating random media from limited microstructural\\ninformation via stochastic optimization, J. Appl. Phys. 86 (1999) 3428–3437.\\n[9] C. Manwart, S. Torquato, R. Hilfer, Stochastic reconstruction of sandstones, Phys.\\nRev. E 62 (2000) 893–899.\\n[10] S. Torquato, Random Heterogeneous Materials:Microstructure and Macroscopic\\nProperties, Springer-Verlag, 2002.\\n[11] S.-Y. Chung, T.-S. Han, S.-Y. Kim, T.-H. Lee, Investigation of the permeability\\nof porous concrete reconstructed using probabilistic description methods, Constr.\\nBuild. Mater. 66 (2014) 760–770. Cement and Concrete Composites 152 (2024) 105646\\n16S.-W. Hong et al.\\n[12] S.-Y. Chung, T.-S. Han, S.-Y. Kim, Reconstruction and evaluation of the air\\npermeability of a cement paste specimen with a void distribution gradient using\\nCT images and numerical methods, Constr. Build. Mater. 87 (2015) 45–53.\\n[13] S.-Y. Kim, J.-S. Kim, J.W. Kang, T.-S. Han, Construction of virtual interfacial\\ntransition zone (ITZ) samples of hydrated cement paste using extended stochastic\\noptimization, Cem. Concr. Compos. 102 (2019) 84–93.\\n[14] J.-S. Kim, S.-Y. Kim, T.-S. Han, Sensitivity and uncertainty estimation of cement\\npaste properties to microstructural characteristics using FOSM method, Constr.\\nBuild. Mater. 242 (2020) 118159.\\n[15] M. Luković, E. Schlangen, G. Ye, Combined experimental and numerical study of\\nfracture behavior of cement paste at the microlevel, Cem. Concr. Res. 73 (2015)\\n123–135.\\n[16] H. Zhang, B. Šavija, E. Schlangen, Size effect on splitting strength of hardened\\ncement paste: Experimental and numerical study, Cem. Concr. Compos. 94 (2018)\\n264–276.\\n[17] H. Zhang, B. Šavija, M. Luković, E. Schlangen, Experimentally informed mi-\\ncromechanical modelling of cement paste: An approach coupling X-ray computed\\ntomography and statistical nanoindentation, Composites B 157 (2019) 109–122.\\n[18] H. Zhang, Y. Xu, Y. Gan, Z. Chang, E. Schlangen, B. Šavija, Combined experi-\\nmental and numerical study of uniaxial compression failure of hardened cement\\npaste at micrometre length scale, Cem. Concr. Res. 126 (2019) 105925.\\n[19] J.-S. Kim, J.-H. Lim, D. Stephan, K. Park, T.-S. Han, Mechanical behavior\\ncomparison of single and multiple phase models for cement paste using micro-CT\\nimages and nanoindentation, Constr. Build. Mater. 342 (2022) 127938.\\n[20] T.-S. Han, D. Eum, S.-Y. Kim, J.-S. Kim, J.-H. Lim, K. Park, D. Stephan,\\nMulti-scale analysis framework for predicting tensile strength of cement paste\\nby combining experiments and simulations, Cem. Concr. Compos. 139 (2023)\\n105006.\\n[21] S.-Y. Kim, D. Eum, H. Lee, K. Park, K. Terada, T.-S. Han, Evaluating tensile\\nstrength of cement paste using multiscale modeling and in-situ splitting tests\\nwith micro-CT, Constr. Build. Mater. 411 (2024) 134642.\\n[22] X. Li, Y. Zhang, H. Zhao, C. Burkhart, L.C. Brinson, W. Chen, A transfer learning\\napproach for microstructure reconstruction and structure-property predictions,\\nSci. Rep. 8 (2018) 13462.\\n[23] R. Bostanabad, Reconstruction of 3D microstructures from 2D images via transfer\\nlearning, Comput. Aided Des. 128 (2020) 102906.\\n[24] P. Seibert, A. Raßloff, K.A. Kalina, J. Gussone, K. Bugelnig, M. Diehl, M. Kästner,\\nTwo-stage 2D-to-3D reconstruction of realistic microstructures: Implementation\\nand numerical validation by effective properties, Comput. Methods Appl. Mech.\\nEngrg. 412 (2023) 116098.\\n[25] J. Fu, D. Xiao, D. Lib, H.R. Thomas, C. Li, Stochastic reconstruction of 3D\\nmicrostructures from 2D cross-sectional images using machine learning-based\\ncharacterization, Comput. Methods Appl. Mech. Engrg. 390 (2022) 114532.\\n[26] J. Feng, Q. Teng, B. Lic, X. He, H. Chen, Y. Li, An end-to-end three-dimensional\\nreconstruction framework of porous media from a single two-dimensional image\\nbased on deep learning, Comput. Methods Appl. Mech. Engrg. 368 (2020)\\n113043.\\n[27] S. Kench, I. Squires, A. Dahari, S. Cooper, MicroLib: A library of 3D mi-\\ncrostructures generated from 2D micrographs using SliceGAN, Sci. Data 9 (2022)\\n645.\\n[28] E. Kononov, M. Tashkinov, V. Silberschmidt, Reconstruction of 3D random media\\nfrom 2D images: Generative adversarial learning approach, Comput. Aided Des.\\n158 (2023) 103498.\\n[29] Y. Dong, P. Qiao, CT image-based synthetic mesostructure generation for\\nmultiscale fracture analysis of concrete, Constr. Build. Mater. 296 (2021) 123582.\\n[30] J. Lin, S. Chen, W. Wang, C. Pathirage, L. Li, K. Sagoe-Crentsil, W. Duan,\\nTransregional spatial correlation revealed by deep learning and implications for\\nmaterial characterisation and reconstruction, Mater. Charact. 178 (2021) 111268.\\n[31] Y. Huang, Z. Xiang, M. Qian, Deep-learning-based porous media microstructure\\nquantitative characterization and reconstruction method, Phys. Rev. E 105 (2022)\\n015308.\\n[32] T. Zhang, M. Ni, Q. Guan, D. Li, S. Zhou, Y. Du, Reconstruction of three-\\ndimensional porous media using multi-scale generative adversarial networks, J.\\nAppl. Geophys. 213 (2023) 105042.\\n[33] J. Guo, C.L.P. Chen, L. Wang, B. Yang, T. Zhang, L. Zhang, Constructing\\nmicrostructural evolution system for cement hydration from observed data using\\ndeep learning, IEEE Trans. Syst. Man Cybern. Syst. 53 (7) (2023) 4576–4589.\\n[34] D.P. Kingma, M. Welling, Auto-encoding variational Bayes, 2013, arXiv:1312.\\n6114.\\n[35] S. Noguchi, J. Inoue, Stochastic characterization and reconstruction of material\\nmicrostructures for establishment of process-structure-property linkage using the\\ndeep generative model, Phys. Rev. E 104 (2021) 025302.\\n[36] L. Xu, N. Hoffman, Z. Wang, H. Xu, Harnessing structural stochasticity in the\\ncomputational discovery and design of microstructures, Mater. Des. 223 (2022)\\n111223.\\n[37] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, S. Ganguli, Deep unsupervised\\nlearning using nonequilibrium thermodynamics, in: F. Bach, D. Blei (Eds.),\\nProceedings of the 32nd International Conference on Machine Learning, in:\\nProceedings of Machine Learning Research, vol. 37, PMLR, Lille, France, 2015,\\npp. 2256–2265.[38] C. Düreth, P. Seibert, D. Rücker, S. Handford, M. Kästner, M. Gude, Conditional\\ndiffusion-based microstructure reconstruction, Mater. Today Commun. 35 (2023)\\n105608.\\n[39] K.-H. Lee, H.J. Lim, G.J. Yun, A data-driven framework for designing microstruc-\\nture of multifunctional composites with deep-learned diffusion-based generative\\nmodels, Eng. Appl. Artif. Intell. 129 (2024) 107590.\\n[40] P. Monteiro, G. Geng, D. Marchon, J. Li, P. Alapati, K. Kurtis, M. Qomi, Advances\\nin characterizing and understanding the microstructure of cementitious materials,\\nCem. Concr. Res. 124 (2019) 105806.\\n[41] S.-Y. Chung, J.-S. Kim, D. Stephan, T.-S. Han, Overview of the use of micro-\\ncomputed tomography (micro-CT) to investigate the relation between the\\nmaterial characteristics and properties of cement-based materials, Constr. Build.\\nMater. 229 (2019) 116843.\\n[42] S. Brisard, M. Serdar, P. Monteiro, Multiscale X-ray tomography of cementitious\\nmaterials: A review, Cem. Concr. Res. 128 (2020) 105824.\\n[43] H. Zhang, Y. Gan, Z. Chang, E. Schlangen, B. Šavija, Microstructure informed mi-\\ncromechanical modelling of hydrated cement paste: Techniques and challenges,\\nConstr. Build. Mater. 251 (2020) 118983.\\n[44] M. Zhang, A. Jivkov, Micromechanical modelling of deformation and fracture\\nof hydrating cement paste using X-ray computed tomography characterisation,\\nComposites B 88 (2016) 64–72.\\n[45] J. Huang, K. Krabbenhoft, A. Lyamin, Statistical homogenization of elastic\\nproperties of cement paste based on X-ray microtomography images, Int. J. Solids\\nStruct. 50 (2013) 699–709.\\n[46] M. Hain, P. Wriggers, Numerical homogenization of hardened cement paste,\\nComput. Mech. 42 (2008) 197–212.\\n[47] T. Wu, İ. Temizer, P. Wriggers, Computational thermal homogenization of\\nconcrete, Cem. Concr. Compos. 35 (2013) 59–70.\\n[48] T. Nguyen, A. Ghazlan, A. Kashani, S. Bordas, T. Ngo, 3D meso-scale modelling\\nof foamed concrete based on X-ray computed tomography, Constr. Build. Mater.\\n188 (2018) 583–598.\\n[49] C. Miehe, M. Hofacker, F. Welschinger, A phase field model for rate-independent\\ncrack propagation: Robust algorithmic implementation based on operator splits,\\nComput. Methods Appl. Mech. Engrg. 199 (2010) 2765–2778.\\n[50] C. Miehe, L.-M. Schänzel, H. Ulmer, Phase field modeling of fracture in multi-\\nphysics problems. Part I: Balance of crack surface and failure criteria for brittle\\ncrack propagation in thermo-elastic solids, Comput. Methods Appl. Mech. Engrg.\\n294 (2015) 449–485.\\n[51] J.-S. Kim, J. Suh, J. Pae, J. Moon, T.-S. Han, Gradient-based phase segmentation\\nmethod for characterization of hydrating cement paste microstructures obtained\\nfrom X-ray micro-CT, J. Build. Eng. 46 (2022) 103721.\\n[52] J. Němeček, J. Lukeš, J. Němeček, High-speed mechanical mapping of blended\\ncement pastes and its comparison with standard modes of nanoindentation,\\nMater. Today Commun. 23 (2020) 100806.\\n[53] B. Cullity, S. Stock, Elements of X-ray Diffraction, Prentice Hall, 2001.\\n[54] T.-S. Han, X. Zhang, J.-S. Kim, S.-Y. Chung, J.-H. Lim, C. Linder, Area of linal-\\npath function for describing the pore microstructures of cement paste and their\\nrelations to the mechanical properties simulated from 𝜇-CT microstructures, Cem.\\nConcr. Compos. 89 (2018) 1–17.\\n[55] J.-S. Kim, J. Kim, T.-S. Han, Microstructure characterization of cement paste from\\nmicro-CT and correlations with mechanical properties evaluated from virtual and\\nreal experiments, Mater. Charact. 155 (2019) 109807.\\n[56] J.-S. Kim, S.-Y. Chung, D. Stephan, T.-S. Han, Issues on characterization of\\ncement paste microstructures from 𝜇-CT and virtual experiment framework for\\nevaluating mechanical properties, Constr. Build. Mater. 202 (2019) 82–102.\\n[57] J.-S. Kim, S.-Y. Chung, T.-S. Han, D. Stephan, M. Elrahman, Correlation between\\nmicrostructural characteristics from micro-CT of foamed concrete and mechanical\\nbehaviors evaluated by experiments and simulations, Cem. Concr. Compos. 112\\n(2020) 103657.\\n[58] J.-S. Kim, S.-Y. Chung, T.-S. Han, D. Stephan, M. Elrahman, Modeling of multiple\\nphase solid microstructures and prediction of mechanical behaviors of foamed\\nconcrete, Constr. Build. Mater. 248 (2020) 118637.\\n[59] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G.S. Corrado, A.\\nDavis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Is-\\nard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Mane, R. Monga,\\nS. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever,\\nK. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viegas, O. Vinyals, P.\\nWarden, M. Wattenberg, M. Wicke, Y. Yu, X. Zheng, Tensorflow: Large-scale\\nmachine learning on heterogeneous distributed systems, 2015, Software available\\nfrom tensorflow.org.\\n[60] I. Gitman, H. Askes, L. Sluys, Representative volume: existence and size\\ndetermination, Eng. Fract. Mech. 74 (2007) 2514–2534.\\n[61] Y. LeCun, B. Boser, J. Denker, D. Henderson, R. Howard, W. Hubbard, L. Jackel,\\nHandwritten digit recognition with a back-propagation network, Adv. Neural Inf.\\nProcess. Syst. 2 (1989) 396–404.\\n[62] P. Isola, J.-Y. Zhu, T. Zhou, A.A. Efros, Image-to-image translation with condi-\\ntional adversarial networks, in: Proceedings of the IEEE Conference on Computer\\nVision and Pattern Recognition, 2017, pp. 1125–1134. Cement and Concrete Composites 152 (2024) 105646\\n17S.-W. Hong et al.\\n[63] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, S. Hochreiter, GANs trained\\nby a two time-scale update rule converge to a local Nash equilibrium, in:\\nAdvances in Neural Information Processing Systems, Vol. 30, Curran Associates,\\nInc., 2017.\\n[64] A. Ang, W. Tang, Probability Concepts in Engineering: Emphasis on Applications\\nto Civil and Environmental Engineering, second ed., Wiley, 2006.[65] V. Nair, G.E. Hinton, Rectified linear units improve restricted boltzmann\\nmachines, in: Proceedings of the 27th International Conference on Machine\\nLearning, ICML-10, 2010, pp. 807–814.\\n[66] J. Masci, U. Meier, D. Cireşan, J. Schmidhuber, Stacked convolutional auto-\\nencoders for hierarchical feature extraction, in: Artificial Neural Networks and\\nMachine Learning–ICANN 2011: 21st International Conference on Artificial\\nNeural Networks, Espoo, Finland, Springer, 2011, pp. 52–59.',\n",
       "  \" \\n \\n \\nChowdhury, G. (2003) Natural language processing. Annual Review of \\nInformation Science and Technology, 37. pp. 51-89. ISSN 0066-4200 \\n \\n \\n \\nhttp://eprints.cdlr.strath.ac.uk/2611/\\n \\n \\n \\nThis is an author-produced versio n of a paper published in The \\nAnnual Review of Information Science and Technology  ISSN 0066-4200 . \\nThis version has been peer-reviewed, but does not include the \\nfinal publisher proof corrections, published layout, or pagination. \\n \\nStrathprints is designed to allow users to access the research \\noutput of the University of St rathclyde. Copyright © and Moral \\nRights for the papers on this site are retained by the individual \\nauthors and/or other copyright  owners. Users may download \\nand/or print one copy of any articl e(s) in Strathprints to facilitate \\ntheir private study or for non-co mmercial research. You may not \\nengage in further distribution of th e material or use it for any \\nprofitmaking activities or any commercial gain. You may freely \\ndistribute the url ( http://eprints.cdlr.strath.ac.uk) of the Strathprints \\nwebsite. \\n \\nAny correspondence concerning this service should be sent to The \\nStrathprints Administrator: eprints@cis.strath.ac.uk  \\n  Natural Language Processing \\n \\nGobinda G. Chowdhury \\n   Dept . of Computer and Information Sci ences \\n   University  of Strathcly de, Gla sgow G1 1XH, UK \\n    e-m ail: gobinda@di s.strath.ac.uk \\n \\nIntroductio n \\n \\nNatural Language Processi ng (NLP) is an area of research and appl ication that explores how \\ncomputers can be used to understand and manipulat e natural language text or speech to do useful \\nthings. NLP  researchers aim to gather knowledge on  how hum an beings  understand and use \\nlanguage so t hat  appropria te  tools and t echni ques can be develope d to m ake co mputer sy stems \\nunderstand an d manipulate natural langu ages to perform  the desired  tasks.  The foundations of \\nNLP lie in a num ber of disciplines, viz. co mputer and inform ation sciences,  linguistics, \\nmathematics,  electrical and electronic engi neering, ar tificial intelligence and robotics, \\npsychology, etc.   Applications of NLP i nclude  a number of fields of studies, such as machine \\ntranslation, natural language text processing a nd summarization, user interfaces,  multilingual and \\ncross language information retrieval (CL IR), speech  recognition, artificial intelligence and expert \\nsystems, and so on. \\n \\nOne im portant area of  application of NLP that is  relatively new and has not been covered in th e \\nprevious ARIST chapters on NLP has beco me quite prom inent  due to the prolifer ation of the \\nworld wide web and digital  libraries. Several research ers have pointed out the need for \\nappropriate research in faci litating m ulti- or cross-lingual inform ation  retrieval,  including \\nmultilingual text processing and m ultilingual user int erface sy stems,  in order t o exploit the full \\nbenefit of the www and digital libraries ( see for ex ample, Borgm an, 1997; Peters & Picchi, 1997) \\n \\nScope \\nSeveral ARIS T chapters ha ve reviewed t he field of NLP. The m ost recent ones include that by \\nWarner  in 1987, and Haas  in 1996.  Reviews of literature on large-scale NLP sy stem s, as well as \\nthe various theoretical is sues have also a ppeared  in a num ber of publications (see for exam ple, \\nJurafsky  &  Martin, 200 0; Manning & Schutze, 199 9; Mani & May bury, 1999; Sparck Jones, \\n1999;  Wilks, 1996).   Smeaton (19 99) provides  a good  overview of t he past research on the \\napplications o f NLP in various inform ation re trieval tasks. Several ARIST chapt ers have \\nappeared  on areas related to NLP, such as on  machine-readable dictionaries (Amsler, 1984; \\n 1 Evans, 1989), speech sy nthesis and reco gnition (Lange, 1993), and cross-language information \\nretrieval (Oar d & Dieke ma, 1998). Research on NLP is regularly  published in a number of \\nconferences such as the annual proceedings of AC L (Association of Com putatio nal Linguistic s) \\nand its European counterpart EACL, biennial pr oceedings of the  I nternational Conference on \\nComputational Linguistics (COLING),  annual proceedings of t he Message Understanding \\nConferences ( MUCs), Text Retrieval Conference s (TR ECs) and AC M-SIGIR (As sociation of \\nComputing Machinery  – Special Interest Group on  Inform ation Retrieval) conferences. The m ost \\nprom inent journals reporting NLP resea rch are Comp utational Linguistics  and Natural Lan guage \\nEngineering . Articles r eporting NLP research also  appear in a num ber of inform ation science  \\njournals such as Information Processing and Management, J ournal  of the American Society for \\nInformation Science and Technology, and Journal of Documentation. Several resear chers have \\nalso conducted dom ain-specific NLP stu dies and have reported them  in journals specifically  \\ndealing with the dom ain co ncerned, such as the International  Journ al of M edical Informatics  and  \\nJournal of Ch emical Information a nd C omputer Science . \\n \\nBeginning wi th the basic issues of NLP, this chapte r aims to chart the major research activities in \\nthis area sinc e the last ARI ST  Chapter in 1996 (Haas, 1996), including:  \\n(i) natural language text processing sy stems – te xt summariz ation, information extraction, \\ninform ation retrieval, etc., includi ng domain-specific applications; \\n(ii) natural language interfaces; \\n(iii) NLP in the context of www a nd digital libraries ; and \\n(iv) evaluation of NLP sy stems.  \\n \\nLinguistic research in  infor mation retrieval has not  been covered in this review, since this is a \\nhuge area and has been dealt with separately  in this v olume by  Davi d Blair. Sim ilarly, NLP iss ues \\nrelated to the inform ation retrieval tools (sear ch engines, etc.) for w eb search ar e not covered in \\nthis chapter since a separ ate chapter on indexing and r etrieval for the Web has been written in t his \\nvolum e by   Edie Rasm ussen.  \\n  \\nTools and techniques developed for building NLP systems have be en discussed in this chapter \\nalong with t he specific areas of applications for whic h the y have been built.  Alt hough m achine \\ntranslation (MT) is an important part, a nd in f act the origin, of NLP resear ch, this paper does not \\ncover this topic with sufficient detail since this  is a huge area and demands a sepa rate chapter on \\nits own. Sim ilarly, cross-language infor mation re trieval (CLIR), althoug h  is  a very important \\n 2 and big area in NLP resear ch, is not covered in great detail in this chapter . A se parate chapte r on \\nCLIR res earch appeared in ARIST (Oar d & Di ekema, 199 8). How ever, MT and CLIR have \\nbeco me two i mportant are as of resear ch in the context of the www digital libraries. This chapter \\nreviews so me works on M T and CLIR in the context of  NLP and I R  in digi tal libraries and \\nwww.  Artifi cial Intelligence techniques,  including ne ural networks etc., used in NLP have not  \\nbeen included in this chapte r. \\n \\nSome Theor etical Develo pments \\nPrevious ARIST chapters (Haas, 1996; Warner, 1987) described a num ber of theoretical \\ndevelopm ents that have influenced resear ch in NLP. The m ost recent theoretical developments \\ncan be grouped into four classes: (i) stat istical  and corpus-based methods in NL P, (ii) recent  \\nefforts to use WordNet  for NLP r esearch, (iii) the resurgence of inte rest in finite-state and other \\ncomputationally lean approaches to NLP , and (iv)   the initiation of collaborative projects to create \\nlarge grammar and NLP tools. Statistical methods are used in NLP for a num ber of purposes, e.g., \\nfor word sense disam biguation,  f or gene rating gr ammars and parsing, fo r determ ining st ylistic \\nevidences of authors and s peakers, and so on. Ch arniak (1995)  points out t hat 90% accuracy  can \\nbe obtained in assigning part-of-speech tag to a wo rd by applying s imple statistic al measures. \\nJelinek (1999 ) is a widely  cited source on the use of statistical meth ods in NLP, e specially  in \\nspeech processing. Rosenfield (2000) reviews st atisti cal language m odels for speech processi ng \\nand argues for a Bay esian approach to the integr ation of linguistic theories of data. Mihalcea & \\nMoldovan  (1999) m ention that althou gh thus far st atistical approaches have been considered the \\nbest for word sense disa mbiguation, they are useful  only in a sm all set of texts. Th ey propose th e \\nuse of WordNet  to im prove the results of statis tical analy ses of nat ural language texts. WordNet \\nis an online le xical referenc e system  developed at  Princeton University. This is an excellent NL P \\ntool containi ng English nouns, verbs, adj ectiv es and a dverbs organized into s ynony m sets, each \\nrepresenting one underl ying lexical concept. Details  of WordNet is available in Fellbau m (1998) \\nand on t he web (http://www.cogsci.princeton.edu/~wn/ ). WordNet is now used i n a num ber of \\nNLP rese arch and applications. One of the major applications of WordNet in NLP has been in \\nEurope with t he formation EuroWordNet in 19 96.  EuroWordNet is a multilingua l database wit h \\nWordNets for several European languag es  includi ng Dutch, Italian, Spanish, Germ an, French, \\nCzech and Es tonian,  structured in the same w ay as the WordNet for English \\n(http://www.hum.uva.nl/~ewn/ ).  The finite-state aut omation is  the mathematical device used to \\nimplement re gular expressions –  the standard  notation for characte rizing text sequences. \\nVariations of automata such as finite-state transducers, Hidden Markov M odels, and n-gram  \\n 3 grammars ar e important co mponents of speech r ecog nition and speech sy nthesis, spell-check ing, \\nand inform ation extraction which are the im portant ap plications of NLP. Different application s of \\nthe Finite State methods in NLP have been discu ssed by  Jurafsky  & Martin (2000), Kornai ( 1999) \\nand Roche & Shabes (1997 ). The work o f NLP rese archers has been  greatly  facili tated b y the \\navailability  of large-scal e grammar for parsi ng and ge neration. Researcher s can get access to \\nlarge-scale grammars and tools thro ugh several websites, for example Lingo \\n(http://lingo.s tanford.edu), Computational Linguistics & Phonetics (http://www.coli.uni-\\nsb.de/software.phtm l), and Parallel grammar project \\n(http://www.parc.xerox.com/istl/groups/nltt/pargram /). Another significant developm ent in recent \\nyears is the for mation of various national and inte rnational consortia and r esear ch groups that can \\nfacilitate, and  help share expertise, research  in NLP. L DC (Linguistic Data Consortium ) \\n(http://www.ldc.upenn.edu/) at the University  of Pe nnsy lvania is a typical exa mple that  create s, \\ncollects and distributes speech and text database s, lexicons, and other resources f or research a nd \\ndevelopm ent among univer sities, co mpanies and gove rnment research laboratories. The Parallel \\nGrammar pro ject is another exam ple of internati onal cooperation. T his  is a collaborative effort \\ninvolv ing res earchers fro m Xerox PARC in Califor nia, the University of St uttgar t and the \\nUniversity  of Konstanz in Germany , the Univer sity of Bergen in Norway , Fuji Xerox in Japan. \\nThe aim  of this project  is to prod uce wide coverage grammars for English, Fren ch, Germ an, \\nNorwegian, Japanese, and Urdu which are writte n collaboratively with a co mmonl y-agreed-upon \\nset of grammatical features (http://www.parc.x erox.com/istl/groups/nltt/pargram /). The recently \\nformed Global WordNet Association is y et another exam ple of cooperation. It i s a   non-\\ncommercial o rganization th at provides a platform  for discussing, sharing and con necting \\nWordNets for all languages in the world.  The first international Wor dNet conference to be held  in \\nIndia in earl y 2002 is expected to address various  problem s of NLP by researcher s from different \\nparts of the world. \\n \\nNatural Language Understanding  \\n \\nAt the core of any  NLP task there is the im portant issue of natural language understanding.  The \\nprocess of building com puter programs that unde rstand natural language involves three major  \\nproblem s: the first one relates to the t hought  process, the second one t o the representatio n and \\nmeaning of the linguistic input, and the  third one  to the world knowledge. Thus, an NLP sy stem  \\nmay begin at the word level – to determine the morpholo gical structure, nature (such as part-of-\\nspeech, mean ing) etc. of t he word – an d then may move on to the sentence level – to determ ine \\n 4 the word order, gra mmar, meaning of the entire sentence, etc.— a nd then to the context and the  \\noverall envir onment or domain. A giv en word or a  sentence may have a specific meaning or \\nconnotation in a given co ntext or dom ain, and may be related to many  other words and/or \\nsentences in t he given context.  \\n \\nLidd y (1998) and Feldm an (1999) su ggest that in  orde r to un derstand natural lang uages, it is \\nimportant to be able to dist inguish am ong the fo llowi ng seven inte rdependent levels, that peo ple \\nuse to extract meaning from  text or spo ken language s:  \\n• phonetic or phonol ogical l evel that deals with pronu nciation \\n• morphological level that deals with the smallest  parts of words, that  carry  a meaning, and  \\nsuffixes and prefixes  \\n• lexical level that deals with lexical meaning of words and parts of speech analy ses \\n• syntactic level that deals with grammar a nd structure of sentences  \\n• semantic leve l that  deals with the m eaning of words and sentences \\n• discourse level that deals with the structure of different kin ds of te xt using docu ment \\nstructures and  \\n• pragmatic lev el that deals with the knowledge  that comes fro m the outside world, i.e., \\nfrom  outside the contents o f the docum ent.  \\n \\nA natural language processing s ystem  may involve  all or some of these levels of analy sis.  \\n \\n \\nNLP Tools and Techniqu es \\nA num ber of researchers h ave attem pted to co me up with im proved technology  for perform ing \\nvarious activities that for m important parts of  NLP works. These works may  be c ategorized as \\nfollows:  \\n  \\n• Lexical and m orphological analy sis,  noun phrase generation, word segmentation, etc. \\n(Bangalore & Joshi, 1999; Barker & Cor nacchia,2000;  Chen & Chang, 1998;  Dogru & \\nSlagle, 1999; Kam -Fai et al .. 1998; Kazakov et al.. , 1999; L ovis et al.. 1998; Tol le &  \\nChen, 200 0; Zweigenbaum  & Grabar, 1999)  \\n \\n 5 • Semantic and  discourse analy sis, word meaning and knowledge representation (Kehler, \\n1997;  Mihalcea & Moldovan,1999; Me yer & Dal e, 1999; Pedersen & Bruce, 1998; \\nPoesio & Vieira,1998; Tsu da & Nakamura, 199 9)  \\n \\n• Knowledge-based approaches and tools for NLP (Argam on et al.., 1998;  Fernandez &  \\nGarcia-Serrano, 2000;   Martinez et al.., 2000, 1998).  \\n \\nDogru & Slagle (1999) pr opose a m odel of lexi con t hat involves automatic acquisition of t he \\nwords as well as representation of the semantic content of in dividual lexical entries. Kazakov et \\nal.. (1999) report  research  on word segmentation based on an automatically  generated annotated \\nlexicon of wo rd-tag pairs. Kam -Fai et al.. (199 8) repo rt the features of an NLP to ol called Chicon  \\nused for word seg mentation in Chinese text.  Zweigenbau m & Gr abar (1999)  propose a method \\nfor acquiring morphological  knowledge about words in medical literature. It takes advantage of \\ncommonly available lists of sy nony m terms to  bootstr ap the acquisition pr ocess. Although the \\nauthors experim ented with the method o n the SNOMED International Microglos sary for \\npatholog y in its French version, the y claim that since the method do es not rely on  a priori \\nlinguistic kn owledge, it is applicable to o ther la nguages such as English.  Lovis et  al.. (199 8) \\npropose the d esign of a lexicon for use i n the NLP of medical texts. \\n \\nNoun phrasin g is considered to be an im portant N LP technique used in inf ormation retrieval. One \\nof the m ajor goals of  noun phrasing re search is  to investigate the possibility  of combining \\ntraditional ke yword and s yntactic approaches with  semantic approaches to text processing in \\norder to im prove the qualit y of inf ormation retrie val. Tolle and Ch en (2000)  compared four noun  \\nphrase generation tools in order to assess thei r ability  to isolate noun phrases from  medical \\njournal abstracts databas es. The NLP tools evaluated were: Chopper  developed b y the Machin e \\nUnderstanding grou p at the  MIT Media Laborator y,  Automatic Indexer  and AZ Noun Phrase r \\ndeveloped at the  University of Arizona, and NPTool  a commercial NLP tool from   LingSoft , a \\nFinnish Compan y.  The National Library of Medicin e’s  SPECIALIST Lexicon  was used alo ng \\nwith the AZ Noun Phrase r. This experiment used a reasonably  large test set of 1.1 gi gabytes of \\ntext, com prising 714,451 a bstracts fro m the CANCER LIT database.  This study  showed that with \\nthe exception of Chopper, the NLP tools were fair ly com parable in their performa nce, measured \\nin terms of re call and precision. The study  also show ed that the SPECIALIST Lexicon increased \\nthe abilit y of the AZ Noun Phraser  to generate releva nt noun ph rases.  Pedersen and  Bruce \\n(1998) propose a corpus-based approach to wo rd-sense disam biguation that onl y requires \\n 6 inform ation that can be automatically  extract ed fro m untagged text. Barker and Cornacchia \\n(2000) describe a si mple system  for choosing noun phrases, fro m a document, based on thei r \\nlength, t heir frequency  of occurrence, an d the fre quency  of their he ad noun, using   a base noun \\nphrase ski mmer and an off-the-shelf online dictiona ry. This resear ch revealed some interestin g \\nfindings:   (1) the si mple noun phrase-based sy stem  perfor ms roughl y as well as a state-of-the-art, \\ncorpus-trained ke yphrase extractor; (2) ratings for individual ke yphrases do not neces sarily  \\ncorrelate with  ratings for sets of ke yphrases for a document; and (3) agreement am ong unbiased \\njudges on t he keyphrase rating task is poor.  Silber & McCoy  (2000) report  research that uses a  \\nlinear tim e algorithm  for calculating lexical chains, which is a method of capturi ng the \\n‘aboutness’  of a docum ent.  \\n \\nMihalcea & Moldovan (1999) argue t hat  the reduced  applicabilit y of statistical methods in word \\nsense disa mbiguation  is due basically  to the lack of widely available se mantically  tagged \\ncorpora. They report   research  that enables the automatic acquisition of sense tagged corpora, \\nand is based on (1) the information provided in WordNet, and (2) the inform ation gathered from  \\nInternet using existing search engines.   \\n \\nMartinez & Garcia-Serrano (19 98) an d Martinez et al.. (200 0)  pr opose a method for t he design of \\nstructured kn owledge m odels for NLP. The key features of their method com prise the \\ndeco mposition of linguistic  knowledge s ources in sp ecialized sub-areas to tackle the com plexity \\nproblem  and a focus on cognitive archit ectures that al low for m odularity , scalabilit y and \\nreusability . The authors clai m that their approach  profi ts from  NLP techniques, first-order logic \\nand som e modelling heuris tics (Martinez et al.. 200 0). Fernandez & Garcia-Serrano (20 00) \\ncomment that knowledge e ngineering is increasingly  regarded as a means to co mplem ent \\ntraditional for mal NLP models by  adding sy mbolic modelling and i nference cap abilities in a way  \\nthat facilitates the introduc tion and m aintenan ce of linguistic experience. They  propose an \\napproach that allows the design of linguistic a pplications that integr ates different formalisms, \\nreuses existin g language re sources and supports t he implementation of the requi red control in a \\nflexible way . Costantino (1999) argues t hat qualita tive data, particularly articles from  online news \\nagencies, ar e  not yet successfully  processed, and as a result, financial operators, notably  traders, \\nsuffer fro m qualitative data-overload. IE-Expert is a system  that com bines the t echniques of NLP, \\ninform ation extraction and expert sy stems in order to be  able to suggest invest ment decisions \\nfrom  large volume of texts (Constantino,  1999).  \\n \\n 7 Natural Language Text Processing Systems \\n \\nManipulation  of texts for knowledge extraction, fo r auto matic indexing and abstracting, or for \\nproducing text in a desired format, has been rec ognized as an im portant area of resear ch in NLP. \\nThis is broadly  classified as the area of natural la nguage text processing that allows structuring of  \\nlarge bodies of textual information with a view to retrieving particular info rmation or to de riving \\nknowledge structures that may be used for a sp ecific purpose. Aut omatic text p rocessing sy stem s \\ngenerally  take some form  of text  input and transform it into an out put of som e different form . The \\ncentral task for natural language text processi ng systems is t he translatio n of potenti ally \\nambiguous natural language queries and texts into unam biguous inte rnal representations on which \\nmatching and retrieval can  take place ( Liddy, 1998). A natural language text processing sy stem \\nmay begin  with morphological analy ses. Stemm ing of  terms, in both the queries and docum ents, \\nis done in order to get the morphological variants of the words inv olved. The le xical and synt actic \\nprocessing involve the uti lization of lexicons for deter mining the characteristi cs of the words,  \\nrecognition of their parts- of-speech, de termining the words and phrases, and for parsing of the \\nsentences.  \\n \\nPast research  concentrating on natural language  text  processing sy stem s has been reviewed  by \\nHaas (1986), Mani & May bury (1999), Smeaton ( 1999), and  Warner (1987).  S ome NLP systems \\nhave been built to process texts using particular small  sublanguages to reduce the size of the  \\noperations and the nature of the com plexities.  These domain-specifi c studies are largely  known as \\n'sublanguage analy ses' (Grish man & Kittredge, 1986). Som e of these studies are li mited to a  \\nparticular subject are a such as medic al scienc e, wherea s others deal with  a specifi c type of \\ndocum ent such as patent texts.  \\n \\n \\nAbstracting  \\n \\nAutomatic ab stracting and text summari zation are now used sy nonymously that aim to generate \\nabstracts or s ummari es of texts. This are a of N LP rese arch  is becoming m ore common in the web \\nand digital library  environment.  In simple abst racting or summari zation sy stems, parts of text – \\nsentences or paragraphs – are sel ected autom atically based on some linguistic and/or statistical \\ncriteria to produce the abstract or su mma ry. More  sophisticated sy stems may merge two or more \\n 8 sentences, or parts thereof, to generate one cohe rent sentence, or may generate sim ple summar ies \\nfrom  discrete items of data.   \\n \\nRecent interests in autom atic abstracting and text summarization are reflect ed by the huge \\nnumber of research papers appearing in a num ber of i nternational conferences an d workshops \\nincluding ACL, ACM, AA AI,  SIGIR, a nd va rious national and reg ional chapters of the \\nAssociations.   Several tech niques are used for autom atic abstractin g and text summa rization. \\nGoldstein et al.. (19 99) use conventional IR methods  and lin guistic cues for extracting and \\nranking sentences for generating news article  summar ies. A num ber of studies on text \\nsummarizatio n have been reported recently. Silber an d McCoy  (2000) claim  that their  linear ti me \\nalgorithm  for calculating lexical chains is an efficient  method for p reparing auto matic \\nsummarizatio n of  d ocuments. Chuang a nd Yang (2000) report a text summarization techniq ue \\nusing  cue phrases appeari ng in the texts of US patent abstracts.  \\n \\nRoux and  Ledora y (2000) report a proje ct, called  Aristotle, that aims to build a n autom atic \\nmedical data system  that is capable of produc ing a semantic representation of th e text in a \\ncanonical form . Song  and  Zhao (20 00) propose a method of auto matic abstracting that i ntegrates \\nthe advantages of  bot h linguistic and statistical analy sis in a corpus.  Jin and  Don g-Yan (2000)  \\npropose a m ethodol ogy for  generating autom atic abstracts that  provides an integ ration of the \\nadvantages of methods based on linguist ic analy sis and those based on statistics. \\n \\nMoens and Uy ttendaele (1997) describe the SALOM ON (Su mmar y and Anal ysis of Legal t exts \\nFOR Managi ng Online Needs) project t hat automa tically  summari zes legal text s written in Dutch. \\nThe sy stem  extracts releva nt inform ation from  the fu ll texts of Bel gian cri minal case s and us es it \\nto summariz e  each deci sion. A text gra mmar represented as a semantic network is used to \\ndeter mine the category  of each case. T he system  extracts r elevan t information about each case,  \\nsuch as the na me of the court that issues the deci sion, the decision date, the offences charged, the \\nrelevant statu tory provisions disclosed by the c ourt, as well as the legal principles applied in  the \\ncase.  R AFI (resu me automatique a fra gments i ndicateurs) is an automatic tex t summari zation \\nsystem  that transform s full text scientific and te chnical docu ments into condensed t exts \\n(Leh mam, 1999).  RAFI adopts  discourse analy sis technique usi ng a thesaurus for recognit ion \\nand selection of the  most pertinent elements of texts. The sy stem assumes a typical structure of  \\nareas fro m each scientif ic document, viz. pr evious knowledge, cont ent, method and new \\nknowledge.  \\n 9  \\nMost of the a utomatic abstracting and text su mmariz ation s ystems work satisfact orily  within a \\nsmall text collection  or wit hin a restricted  dom ain. Building r obust and dom ain-independent \\nsystems is a c omplex and resource-intensive task. Arguing that pure ly autom atic abstracting \\nsystems do not alway s produce useful results, Crave n (1988, 1993, 2000) proposes a hy brid \\nabstracting syste m in whic h som e tasks are perfo rmed by human abstractors and others b y an \\nabstractor’ s assistanc e software c alled TEXNET. However, rec ent experiments on the usefulness \\nof the autom atically  extracted key words a nd phrases from  full texts  by TEXNET in the actual \\nprocess of abstracting by  human abstract ors show ed some consider able variation am ong subjects, \\nand onl y 37%  of the subjects found t he key words and phrases to be useful in writing their \\nabstracts ( Craven, 2000).  \\n \\n \\nInformation Extraction \\n \\nKnowledge discovery  and data mining have beco me important are as of resear ch over the past few \\nyears and a num ber of infor mation scien ce  journals have published special issue s reporting \\nresearch on these topics (see for exam ple, Benoit,  2001;Qin and N orton, 1999; Raghavan et al.., \\n1998;  Trybula, 1997;  Vickery , 1997). Knowledge  discovery  and data mining research use a \\nvariety  of techniques in order to extract useful information from  source documents. Inform ation \\nextraction (IE) is a subset of  knowledge discovery  and data mining r esear ch that  ai ms to extract \\nuseful bits of textual infor mation from  natura l language texts  (Ga izauskas & Wilks, 1998). A \\nvariety  of inf ormation extraction (IE) techniques are used and the extracted infor mation can be \\nused for a num ber of purposes, for exam ple to pr epare a su mmary  of texts, to populate databases, \\nfill-in slots in fram es, identify ke ywords and phrase for inform ation retrieval, and so on. IE \\ntechniques are also used for classify ing text ite ms according to som e pre-defined categories. A n \\nearlier exa mple of text categorization s ystem is CONSTRUE, developed for Reut ers,  that \\nclassifi es news stories (Hay es, 1992). T he CONSTR UE software was subsequently generalized \\ninto a commercial product called TCS (Text Categor ization Shell). An evaluation of five text \\ncategorizatio n system s has been reported b y Yang an d Liu (1 999).  \\n \\nMorin (19 99) suggests that althoug h many IE systems can successfull y extract term s from \\ndocum ents, acquisition of  relati ons between terms is still a difficulty. PROMETHEE is a system  \\nthat extracts l exico-sy ntactic patterns rel ative to a specific concept ual relation from  technical \\n 10 corpora (Mor in,19 99). Bo ndale et al..  (1999) sug gest that IE sy stems must operate at many  \\nlevels, fro m word recognit ion to discour se analy sis at the level of th e complete d ocument. They \\nreport an appl ication of the Blank Slate Language  Processor (BSLP)  approach for the analy sis of \\na real life nat ural language corpus that consists  of responses to ope n-ended quest ionnaires in t he \\nfield of adver tising.  \\n \\nGlasgow et al .. (1998) report a sy stem  called MITA (Metlife’s Intelligent Text Analy zer) that \\nextracts information from  life insurance appli cations. Ahonen et al.. (199 8) pro pose a general \\nframework for text m ining that uses pragmatic and discourse level a nalyses of text. Sokol et al.. \\n(2000)  report  resear ch that uses  visualization and NL P  technologi es to perform  text m ining. \\nHeng-Hsou et al.. (2000) argue that IE s ystems are usu ally event-driven (i.e., are usually based on \\ndomain knowledge built on various events) and  propose an even t detection driven intelligent \\ninform ation extraction b y using the neur al netw ork paradigm . They  use the backpropagation  (BP) \\nlearning algor ithm to train the event detector, and  app ly NLP technolog y to aid t he selection of \\nnouns as feature words which are supposed to charact erize docu ments appropriat ely. These nouns \\nare stored in ontolo gy as a knowledge ba se, and are used  for the ext raction of useful inform ation \\nfrom  e-mail mes sages.  \\n \\nCowie and Lehnert (1996)  reviewed the earlier research on IE and  commented that the NLP \\nresearch co mmunity  is ill-prepared to tackle the difficult problems of sem antic f eature-tagging, \\nco-referenc e resolution, and discourse analy sis, all of which are i mportant issues of IE researc h. \\nGaizauska s and Wilks (1998) reviewed the IE  resear ch from  its origin in the Artificial \\nIntelligence world in the s ixties and seventies th rough to the m odern da ys. The y discussed the \\nmajor IE projects undertaken in different sector s, viz., Academic Resear ch. E mployment, Fault \\nDiagnosis, Finance, Law, Medicine, Military  Intelligence, Police, Software Sy stem  Requirements \\nSpecification, and Technol ogy/Product Tracking.  \\n \\nChowdhur y (1999a) revie wed research that used te mplate mining t echniques in: the extraction of \\nproper nam es from  full text docum ents, extracti on of facts fro m press rele ases, abstracting \\nscientific papers, su mmarizing new pro duct inform ation, extracting specific information  from  \\nchemical texts, and so on. He also discu ssed how some w eb sear ch engines use te mplates to \\nfacilitate infor mation retrieval. He reco mmends that  if  each web author is given a tem plate to  \\nfill-in in order to characteri ze his/her document, then eventuall y a more controlled and s ystem atic \\nmethod of creating docum ent surrogates can be achie ved. However, he warns that  a single all-\\n 11 purpose m etadata form at will not be appl icable for all authors in all the dom ains, and further \\nresea rch is ne cessary to come up with appropriate formats for ea ch.  \\n \\nArguing that IR has been the subject of resea rch and developm ent and has been delivering \\nworking sol utions for m any decades whereas IE is a more recent an d emerging technology,  \\nSmeaton (1997) comments that it is of interest to the IE community to see how a related task, \\nperhaps the m ost-relat ed task, IR, has mana ged to use the NLP base technology in its \\ndevelopm ent so far. Co mmenting o n the future challenges of IE rese archers, G aizauskas and \\nWilks (199 8) mention that t he  performance levels of  the common IE sy stem s, which stand in the \\nrange of  50 % for co mbined recall and precision, sho uld im prove significantl y to satisfy  \\ninform ation analy sts. A m ajor stum bling block  of IE systems developm ent is the cost of \\ndevelopm ent. CONSTR UE, for exam ple required 9.5 person y ears of effort (Hay es & Weinstei n, \\n1991). Portabilit y and scalabilit y are also two big issue s for IE sy stems. Since they depend \\nheavily on t he dom ain knowledge, a given IE sy stem  may work satisfactorily  in a relatively  \\nsmaller text collection, but it may  not per form well  in a  larger collection, or i n a different \\ndomain. Alter native technologies are now being used to overcom e these proble ms. Ada ms (20 01)  \\ndiscusses the merits of the NLP and the wrapper induction technol ogy in inform ation extraction \\nfrom  the web docum ents.  In contrast to NLP,  wrapper inductio n operates independentl y of \\nspecific do main knowledge. Instead of analy sing the meaning of discourse at the  sentence lev el, \\nthe wrapper technology identifies relev ant cont ent based on the textual qualitie s that surround \\ndesired data. Wrappers operate on the surface fe atures of docum ent texts that characteriz e train ing \\nexam ples. A number of vendors, such a s Jango  (purchased by Exc ite), Junglee  (purchased by  \\nAmazon), and Mohomine  employ wrap per inductio n technolog y (Adams, 2001).  \\n \\n \\nInform ation Retrieval \\n \\nInform ation r etrieval has been a major area of app lication of NLP, and consequentl y a  number of \\nresea rch projects, dealing with the various applications on NLP in IR, have taken place \\nthroughout  the world resulting in a large volum e of publications.  L ewis and Sparck Jones (1996) \\ncomment that the generic challenge for NLP in th e field of IR  is whether the neces sary NLP of \\ntexts and que ries is doable, and the specific cha llenges are whether non-statistical and statistical \\ndata can be com bined and whether data about individ ual docum ents and whole files can be \\ncombined. Th ey further comment that there ar e major challenges in making the NLP technolog y \\n 12 operate effect ively and efficiently  and also in cond ucting appr opriate evaluation tests to assess \\nwhether and how far the approach work s in an envi ronment of interactive se arching of large te xt \\nfiles. Feld man (199 9) sug gests that in order to achieve success in IR, NLP techniques should be \\napplied in co njunctio n with other techn ologies, such as visualizati on, intelligent agents and \\nspeech recog nition.   \\n \\nArguing that  syntactic phra ses ar e more meaningful than statisticall y obtained w ord pairs, and \\nthus are more powerful for discrim inating am ong documents, Narita and Ogawa (2000) \\nuse a shallow  syntactic processing instea d of st atistica l processing to autom atically identify \\ncandidate phrasal ter ms from query  texts. Com paring the performance of  Boolean and natural \\nlanguage sear ches,  Paris and Tibbo (1998) found  that in their experi ment, Boolean sear ches  had \\nbetter results than freesty le (natural language) sear ches. However, t hey conclude d that  neither \\ncould be cons idered as the best for every query . In other words, their conclusion was that \\ndifferent queries dem and different techniques.  \\n \\nPirkola (20 01) shows that languages vary significantl y in their m orpholo gical pr operties. \\nHowever,  for each language there are two variab les that describe the morphologi cal co mplexity, \\nviz.,  index of  synthesis (IS) that describes the am ount of affixation in an individual language, i .e., \\nthe average num ber of morphemes per w ord in th e lan guage;  and i ndex of f usion (IF) that \\ndescribes the ease with which two m orphem es can be separated in a la nguage. Pir kola (2001) \\nshows that calculation of t he ISs and IFs in a la nguag e is a relatively sim ple task, and once the y \\nhave been established,  the y could be utilized  fruitfully in em pirical  IR resea rch a nd system  \\ndevelopm ent.   \\n \\nVariations in presenting subject matter  greatly  affect IR and hence linguistic vari ation of \\ndocum ent tex ts is one of the greatest cha llenges to  IR. In order to inves tigate how consistently \\nnewspapers c hoose words and concepts to descr ibe an event, Lehtokangas & Jar velin (2001) \\nchose article s on the sam e news fro m three Finnish newspapers. Their experiment revealed that \\nfor short newswire  the consistency  was 83%  and fo r long articles 47% . It was also revealed that  \\nthe newspape rs were very  consis tent in using concepts to represent events, with a level of \\nconsistency  varying between 92-97% . \\n \\n \\n 13 Khoo et al.. ( 2001) rep ort an experim ent that investig ates whether inform ation obtained b y \\nmatching cause-eff ect relat ions expresse d in docu ments with the cause-effe ct rel ations expressed \\nin user queries can be used to im prove re sults in document retrieval  com pared wi th the use of \\nonly the keywords withou t considering the rela tions. Their experiment with the Wall Street \\nJournal full te xt database re vealed that ca usal relations matching where either the cause or the \\neffect is a wildcard can be used to im prove info rmation retrieval effectiveness if t he appropriate \\nweight for each ty pe of m atching can be deter mined for each query . However, the  authors stress \\nthat the results of this stud y were not as strong as the y had expected it to be .  \\n \\nChandrasekar  & Srinivas (1998) propose that c oherent text contai ns significant latent \\ninform ation, such as sy ntactic structure and patte rns of language u se, and this in formation could \\nbe used  to i mprove the perform ance of inform ation retrieval sy stems. They  describe a sy stem , \\ncalled Glean , that uses sy ntactic infor mation for eff ectively filtering irrele vant documents, and \\nthereby  improving  the pre cision of info rmation retrieval sy stem s.   \\n \\nA num ber of tracks (research groups or themes) in the TREC series of experiments deal directly \\nor indirectl y with NLP and inform ation retrieva l, such as the cross-language track, filtering tr ack, \\ninteractive tra ck,  question-answering tra ck, and the w eb track.  Reports of progress of the NLIR \\n(Natural Lan guage Information Retrieval) project are  available in the TREC reports (Perez-\\nCarballo & Strzalkowski, 2000;  S trzalkowski. et al.., 1997, 1998, 1999).   The major goal of t his \\nproject has been to dem onstrate that robust NLP techniques used f or indexi ng and searching of \\ntext docum ents perfor m better co mpared to the si mple key word and string-based methods used in \\nstatistical full-text retrieval (Strzalkowski, T. et  al.., 1999). However, results indicate that sim ple \\nlinguisticall y motivated indexing (LMI)  did n ot prove to be m ore effective than well-executed \\nstatistical approaches in English language texts.  Never theless, it was noted that m ore detailed \\nsearch topic statements responded well t o LMI com pared to  terse one-sentence search queries.  \\nThus, it was concluded t hat quer y expans ion, us ing NLP techniques,  leads to a sustainable \\nadvances in IR effectiveness (Strzalkowski et al.., 1999).   \\n \\n \\nNatural Language Interfaces \\n \\nA natural language interface is one that accepts  query  statements or commands i n natural \\nlanguage and sends data to so me system , typical ly a retrieval sy stem, which then r esults in \\n 14 appropriate  r esponses to the commands or quer y statements. A nat ural language interface should \\nbe able to translate the natural language statem ents into appro priate actions for th e system .  \\nA large num ber of natural language interfaces that work reasonably well  in narrow dom ains have \\nbeen reported in the literature (for review of  such s ystems see Chowdhur y, 1999b, Chapter \\n19;Haas, 1996; Stock, 2000).  \\n \\nMuch of the e fforts in natur al language interface desig n to date have  focused on handling rather  \\nsimple natural language qu eries. A nu mber of questio n answering sy stem s are now being \\ndeveloped tha t aim to provi de answers to  natural langu age questions, as opposed t o docum ents \\ncontaining i nformation related to the q uestion. Su ch system s often use a variety  of IE and IR \\noperations usi ng NLP tools  and techniqu es to get the correct answer  from  the source texts. Bre ck \\net al. (1999) r eport  a question answering sy stem  that uses techniques fro m knowledge \\nrepresentatio n, inform ation retrieval, and NLP. Th e authors claim  that this com bination enables \\ndomain independence and robustness in t he face of te xt variabilit y, both i n the question and in the \\nraw text documents used as knowledge s ources. Research reported i n the Question Answering \\n(QA) track of   TREC  (Text Retrieval C onferences) s how some interesting resul ts.   The basic \\ntechnolog y used by the participants in th e QA track included several steps. First, cue \\nwords/phrase like ‘who’ (as in ‘who is the prime minister of Japan’ ), ‘when’  (as in ‘When did the \\nJurassic perio d end’ ) were identified to guess wh at was needed; and then a small portion of the  \\ndocum ent collection was retrieved using standard te xt retrieval tech nology. This was followed  by \\na shallow parsing of the ret urned docum ents for id entify ing  the entities required for an answer. If \\nno appropriate answer ty pe was found then best matching passage was retri eved. This approa ch \\nworks well as long as the q uery types  recognized by the system  have broad cov erage, and the \\nsystem  can classify  questions reasonably accura tely (Voorhees,1999). In TREC-8, the first QA \\ntrack of TREC,  the m ost accurate Q A system s could answer more than 2/3 of the questions \\ncorrectly . In the second QA  track (TREC-9), the best perform ing QA sy stem , the Falcon sy stem \\nfrom  Southern Methodist University ,  was able to answer 65% of the questions  (Voorhees, 2000). \\nThese results are quite i mpressive in a domain- independent question answering environm ent. \\nHowever, the questions were still si mple in the first t wo QA tracks. In the fut ure more co mplex \\nquestions requiring answers to be obtained from  more than one documents will be handled by  QA \\ntrack rese archers.    \\n \\n Owei (2000)  argues that the drawbacks of m ost natural language interfaces to database systems \\nstem  primarily from  their weak interpretative power  which is caused by  their  i nabilit y to deal \\n 15 with the nuances in human use of natural language . The author further argues that the difficult y \\nwith NL database query  languages (DBQLs) can be overcome by  combining  c oncept based \\nDBQL paradi gms with NL approaches to enhan ce the overall ease-o f-use of the query  interface . \\n \\nZadrozn y et al. (200 0) sug gest that in an  ideal information retrieval envi ronm ent, users should be \\nable to express their interes ts or queries direc tly and naturally , by speaking, typing, and/or \\npointi ng; the computer sy stem then should be able  to provide i ntelligent answers or ask relevant \\nquestions. Ho wever, they  comment that even thou gh we build natu ral language sy stem s, this goal \\ncannot be full y achieved due to lim itatio ns of  science,  technology, business knowledge, and \\nprogramming environm ents. The specifi c problem s include (Zadrozny  et al., 2000):  \\n• Limitations of NL understanding;   \\n• Managing the  complexities of interaction (for exam ple, when using NL on devic es with \\ndiffering ban dwidth);  \\n• Lack of precise user models (for exam ple, knowing how dem ographics and personal \\ncharacteristics of a person should be reflected in the type of lang uage and dialog ue the \\nsystem  is usi ng with the user), and  \\n• Lack of m iddleware and toolkits.  \\n \\nNLP Software \\n \\nA num ber of  specific NLP  software products have  been developed  over the past decades, so me \\nof which are available for free, while others  are avail able co mmer cially. Many such NLP \\nsoftware pack ages and tool s have alread y been m entioned in t he discussions through out this \\nchapter. Some more NLP t ools and soft ware are mentioned in this section. \\n \\nPasero & Sab atier (1998)  describe principles underly ing ILLICO, a generic natural-language \\nsoftware tool for buil ding larger applications  for perfo rming specific linguistic tasks such as \\nanaly sis, synthesis, and gui ded com position. Lid dy (1998) and  Liddy et al. (20 00) discuss the \\ncommercial u se of NLP in IR with the exam ple of DR-LINK (Document Retrieval Using \\nLINguistic Knowledge) system  dem onstrating the capabilities of NLP for IR. Detailed product  \\ninform ation a nd a dem o of DR-LINK are now available online (http://www.textwise.co m/dr-\\n 16 link.htm l).   Nerbonne et al. (1998) report on GLOSSER, an intelligent assistant for Dutch \\nstudents for learning to read French. Scott (1999) describes the Kana Customer M essaging \\nSystem  that can categorize inbou nd e-m ails, forward th em to the rig ht department and generally \\nstrea mline the response process. Kana  also has an auto-suggestion function that helps a customer \\nservice repr esentative answer questions on unf amiliar t erritory . Scott  (1999)  describes another \\nsystem , called Brightware, that  uses NLP techniques  to elicit meaning from  groups of words or \\nphrases and reply  to som e e-mails automatic ally.  NLPWin is an NLP sy stem  from Microsoft  that \\naccepts sente nces and delivers detailed sy ntactic analy sis, together with a logical form   \\nrepresenting an abstraction of the m eaning (E lworthy, 2000). Scarle tt and Szpakowicz (2000) \\nreport a diagnostic evaluati on of DIPETT, a br oad-coverage parser  of English sentences.  \\n \\nThe Natural Language Processing Laboratory , Center  for Intelligent  Inform ation Retrieval at t he \\nUniversity  of Massachusett s,  distributes sour ce codes and executables to support IE sy stem  \\ndevelopm ent efforts at other sites. Each module is designed to be us ed in a dom ain-specific an d \\ntask-specific custo mizable IE system . Available software includes (Natural Lan guage …, n.d .) \\n• MARMOT Text Brackettin g Module ,  a text file translator which segments arbitrary  text \\nblocks into sentences, applies low-level s pecialists suc h as date reco gnizers, assoc iates \\nwords with part-of-speech tags, and brack ets the text into annotated noun phrases, \\nprepositional phrases, and verb phrases.  \\n• BADGER Extraction M odule, that analy zes bracketed t ext and produces c ase fr ame \\ninstantiations according to application-specific domai n guidelines.  \\n• CRYSTAL Dictionary Induction Module , that learns text extraction rules, suitable for use \\nby BADGER, from  annotated training te xts.  \\n• ID3-S Inducti ve Learning M odule , a variant on ID3 w hich induces decision trees  on the \\nbasis of training exam ples.  \\n \\n \\nWaldrop (2001) briefly  describes the features of  three NLP softwar e packages, viz.  \\n \\n• Jupiter ,  a product of t he MIT resear ch Lab that  works in the fiel d of weather forecast \\n• Movieline , a product of Carnegie Mellon that talks ab out local m ovie schedules, and   \\n 17 • MindNet from  Microsoft Rese arch, a s ystem  for automatically  extracting a massively  \\nhyperlinked  web of concepts, from , say, a standard d ictionary. \\n \\nFeldman (199 9)  m entions a num ber of NLP software packages, such as \\n• ConQuest , a part of Excalibur , that incorporates a lexicon that is im plemented as a \\nsemantic network  \\n• InQuery that parses sentences, stems words and recognizes proper nouns and concepts \\nbased on term  co-occurre nce  \\n• The Linguist X parser  from  XERO X PARC that extracts sy ntactic information, and is \\nused in InfoSeek   \\n• Text m ining sy stem s like NetOwl from SRA and KNOW-IT  from TextWise .  \\n \\nA recent surv ey of 68 E uropean university centres in com putational linguistics and NLP, carried \\nout under the auspices of a Socrates Wor king Grou p on Advanced Computing in the Humanities, \\nrevealed that Java has alr eady reached the status of second m ost commonly  taught programmi ng \\nlanguage (Black et al., 2000). In addi tion, Jav a based program s are being used to develop \\ninteractive instructional materials.  Black et al . (2000) review so me Java-bas ed coursewar e in use \\nand  discuss  the issues involved in m ore com plex nat ural language processing applications that \\nuse Java.   \\n \\n \\nInternet, Web and Digital  Library Applications of NLP  \\n \\nThe Internet and the web h ave brought  significant improvem ents in the way  we create, look for \\nand use infor mation. A hu ge volum e of inform ation is now available throug h the  Internet and \\ndigital libraries. However, these developments ha ve made so me proble ms relat ed to inform ation \\nprocessing and retrieval more prom inent.  According to a recent Survey  (Global Reach, 2001), \\n55% of the Internet users are non-Engl ish speak ers an d this is increasing rapidl y, thereby \\nreducing the percentage of net users who are na tive English speakers. However, about 8 0%  of \\nthe Internet and digital library  resources availabl e today are in English (Bian, Guo-Wei & Che n, \\n2000).  This c alls for the urgent need for the est ablishment of  m ultilingual inf ormation sy stems \\nand CLIR facilities.   How to m anipulate the large vol ume of multilingual data has beco me a \\nmajor research question. In fact, several issues ar e involved here. At the user interface level, th ere \\nhas to be a qu ery translatio n system  that should transla te the quer y from the user’s native \\n 18 language to t he language o f the sy stem . Seve ral approaches have been proposed f or quer y \\ntranslation. The dictionar y based approach uses a bilingual dictionary  to convert  terms from the \\nsource language to the target langua ge. Coverage and up-to-datene ss of the bilingual dictionar y is \\na major issue here. The corpus-based approach u ses parallel corpora for word selection, where the \\nproblem  lies with the dom ain and scale of the co rpora. Bian & Chen (2000)  propose a Chinese-\\nEnglish CLIR sy stem  on www, c alled MTIR,  that integrates the query  translation and document \\ntranslation. They  also address a nu mber of issues of  machine trans lation on the web, viz., the role \\nplayed by  the HTML tags in translation, the trade-off between the s peed and performance of the \\ntranslation syste m, and the form  in whic h the translated material i s presented.  \\n \\nStaab et al. (1999) describe the features of an  intellige nt inform ation agent called GETESS that \\nuses semantic methods and NLP capabilities in orde r to gather tourist  inform ation from  the web \\nand present it to the hum an user in an int uitive, user-friendl y way. Ceric (2000) reviews the \\nadvancem ents of the web search technology  and mentions that, among others, NLP technologies \\nwill have very good im pact on the success of th e sear ch engines.  Mock and Vem uri (1997) \\ndescribe the Intelligent News Filtering Organizationa l System  (INFOS) that is designed to filter \\nout unwanted news ite ms from  a Usenet.   INFOS  builds a profile of user interests  based on the \\nuser feedback . After the user browses e ach article , INFOS asks the user to rate the article, and \\nuses this as a criterion for selection (or rejection) of similar articl es next tim e rou nd. News \\narticles are cl assified by  a simple key word method, called the Global Hill Cli mbing (GHC), that \\nis used as a si mple quick-pass method. Articles that cannot be classified by  GHC are passed \\nthroug h a WordNet knowledgebase through a Case based reasoning (CBR) module which is a \\nslower but more accurate method. Very sm all-scale evaluation of INFOS suggests that the \\nindexing  pattern method, i. e., mapping o f the words from  the input text into t he correct concepts \\nin the WordN et abstraction hierarchy , correctly  classif ied 80% of the article s; the major rea sons \\nfor errors being the weakness of the sy stem to disa mbiguate pronouns.  \\n \\nOne of the major stum bling blocks of providin g perso nalized news delivery to us ers over the \\nInternet is the problem  involved in the autom atic association of related item s of different media \\ntype. Carrick and Watters (1997) describe a sy stem  that ai ms to det ermine to what degree any  two \\nnews ite ms re fer to the sa me news event.  This resear ch focused on deter mining the associatio n \\nbetween photographs and s tories b y usin g nam es. The algorithm  developed in co urse of this \\nresea rch wa s tested against  a test data se t as well as n ew data set s.  The pair of news ite ms an d \\n 19 photos generated b y the s ystem were checked b y human experts. The sy stem  performed,  in term s \\nof recall, precision and tim e, sim ilarly  on the new data sets as it did on t he traini ng set.  \\n \\nBecause of the volum e of text available on the web, many  researchers have proposed to use t he \\nweb as the testbed for NLP research. Grefenstette  (1999) argues that although noi sy, web text \\npresents language as it is used, and statistics de rived from  the web can have practical uses in \\nmany  NLP ap plications.  \\n \\n \\nMachine Translation and CLIR \\n \\nWith the prol iferation of the web and digita l libraries, m ultilingual inform ation retrieval has \\nbeco me a major challenge. There are two  sets of  issues here: (1) recogniti on, m anipulation an d \\ndisplay of m ultiple languages, and (2) cross-langua ge inform ation search and retrieval (Peter & \\nPicchi, 1997) .  The first set of issues relate to  the enabling technol ogy that will al low  users to \\naccess infor mation  in what ever language it is stored; while the second set im plies per mitting  \\nusers to specify  their infor mation needs in their preferred langua ge while retrieving inf ormation \\nin whatever language it is stored.  Text t ranslati on can take place at two levels: (1) translation of \\nthe full text fr om one language to anothe r for the pur pose of search and retrieval, and (2) \\ntranslation of queries fro m one language to one or  more different languages. The first option  is \\nfeasible for s mall collectio ns or for specific a pplications, as in mete orological reports (Oudet, \\n1997).  Translation of q ueries is a more practicab le approach and pro mising results have been \\nreported in the literature (discussed below).  \\n \\nOard (1997) comments that seeking infor mation from  a digital libra ry could benefit from  the \\nabilit y to query large collections once using a single l anguage. Furt herm ore, if the retrieved \\ninform ation is not available in a language that the user can read, some form  of translation will be \\nneeded. Multi lingual thesauri such  as EUROVOC help to address thi s challenge by facilitating \\ncontrolled vocabulary  search using terms fro m sever al languages, and services such as INSPEC \\nproduce Engl ish abstracts for docum ents in ot her lan guages (Oard, 1997).  However, as Oard \\nmentions, fully autom atic MT is presently neither sufficiently  fast nor sufficiently accurate to \\nadequately  support i nteractive cross-language info rmation seeking i n the web and digital librari es. \\nFortunatel y, an active and rapidl y growing r esearch co mmunity  has coalesced around t hese and \\n 20 other related issues, apply ing techniq ues drawn fro m several fields - notabl y IR a nd NLP - to \\nprovide access to large m ultilingual colle ctions. \\n \\nBorgman (1997) comments that we have hundreds (and som etimes thousands) o f years worth of \\ntextual materials in hundre ds of languag es, create d long before dat a encoding st andards existed. \\nShe  illustrates the multi-language DL challenge with exam ples drawn from  the r esearch library \\ncommunity , which t ypically handles col lections of materials in  ab out 4 00 differ ent languages.  \\n \\nRuiz and  Sri nivasan (1998) investigate an  autom atic method for C LIR that utili zes the \\nmultilingual Unified Medical Language S ystem  (UMLS) Metathesaurus to translate Spanish \\nnatural-language queries into English. They  conc lude that  the UMLS Metathesa urus-based CLIR \\nmethod is at least equivalent to, if not better,  than m ultilingual dictionar y based approaches. Dan-\\nHee  et al. (2 000), comm ent that there i s no re liable guideline as to how large machine readable \\ncorpus resources should be com piled to develop pr actical NLP soft ware package and/or com plete \\ndictionaries for hum ans an d com putational use. They propose  a ne w mathematical tool: a \\npiecewise cur ve-fitting algorithm , and suggest how  to determ ine the tolerance error of the \\nalgorithm  for good  predicti on, usin g a sp ecific corpus.  \\n \\nTwo Tele matics Application Program  projects in the Tele matics fo r Libraries se ctor, TRANS LIB \\nand CANAL/ LS, were acti ve between 1995 and 1997 (Oard,1997). Both these pr ojects \\ninvestigated cross-language searching in library  catalogs, and each included Engl ish, Spanish a nd \\nat least one other language: CANAL/LS added German and French, while TRANSLIB added \\nGreek. MULINEX, another European pr oject,  is concerned with the efficient use of m ultilingual \\nonline inf ormation. The pr oject ai ms  to process multilingual inf ormation and pr esent it to the \\nuser in a way  which facilitates finding and ev aluating t he desired information quic kly and \\naccurat ely (MULINEX, n.d.). TwentyOne , started in 1996, is a EU f unded pr oject which has the \\ntarget to develop a tool  for efficient dissemina tion of multimedia inform ation in the field of \\nsustainable development (Twenty One, n.d.). Deta ils of these and CLIR res earch projects in the \\nUS and other parts of the world have been reviewed by Oard & Diekam a (1998).  \\n \\nMagnini et al.   (2000) repor t two projects where NLP has been used for im proving  the \\nperformance i n the public adm inistration  sector. The first project, GIST, is concerned with \\nautomatic multilingual generation of inst ructiona l text s for form -filling. The second project, \\n 21 TAMIC, ai ms at providing an interface f or inte ractive acce ss to infor mation, centered on NLP \\nand supposed to be used by the clerk but with the active participation of the citizen. \\n \\nPowell and Fox (1998) describe a federa ted search sy stem, call ed SearchDB-M L Lite ,  for \\nsearching heterogeneous multilingual the ses and di ssertations collections on the World Wide Web \\nNDLTD: Net worked Digit al Library  of Theses and Dissertations ( NDLTD, n.d.). A markup \\nlanguage, called SearchDB , was developed for describing the characteristic s of a search engine  \\nand its interface, and a prot ocol was built  for re questing word trans lations between languages. A \\nreview of the results generated from  query ing over 50  sites sim ultaneously revealed that in some \\ncases more so phisticated query  mapping i s necessary  to retrieve resul ts sets that truly correspond \\nto the orig inal quer y. The authors report that an extended version o f the SearchDB  markup \\nlanguage is being develope d that can reflect th e default and available query m odifiers for each \\nsearch engine; work is also underway to implem ent a mapping s ystem  that uses t his inform ation \\n \\nA num ber of companies now provide m achine translation service, for exa mple (McMurchie, \\n1998): \\n• Berlitz International Inc. that offers pr ofessional translation service in 20 countri es \\n• Lernout & Hauspie  has an Internet Translation Division  \\n• Orange, Calif -based Language Force Inc.  that has a product called Universal tra nslator \\nDeluxe  \\n• IBM MT services through i ts WebSphere Translation Server. \\n \\nA large num ber of resear ch papers are av ailable that discuss various resea rch projects dealing \\nwith MT and CLIR with reference to specific  languages, for exam ple in Chinese (Kwok et al. \\n2000;  Lee et al., 1999), Japanese (Jie  & Akahor i , 2000; Ma, et al . 2000; Ogura  et al. 2000)  , \\nPortugese (Barahona & Al feres, 1999),  Sinhalese (Herath &  Herat h, 1999), Spanish (Weigard & \\nHoppenbro uwers,1998; M arquez et al., 2000),  Thai (I sahara et al.,2 000), T urkish  (Say , 1999), \\nand so on.  Some studies have considered m ore than two languages; see for exam ple Ide, 2000. \\nThese papers address various issues of MT, for example,  \\n \\n• Use of cue phrases in deter mining relationships am ong the lexical units in a disc ourse \\n(Say, 199 9); \\n 22 • Generation of semantic maps of terms (Ma et al., 200 0);  \\n \\n• Creation of language-specific seman tic dictionaries (Ogura et al., 2000); \\n \\n• Discourse an alysis (Jie  & Akahori, 2000); \\n \\n• Lexical analysis (Ide, 2000 ; Lee et al., 1999);  \\n \\n• Part-of-speech taggin g (Isahara et al., 2000; Marquez et al., 2000) \\n \\n• Query  translation (Kwok et al.,  2000) \\n \\n• Transliteratio n of foreign words for inf ormation retrieval (Jeong, et al., 1999) \\n \\nWeigard & Hoppenbr ouwers (1998) rep ort the way  an English/S panish lexicon,  includin g an \\nontology , is constructed for  NLP tasks in an ESPRIT project called TREVI.  E mphasizing the \\npoint t hat the re has not been an y stud y  of natu ral language information retrieval in Swedish, \\nHedlund et al. (2001) describe the features of Swedish language and point out a number of \\nresea rch proble ms. They  further stress th at separat e research in NL P in Swedish is required \\nbecause the r esear ch result s and tools for other langua ges do not  quite appl y to Swedish becau se \\nof the uni que features of the language.  \\n \\nCommenting on the pr ogress of MT research, Jurafsk y & Martin (2 000; p. 825) c omment that \\n“machine translation s ystem  design is hard wo rk, req uiring careful selection of m odels and \\nalgorithm s and com bination into a useful sy stem .” Th ey further comment that “ despite half a \\ncentury  of research, machine translation is fa r from solved; hum an language is a rich and \\nfascinating ar ea whose tre asures have only begun to be explored”.  \\n \\n \\n \\nEvaluation \\n \\nEvaluation is an im portant area in any  system development activity , and inform ation science \\nresearchers h ave long been struggling to come up with appropriate evaluation mechanisms for \\n 23 large-sc ale information sy stems. Conseq uently , NLP resear chers ha ve also been try ing to develop \\nreliable methods for evaluating robust NLP sy stems.  However, a  single set of evaluation criteria \\nwill not be applicable for all NLP tasks. Differe nt eval uation parameters may be required for each \\ntask, such as IE and automatic abstra cting which ar e significantly  different in nature co mpared to \\nsome other N LP tasks such as MT, CLIT or natural language user interfac es.  \\n \\nThe ELSE (Evaluation in Language and Speech Engineering) proj ect under the  contract from  the \\nEuropean Commi ssion aimed to study  the possible implementation of com parative evaluation in \\nNLP sy stems. Com parative evaluation in  Langua ge En gineering has been used since 1984 as a \\nbasic paradigm  in the DARPA research  program  in the US on h uman language technolog y since \\n1984 . Com parative evaluation consists o f a set of participants that com pare the results of their \\nsystems using sim ilar task s and related data with  metrics that were agreed upon.  Usually  this \\nevaluation is performed in a num ber of s uccessive evaluation ca mpaigns with more co mplex task \\nto perform  at every  cam paign. ELSE proposition departs fro m the DARPA research program in \\ntwo way s: first by consider ing usabilit y criteria in the evaluation, and second by trading \\ncompetitive aspects for more contrastive and collabor ative ones through the use of \\nmultidimensional results (Paroubek & Blasband, 1999). The ELS E consortium has identified the \\nfollowing fi ve types of eva luation (Paro ubek & Blasband, 19 99):  \\n• Basic r esearch evaluation : tries to validate a new idea or to assess t he am ount of \\nimprovem ent it brings o ver older m ethods.  \\n• Technolog y evaluation:  tries to asses s the perfor mance and appropriateness of a \\ntechnolog y for solving a problem  that is well-defined, sim plified and abstracted.  \\n• Usage evaluation: tries to a ssess the usability  of a technology for solving a real problem  \\nin the field. It  invol ves the end-users in the environm ent intended f or the deplo yment of \\nthe sy stem  under test.  \\n• Impact evalu ation: tries to measure the socio-econom ic consequences of a technology .  \\n• Program  evaluation:  attempts to determ ine how worth while a fundi ng pro gram has been \\nfor a given te chnolog y.  \\n \\nEAGLES (The Expert Advisory Group on La nguage E ngineering St andards – Evaluation \\nWorkgroup) ( Centre for .., 2000), phase one (EAGLES-I: 1993—1995) and pha se two \\n 24 (EAGLES-II:1997—1998) , is an Europe an Initiative  t hat proposed a user-centred evaluation of \\nNLP sy stems.   The EAGLES work takes as its starting point an exist ing Standard,  viz.  ISO 9126, \\nwhich is concerned primari ly with the de finiti on of quality  characteristics to be used in the \\nevaluation of software products. \\n \\nThe DiET project (1997-1999) was designed to  develop data, m ethods and t ools for the glass-box \\nevaluation of NLP co mponents, buildi ng on the r esults  of previo us projects covering different \\naspects of assessment and evaluation. T he webpage of the DiET project (DiET, 1997) sa ys that \\nthe project “will extend and develop test-suit es with annotated test item s for grammar, \\nmorphology  and discourse, for English,  French  and Germ an. DiET will provide user-support i n \\nterms of database technology , test-suite constr uction t ools and graphic interfaces.”, and that it \\n“will result in a tool-package for in-house and ex ternal quality  assurance and evaluation, which \\nwill enable the co mmerci al user to assess and com pare Language Technology pr oducts”. \\n \\nMUC, the Message Understanding Conference s, which have now ceased, was t he pioneer in \\nopening an international platfo rm for sharing researc h on NLP s ystems. In particular, MUC \\nresearchers were involved i n the evaluation of IE s ystems applied to a co mmon task.   The first \\nfive MUCs had focused on analy zing free text, iden tifying events of a specified t ype, and filli ng a \\ndata base te mplate with information about each  such event (MUC- 6, 1996). After MUC-5, a \\nbroad set of o bjectives was defined for t he fort hcom ing MUCs, such as:  to pus h inform ation \\nextraction sy stems towards greater portabilit y to new domains, and to encourage evaluations of \\nsome basic language anal ysis technologi es. In MUC-7 (the last MUC), the m ultilingual NE \\n(nam ed entities) evaluation was run using training and test articles from  comparable dom ains for \\nall languages (Chinchor, n .d.). The pape rs in the MUC-7 conference  report some interestin g \\nobservations by system  developers who were non- native speakers of the langua ge of their s ystem  \\nand sy stem  developers who were native speakers of the language o f their sy stem. Results of \\nMUC-3 throu gh MUC-7 ha ve been summarized by Chinchor (n .d.).  \\n \\n \\nConclusion \\n \\nResults of some NLP experim ents reported in this  paper show encouraging  results. However, one \\nshould not forget that m ost of these experi mental systems end in the lab; ver y few experimental  \\nsystems are converted to re al systems or products. On e of the major stum bling blocks  of NLP \\n 25 resea rch, as i n areas like information retrieval research, has been the absence of la rge test \\ncollections and re-usable experimental methods a nd tools. Fort unately, the situation has chan ged \\nover the past few y ears. Several national and internati onal research groups are now  working \\ntogether to build and re-use large test collections  and experimental tools and tech niques. Since the \\norigin of the Message Understanding Conferences, group research efforts have proliferated wi th \\nthe regular conferences and  workshops, f or exam ple,  the TREC seri es and other conferences \\norganized by  NAACL ( North Americ an Chapter of the Associ ation for Com putational \\nLinguistics), EACL (European ACL), and so on .  These group research efforts help research ers \\nshare their expertise by  building re-usable N LP tools, t est collections, and experimental \\nmethodologie s.  References to som e re-usable N LP tools and coope rative research grou ps hav e \\nbeen made earlier in this pa per (see under the heading Some Theoretical Developments ). \\n \\nSome recent studies on ev aluation also show prom ising results.  Very  small-sc ale evaluation of \\nINFOS suggests that the indexing pattern m ethod, i.e., mapping of the words from  the input text \\ninto the corre ct concepts in th e WordNet abstraction hierarchy , correctly  classifie d 80% of the \\narticles (Mock and Vem uri, 199 7). Som e large-scale experi ments with NLP als o show \\nencouraging r esults. For exam ple, Kwok  et al. (2000 ,1999) report  that their PIRCS sy stem  can \\nperform  the t asks of English-Chinese query  translation with an effectiveness of over 80%. \\nStrzalkowski et al. (TREC-8;199 8) repor t that b y using the algorith m of auto matic expansion of \\nqueries, using  NLP techniques, they obta ined a 37%  improvement of average precision over a \\nbaseline wher e no expansion was used. There are c onflicting results too. For  example, Elworth y \\n(2000) rep orts that the NLP sy stem , using the Micros oft prod uct NLPWin, perfo rmed much \\npoorer in t he TREC-9 test set co mpared with the TREC-8 test set. While tr ying to find out the \\nreasons for this discrepancy, Elworth y (2000) co mments that an important challenge for the \\nfuture work may be looki ng at how t o build a system  that merges definitive, pre-encoded \\nknowledge, a nd ad-hoc docu ments of unknown relia bility.  \\n \\nAs alre ady mentioned earlier (in the sect ion on  Abstracting), Craven’ s study  with TEXNET \\n(Craven, 199 6) shows a limited success (onl y 37%).  Gaizauska s and Wilks m ention that the  \\nperformance l evels of  the common IE syste ms, stand in the range of   50%  for co mbined recall \\nand precision. Such low succes s rate s are not accep table in  large-scale operatio nal inform ation \\nsystems.   \\n \\n 26 Smith (1998)  suggests that there are two possibl e scenarios  for the future relations between \\ncomputers an d hum ans: (1) in the user-friendlin ess scenario, com puters beco me smart enough  to \\ncommunicat e in natural language, and (2) in th e com puter friendliness s cenario humans adapt \\ntheir practices in order to c ommunicate with, and make use of, com puter s. He f urther argues that \\nthe use of com puter-fri endly encoding of natural language texts on the web is sym ptomatic of  a \\nrevolutionar y trend toward the com puterizati on of hum an knowledge .  Petreley  (2000, p.102) \\nraises a very  pertinent que stion about  natural la nguage user interfaces: “will the natural language \\ninterface hav e to wait until voice recognition b ecom es more commonplace?”. This statement \\nappears to be quite legitim ate when we see that  although a large num ber of natural language user \\ninterfaces were built, m ost at the laboratory  level,  and a few at the commer cial level (for details \\nof these see, Haas, 1996; Chowdhur y, 1999b, Chap ters 18-21), na tural language user interfaces \\nare not still very  comm on. The im pediments to pr ogress to the natur al language interfaces lie on \\nseveral planes including   language issues. Zadrozn y et al. (200 0) mention that ex cept for very \\nrestricted domains, we do not know how to compute the meaning of a sentence based on \\nmeanings of its words and its context. Anothe r problem  is caus ed by the lack of precise user \\nmodels. Zadrozny  et al. (2000) m aintain that even assum ing that we can have any piece of \\ninform ation about a person , we do not know how  could we use this knowledge t o make this \\nperson' s inter action with a dialogue s ystem most effective and pleasant. \\n \\nMT invol ves a num ber of  difficult probl ems, mainly  because hu man language i s at times quite \\nambiguous an d full of  special constructions, and excep tions to rules.   Despite that there has been \\na steady  developm ent, and MT resear ch has now reac hed a stage w here the benefits can be \\nenjoyed by people. A number of web search tools, vi z. Altavista, Google, L ycos and AOL offer \\nfree MT facil ities of web inform ation re sources. A num ber of co mpanies also provide MT \\nservices commerci ally. For exam ple, the IBM WebS phere Translation Server for Multiplatforms \\nis a machine translation ser vice available  comme rciall y for translating web documents in a \\nnumber of languages, such as English, French, It alian, Spanish, C hinese, Japanese and Korean.  \\nIn June 2001, Autodesk, a US software company began to offer MT services to its European \\ncusto mers at a cost which is 50% less co mpared to the hum an transl ation services  (Schenker, \\n2001).   Tho ugh  m achine translations are not alway s perfect and do not produce as good \\ntranslations a s hum an trans lators would produ ce, the results, and evidences of interests in \\nimproving t he perform ance level of MT sy stem s, are very enco uraging.  \\n 27 One area of a pplication of NLP that has drawn much resea rch attent ion, but where the results a re \\nyet to reach the general public with an acceptable level of performance, is the  natural language  \\nquestion-answering sy stem . While so me sy stems, as reported in this chapter, produce accept able \\nresults, there are still many failures and surprises.  Results of s ystems reported un der the QA track \\nof TREC (reported under t he heading of  natural langu age interfaces in this paper)  show prom ising \\nresults with some si mple type of natural  langua ge que ries. However,  these sy stems ar e still at  \\nexperi mental stages, and much resear ch is needed  before robust QA sy stems can be built that are \\ncapable of accepting user queries in any form  of natural language and pro ducin g natural lang uage \\nanswers r etrieved form  a num ber of distributed inform ation resources.  Scalabilit y and portabil ity \\nare the main challenges facing natural l anguage  text processing resear ch. Adams (2001) argues \\nthat current NLP sy stem s establish patterns th at are valid for a specific domain and for a \\nparticular tas k only; as soon as the topic, context or the user  changes, entirely  new patterns need \\nto be established. Sparck Jones (1999)  rightly warns t hat advanced NLP techniqu es such as \\nconcept extraction, are too expensive for larg e-scal e NLP applications. The resear ch co mmunity, \\nhowever, is making conti nuous efforts. The reason for not having reliable NLP systems that work \\nat a high level of perform ance with high  degr ee of sophistication may largely b e, not the \\ninefficiency  of the sy stem s or resear chers, but  the complexities and idios yncrasies of hum an \\nbehaviour an d comm unication patterns.  \\n \\nRefe renc es \\nAdam s, K.C. (2001). The Web as a database: New ex traction technologies & content \\nmanagement,  Online ; 25, 27-32 \\nAhonen, H.; Heinonen, O.; Klem ettinen , M. & Verkam o, A.I. (1998). Appl ying data mining \\ntechniques for descriptive phrase extract ion in digital docum ent collections.    IEEE International \\nForum on Re search and Technology. A dvances in Digital Librarie s - ADL'98,   22-24 April 1998,  \\nSanta Barbara, CA.  Los      Alam itos, CA: IEEE Com puter Societ y,  pp. 2-11  \\n \\nAmsler, R.A.(1984).  Machine-readable dictionaries. In: M. E. Will iams, (ed.) Annual  Review of \\nInformation Science and Technology (AR IST: Volum e 19, White Pla ins, NY: Knowledge \\nIndustr y Publications Inc. for the American Society  for Inform ation  Science. pp.161-2 09.  \\nArgam on, S.; Dagan, I. & Kry molowski, Y. (199 8). A memory-based approach to learning \\nshallow natural language p atterns. In 17t h Intern ationa l Conference on Com putational Ling uistics \\n(COLING '98), August 1 0-14, 1 998, Uni versité  de Montréal, Montr éal, Québec, Canada , \\nMontreal: ACL.  pp.  67-7 3. \\nBangalore, S. & Joshi, A.K. (199 9). Su pertagging: an approach to alm ost parsing. Computatio nal \\nLinguistics , 25, 237-265. \\n 28 Barahona, P.& Alfer es, J.J. (Eds.). (1999).  Progress i n Artificial Intelligence. 9th Portuguese \\nConference o n Artificial Intelligence, EPIA'99. Proceedings , 21-2 4 Sept. 1 999    Evora, Port ugal.  \\nBerlin: Springer-Verlag. \\nBarker, K.& Cornacchia, N. (2000).  Using noun phrase heads to extract document ke yphrases In: \\nH.J. Hamilton (Ed.) Advances in Artifici al Intelligenc e. Proceedings of 13th Biennial Conference \\nof the Canadi an Society for Computati onal  Studies of Intelligence, AI 2000 . 14-17 May 20 00,  \\nMontreal,    B erlin: Springe r-Verlag.  pp. 40-52   \\n \\nBenoit, G. (2 001) Data m ining. I n: Cro nin, B. (ed.).  Annual Revi ew of Information Science and \\nTech nology (ARI ST): Volume 36 . Med ford, NJ: Inform ation toda y for ASIS, pp.  \\nBian, Guo-Wei & Chen, Hsin-Hsi (2000). Cross-language inform ation access to multilingual \\ncollections on the Internet . Journal of the American S ociety for Information Scie nce, 51, 2 81-296.  \\nBlack, W.J.; Rinaldi, F. &  McNaught, J. (2000). Natural language processing in Java: \\napplications in education and knowledg e managemen t. Proceedings of the Second International \\nConference o n the Practical Application of Java.  12-14 April 2000,     Manche ster.  Practical \\nApplication Company: Blackpool.     pp. 157-70  \\n \\nBondale, N.; Maloor, P.; V aidyanathan , A.; Sengupta,  S. &  Rao, P. V.S. (1999) . Extraction of \\ninform ation from  open-ended questionna ires usi ng natural language processing techniques.  \\nComputer Science and Info rmatics ,    29,  15-22 . \\n \\nBorgman, C.L. (1997). M ulti-Media, Multi-Cultura l, and Multi- Lingual Digit al Libraries: Or \\nHow Do We Exchange Data In 400  Languages? D-Lib M agazine . [Online ] Avail able \\nhttp://www.dlib.org/dlib/j une97/06borgman.ht ml \\nBreck, E.; Burger, J.; House, D.; Light, M. & Mani, I. (1999) Question answering from  large \\ndocum ent collections.  Question Answering Systems. Papers from the 1999 AAAI Fall \\nSymposium,     5-7 Nov. 1999,     North Falmouth, MA.  Menlo Park, CA:  AAAI Press.  pp. 26-\\n31   \\n \\nCarrick, C. and Watters, C. (199 7). Au tomatic associ ation of news item s. Information Processing \\n& Management , 33, 615-632. \\nCentre for Language Technology ( 2000). EAG LES-ll Inform ation Page:  Evaluation of NLP \\nSystem s . [Online]  Available:  http://w ww.cst.ku.dk/projects/eagl es2.htm l \\nCeric, V. (2000). Advancements and trends in th e World Wide Web search. In: D.  Kalpic & V.H. \\nDobric (Eds.).  Proceedings of the 22nd International Conference o n Information Technology \\nInterfaces,  13-16 June 2000,    P ula, Croatia. SRCE University Com puter Centre, Univ. Zagr eb, \\npp. 2 11-20  \\n \\nChandrasekar , R. & Srinivas, B. (1998). Glean: usi ng syntactic infor mation in docu ment filteri ng. \\nInformation Processing & Management , 34, 623-640 \\nCharniak, E. (1995).  Natural language learni ng. ACM Computing S urveys, 27,  317-33 19. \\n 29 Chen, J.N. & Chang, J.S. ( 1998). Topic al clustering of MRD senses based on inform ation \\nretrieval tech niques. Comp utatio nal Li nguistics , 24, 61-96.  \\nChinchor,  N.  A. Overview of MUC-7/MET-2. [ Online]  Available: \\nhttp://www.itl.nist.gov/iaui /894.02/related_project s/muc/proceedings/ muc_7_pr oceedings/overvie\\nw.htm l \\nChowdhur y, G. G. (1999a) . Tem plate mining f or infor mation extraction from  digital docum ents. \\nLibrary Trends , 48, 182-208.  \\nChowdhur y, G.G. (1999b) . Introductio n to modern in formation retrieval . Londo n: Librar y \\nAssociation Publishing .  \\nChuang, W. & Yang, J. (2000).  E xtracting sente nce seg ments for text summarization: a machine \\nlearning appr oach. In:  Proceedings of the 23rd annual internation al ACM SIGIR \\nconfe rence on Research and  developm ent in info rmation retrie val, ACM, pp. \\n152-159.  \\n \\nCostantino, M . (1999). Natural language  processi ng and expert system techniques for equity derivatives \\ntrading: the IE-Exp ert system . In: D. Kalp ic & V. H.  Dobric (Eds). Proceedings of the 21st International \\nConference on  Information Technology Interfaces, Pula, Cr oatia,  15- 18 June, 1999.  Univ. Za greb , Zagreb, \\nCroatia,    pp. 63-9  \\n  \\nCowie, J. & Lehnert, W. ( 1996).  Infor mation extraction. Commu nications of  the ACM , 39, 80 – \\n91  \\nCraven, T. C. (2000) . Abstracts produced using com puter assistan ce. Journal of the American  \\nSociety for Information Sci ence,  51, 74 5-756  \\nCraven, T.C. (1988).  Text network displ ay editi ng wit h special reference to the production  of  \\ncusto mized a bstracts. Canadian  Journa l of Informati on Science , 13, 59-68. \\nCraven, T.C. (1996). An experi ment in the use of  tools for com puter-assist ed abstracting. In: \\nASIS’ 96: Proceedings of the 59th ASIS Annual Meeting 1 996. Baltim ore, MD, October 21-2 4, \\n1996 . Vol. 3 3, Medford, N J: Information Toda y, pp. 203-2 08.  \\nCraven, T.C. (1993).  A com puter-aided abstracting tool kit. Canadian Journa l of Information \\nScience , 18, 1 9-31. \\nDan-Hee,  Y.; Gomez, P.C. & Song, M.   (2000) . An algorithm  for predicting the  relationship \\nbetween le mmas and corpus size. ETRI Journal,  22,  20-31  \\n \\nDiET: Diagnostoc and Ev aluation Tool s for natu ral language appli cations (1997 ). [Online]  \\nAvailable: http://www.dfki.de/lt/projects/diet-e.htm l \\nDogru, S.&  Slagle, J.R.(1999).  Implementing a semantic lexicon.   In: W. Tepfen hart & W.  Cy re \\n(Eds.) Conceptual Structures: Standards and Prac tices. 7th International Confe rence on \\nConceptual Structures, IC CS'99  Proceedings,  12-15 July 1999,     Blacksburg, VA.    Berlin:  \\nSpringer-Verlag  pp. 154-67  \\n \\n 30 Elworthy, D. (2000). Question answering usi ng a large NLP system . The Ninth Text \\nREtrievalConference (T REC 9)   [Online]  Availa ble: \\nhttp://trec.nist.gov/pubs/tr ec9/papers/m src-qa.pdf \\nEvans, M. (1989). Com puter-readable Dictionaries.  . In: M.E. Willi ams (Ed). An nual Review of \\nInform ation Science and Technolog y (ARIST): Volume 24. Am sterdam , The Netherlands: \\nElsevier Science Publishers B.V. for the Am erican Society  for I nformation Science. 85-117.   \\nFellbaum , C. (ed.) (1998).  WordNet : an electronic le xical databas e. Cambridge , Mass : MIT \\nPress \\nFeldman, S. (1999).  NLP meets the jabberwocky . Online , 23, 62-72.  \\nFernandez, P.M. & Garci a-Serrano, A.M. (200 0). The role of knowledge-based technology in \\nlanguage appl ications developm ent. Expe rt System s with Applications 19, 31- 44  \\nGaizauskas, R. & Wilks, Y. (1998).  Information extraction: be yond docum ent retrieval. Journal \\nof Documentation , 54, 70- 105.  \\nGlasgow, B.; Mandell, A.; Binney, D.; Ghem ri, L. & Fisher, D. (1998). MITA: an inform ation-\\nextraction approach to the analy sis of free -form  text i n life insurance applications.  AI M agazine,    \\n 19,     59-71   \\n  \\nGlobal Reach  (2001) . Global Internet Statis tics (by  language). [ Online] . Availabl e: \\nhttp://www.eurom ktg.co m/globstats/ \\nGoldstein, J.; Kantrowitz, M.; Mittal, V. & Ca rbonell, J.  (1999). S ummarizing text docum ents: \\nsentence s election and eva luation m etrics. In: Proceeding of the 22nd Annual I nternational \\nConference on Resear ch and Development in In form ation Retrieval. ACM, pp. 121-128.  \\nGrefenstette, G. (1999).  The World Wid e Web as a resource for exam ple-based machine \\ntranslation tasks.  Translati ng and the C omputer 21. Proceedings of the Twenty-first International \\nConference o n Translating and t he Computer     10- 11 Nov. 19 99,     Lond on:  As lib/IMI , p p. 12  \\nGrish man, R.  & Kittredge, R. (Eds.) (1986). Analyzing language in restrict ed domains: \\nsublanguage descriptions and processi ng. London: Lawrenc e Erlbaum  Associ ates  \\nHaas, S. W. ( 1996). Natural language pr ocessing: toward large-scal e robust s ystems. In: M.E. \\nWilliam s (Ed.). Annual Review of Infor mation Science and Technology (ARIST): Volum e 31. \\nMedford, NJ: Learned Inform ation Inc. for the Am erican Society  for Inform ation  Science. pp. 83-\\n119.  \\nHayes, P. (1992)  Intellig ent high-volume text processing using sha llow, domain-specific techniques. \\nIn: J acobs, P. S., (ed. ). Text-based intellig ent systems , Hillsda le, NJ, Lawrence Erlbaum, pp. 227-241. \\nHayes,  P. & Weinstein,  S. (1991). Cons true-TIS : a system for c ontent-based inde xing of a database of \\nnews stories. I n: Rapp aport, A. & S mith, R. (eds.), Innova tive ap plications of artificial intellig ence 2, \\nCam bridge, MA , MIT Press, pp. 51-64. \\nHedlund, T.; Pirkola, A. & Jarvelin, K. (2001).  Aspects of Swedish m orpholog y and sem antics \\nfrom  the perspectives of mono- and  cross-language information retrieval. Information Processing \\n& Management , 37, 147-161.  \\nHeng-Hsou Chang; Yau-Hwang Ko & Jang-Pong Hs u (2000).  An  event-driven and ont ology-\\nbased approach for the delivery  and infor mation extraction of e-m ails. Proceedings International \\n 31 Symposium on Multimedia Software Engineering,     11-13 Dec. 2 000,  Taipei, Taiwan.  Los \\nAlam itos, CA: IEEE Com puter Society , pp. 103-9      \\n \\nHerath, S. & Herath, A. (1999). Alg orithm to de termine the subject in flexible w ord order \\nlanguage based machine tr anslations: a case study for  Sinhalese. Communicatio ns of COLIPS, 9,  \\n1-17  \\n \\nIde, N (2000). Cross-ling ual sense determination: can it wo rk? Computers a nd the Human ities,     34,  223-\\n34  \\n \\nIsahara, H.; Ma, Q.; Sornlertla mvanich,  V. & Ta kahashi, N. (200 0). ORCHID: b uilding lingui stic \\nresources in Thai.  Literary & Linguistic Computing, 15,  465-7 8    \\n \\nJelinek, F. (1999). Statistic al Methods fo r Speech Recogniti on (Language, Speech, and \\nCommunication). MIT Pre ss. \\nJeong, K.S.; Mayeng, S.H. ; Lee, J.S.; Choi, K.S.(1 999). Autom atic identification  and back-\\ntransliteration of foreign w ords for inf ormation retrieval. Informati on Processing &  Management , \\n35, 5 23-540. \\nJie Chi Yang & Akahori, K. (2000). A discourse struct ure analy sis of technical Ja panese texts a nd \\nits im plementation on the WWW. Computer Assisted Lan guage Learning,  13, 119-4 1  \\n \\nJin, Song and Dong-Yan,  Zhao (2000). Study  of automatic abstr acting based on corpus and \\nhierarchical d ictionary ,   Journal of Software, 11, 30 8-14  \\n \\nJurafsky , D. & Martin, J.H. (2000).  Speech and language processing: an introduction t o natural \\nlanguage processing, computati onal linguistics and s peech recognition . Upper Saddle River, NJ: \\nPrentice Hall.   \\nKam -Fai Wong; Lum , V.Y.&  Wai-Ip Lam  (1998). Chicon-a Chinese text manipulation language.  \\nSoftware - Practice and Experience, 28,  681-7 01  \\n \\nKazakov, D.; Manandhar, S. &  Erjavec, T. (19 99). Learning word segmentation rules for tag \\nprediction.  I n: S. Dzeroski, S. & P.  Fla ch (Eds.) Inductive Logic Programming. 9th  \\nInternational Workshop, ILP-99 Proceedings,  24-27 June 199 , Bled , Slovenia. B erlin:  Sprin ger-\\nVerlag , pp. 1 52-16 1  \\nKehler, A. (1997). Current  theories of centering fo r pronoun interpretation: a critical evaluation. \\nComputation al Ling uistics , 23, 467-475. \\nKhoo, C.S.G;  Myaeng, S.H  & Oddy, R. N (2001). Usi ng cause-effect relations in text to im prove \\ninform ation retrieval preci sion. Information Processing &  Management , 37, 1 19-145 \\nKim, T.; Si m, C.; Sanghwa, Y. & Jung, H. (1999). Fr om to-CLIR: web-based natural language \\ninterface for cross-language information retrieval. Information Processing &  Management , 35, \\n559-5 86 \\n 32 King, M. (1996). Evaluating natu ral language processing s ystems. Communications of t he ACM , \\n39, 7 3-80  \\nKornai, A. (ed.) (19 99). E xtended Finit e State M odels of  Languag e (Studies in Natural Language \\nProcessing), Ca mbridge  University  Press. \\n \\nKwok, K.L; Grunfeld, L.; Dinstl, N. & Chan, M. (20 00). TREC-9 cross language, web and \\nquestion-answering track experim ents using PIRCS.  The Ninth Te xt REtrieval Conference ( TREC \\n9). [Online]  Available:  http://trec.nist.gov/pubs/trec9/t9_proceedings.htm l \\nKwok, K.L.; Grunfield, L. & Chen, M. (1999).  TREC -8 Ad-hoc, query  filtering t rack experiments \\nusing PIRCS.  The Eighth  text retrieval Conference (TREC-8). [ Online]  Available:  \\nhttp://trec.nist .gov/ pubs/tre c8/papers/queenst8.pdf \\nLange, H. (1993). Speech Synthesis and Speech  Reco gnition: Tom orrow’ s Human-Co mputer \\nInterfaces? In: M.E. Willia ms (Ed.). Annual Review of Information Science and Technology  \\n(ARIST): Vo lume 28. Med ford, NJ: Learned Info rmation Inc. for the A merican S ociety  for \\nInform ation Science. pp.15 3-185 \\nLee, K.H; Ng , M.K.M &  Lu, Q. (1999). Te xt seg mentation for Chinese spell c hecking. Journal \\nof the Americ an Society for Information Science , 50, 7 51-75 9.  \\nLehmam, A. (1999).  Text structuration l eading to an a utomatic summary  system : RAFI. \\nInformation Processing & Management ,  35,  181-191  \\nLehtokangas, R. & Jarveli n, K. (2001). Consiste ncy of textual expression in newspaper artic les: \\nan argument for se mantically base query  expansion. Journal of Doc umentation , 57, 535-548  \\nLewis, D.D. & Sparck Jones, K. (1996). Natura l language processi ng for i nformation retrieval. \\nCommunications of the AC M, 39(1), 9 2 – 101   \\nLiddy , E. (1998). Enhanced text retr ieval using nat ural language pr ocessing. Bulletin of the \\nAmerican Society for Information Scien ce, 24, 14- 16.  \\nLiddy, E.; Diamond, T . & McKenna, M (2000). DR-LINK in TIPSTER  III.  Information Retrieva l,     3,  \\n291-311   \\n \\nLovis, C.; Baud , R.; Rassino ux, A.M.; Michel, P.A .& Sc herter, J.R. (1 998). Medical dictionaries for patient \\nencoding system s: a methodology.  Artificia l Intellig ence in  Medicine,  14, 201—214.  \\n \\nMa, Q.; Kanzaki, K.; Murata, M.; Uti yama, M.; Uchi moto, K. &  I sahara, H. Sel f-organizing \\nsemantic maps of Japanese nouns i n terms of adnom inal constituents. In: S. Herath & A. Herat h, \\n(Eds.) Proceedings of the IEEE-INNS-ENNS Interna tional Joi nt Conference on Neural Networks. \\nIJCNN 2000. Neural Computing: New Challe nges and Perspecti ves for the New Millennium . 24-\\n27 Jul y 2000.     Com o,  Italy.  Los Alam itos, CA: IEEE Com put. Soc , ,     pp. 91-96      \\n \\nMagnini, B.; Not, E.; Stoc k, O. & Strappara va, C. (2000). Natural language processing for \\ntransparent c ommunication between pu blic adm inistration and citizens. Artificial Intelligenc e and \\nLaw,    8, 1-34  \\nMani, I.  &  Maybury, M.T. (199 9). Advances in automatic text summarization . Cam bridge, MA: \\nMIT Press  \\n 33 Manning, C. D. & Schutze, H. (199 9). Foundations of statistical natural language processing . \\nCambridge, MA: MIT Press \\nMarquez, L.; Padro, L. &  Rodriguez, H. (200 0). A machine learning approach t o POS taggin g  \\nMachine Learning ,    39, 59-91  \\nMartinez, P.; de Miguel, A.; Cuadra, D.; Nieto,  C. & Castro, E. (2000).  Data conceptual \\nmodelling through natural l anguage: identification and validation of  relationship cardinalities.   \\nChallenges of  Information Technology Manageme nt in the 21st Ce ntury. 200 0 Information \\nResources Management A ssociation Int ernational C onference,     21-24 Ma y 2000,     Anch orage, \\nAK. Hershey , PA: Idea Group Pu blishing . pp. 500-504  \\n \\nMartinez, P. &  Garci a-Serrano, A. (1998) .   A know ledge-based methodology applied to \\nlinguistic eng ineering .  In:  R.N. Horspool (Ed.)  S ystems Implementation 2 000. IFIP TC2 \\nWG2.4 Work ing Conferen ce on S ystems Im plementa tion 2 000: Languages, Methods and T ools,  \\n   23-2 6 Feb. 1998 ,     Berli n. Lon don: Chapman & Hall  pp. 1 66-179      \\nMcMurchie, L.L (1998) Software speak s user’ s language. Computing Can ada, 24, 19-21. \\nMeyer , J.& Dale, R. (1999). Building hybrid knowledge represent ations from text. In: Edwards, J. \\n(ed.),  Proceedings of the 23r d Austr alasian Computer  Science Confer ence. ACSC 2000, IEEE \\nComput . Soc , Lo s Alamit os, CA , pp. 158 -65 \\n  \\nMihalcea, R. & Moldovan, D.I. (1999). Automatic acquisition of sense tagged corpora.  In:  A.N. \\nKumar & I. Russell (Eds.). Proceedings of the Twelfth Interna tional Florida AI Research Society \\nConference,      3-5 Ma y 1999,  Orlando , FL.   Menlo Park, CA: AAAI Press , pp. 29 3-7      \\nMock, K.J. &  Vem uri, V.R. (1997).  Informati on filtering via hi ll clim bing, wordnet and index \\npatterns. Information Processing & Management , 33, 633- 644. \\nMoens, Marie-Francine &  Uyttendaele, Caro line (199 7), Autom atic text structuring and \\ncategorizatio n as a first ste p in summ arizing legal cas es. Information Processing &  Management , \\n33,  727-7 37 \\nMorin, E. ( 1999). Autom atic acquisition of se mantic relations between terms from  technical \\ncorpora. In:  P. Sandrini(E d.). TKE'99. Terminology and Knowledge Engineering. Proceedings \\nFifth Internat ional Congress on Term inology and Knowledge Engi neering .     Innsbruck, Aust ria , \\n23-27 Au g. 1999.     Vienn a: TermNet   pp. 2 68-78  \\n \\nMUC-6 (1996). [Online ] Available : http:// www.cs. nyu.edu/cs/fa culty /grishm an/muc6.ht ml \\nMULINEX: Multilingual Indexing, Navigation and Editing E xtensions for the World Wide Web. \\n[Online] . Available: http:// mulinex.dfki.de/ \\nNarita, M.&  Ogawa, Y. (2 000). T he use of phrases from  query  texts in inform ation retrieval. \\nSIGIR Forum , 34, 318-20  \\nNatural Language Processi ng Laborator y, Universi ty of Massachusetts. [Online]  Available: \\nhttp://www-nlp.cs.umass. edu/nlplic.html \\nNDLTD: N etworked Digital Library  of Theses and D issertations. [Online ] Avail able:   \\nhttp://www.ndltd.org \\n 34 Nerbonne, J.; Dokter, D. & Sm it, P. (1998). Morphological Processi ng and Com puter-Assist ed \\nLanguage Learning.  Com puter Assisted Lan guage Learning , 11, 543-5 9  \\nOard, D. W. (1997).  Servin g users in m any lang uages: cross-language inform ation retrieval for \\ndigital librari es, D-Lib M agazine.  [Online]  Available:  \\nhttp://www.dlib.org/ dlib/decem ber97/oard/12oard.ht ml \\nOard, D. W & Diekama,  A.R. (1998). Cross-langua ge Inform ation Retrieval.  In: M.E. Willi ams \\n(Ed.). Annual Review of Information Scie nce and Tech nology (ARIS T): Volum e 33. Medford,  NJ: \\nLearned Information Inc. for the American So ciety  for Inform ation  Science. pp. 223-2 56   \\nOgura, K.; Nakaiwa, H.; Matsuo, Y.; Ooy ama, Y. &  Bond, F. ( 2000) T he electronic dictio nary. \\nGoi-Taikei-a Japanese l exicon and its applications. NTT Review, 12, 53- 8   \\nOudet, B. (1997). Multil ingualism  on the Internet. Scientific Ameri can, 276 (3), 77-78. \\nOwei, V. (2000) Natural language quer ying of databases: an information extraction appr oach in \\nthe conceptual query  language. International Jo urnal of Human-Co mputer Studie s, 53,  439-9 2 \\nParis, L.A.H. &  Tibbo, H.R. (1998). Fr eesty le vs. Boolean: a co mparison of par tial and exact \\nmatch retriev al systems. Information Pr ocessing & Management,  34, 175-90 \\nParoubek, P. &  Blasband, M. (199 9). Executive Summary  of a Blueprint for a General \\nInfrastructure for Natural Language Processing Sy stems Evaluation  \\nUsing Sem i-Automatic Quantitative Black B ox Approach in a Multilingual Environm ent.  \\n[Online]  Avai lable:  http://www.li msi.fr/TLP/ELSE/Pream bleXwh yXwhatXrev3.htm  \\nPasero, R. & Sabatier, P. (1998)  Lingui stic Ga mes fo r Language L earning: A Special Use of the \\nILLICO Library . Comp uter Assisted La ngua ge Learning , 11, 561 -85  \\n \\nPede rsen, T . &  Bruce, R . (1998).  Knowle dge lean  word-sense disambiguation.  Proceedings Fifteenth \\nNatio nal Conference on  Artifi cial In tellig ence (AAAI-98). Tenth Con ference on Innovative App licatio ns of \\nArtificial In tellig ence.     26-30 July 199 8, Madison. Men lo Park, CA: WI AAAI Press/MI T Press  pp. 800-\\n5  \\n \\nPerez-Ca rballo, J. &  Strzalkowski,  T. (20 00). Natural langu age info rmation  retrie val: p rogress report. \\nInformation Processi ng & Mana gement , 36, 155-178 \\nPeters, C. & Picchi, E. (1997).  Across Languages, Across Cultures: Issues in \\nMultilingu ality and Dig ital Libr aries,  D-Lib Magazine . [Online] Available: \\nhttp://www.dlib.org/dlib/m ay97/peters/05peters.htm l \\nPetreley , N. ( 2000).  Waiting for innovati ons to hi t the mainstream : What about natural language?  \\nInfoWorld, 22(4), 102 \\nPirkola, A. (2 001). M orphological t ypology of lan guag es for IR. Journal of Docu mentation , 57, \\n330-3 48  \\nPoesio, M. & Vieira, R. (1998). A corpus-based investigation of definite description use. \\nComputation al Ling uistics , 24, 183-216 \\n 35 Powell, J. &  Fox, E.A. (1998). Multilin gual federated searching across heterogeneous \\ncollections. D-Lib M agazin e. [Online]  Available: \\nhttp://www.dlib.org/ dlib/septem ber98/powell/09pow ell.htm l \\nQin, J. & Norton, M.J. (E ds.) (1999).  Introduction . Special Issue:  Knowledge discovery  in \\nbibliographic databases. Library Trends , 48, 1-8.  \\nRaghavan, V.V.; Deogun, J .S.; & Server, H. (Eds .) (19 98). Special t opical issue: Knowledge \\ndiscovery  and data mining. Journal of the American S ociety for Information Scie nce, 49(5). \\nRoche,  E. and Shabes, Y. (eds.) (1997). Fi nite-State  Language Pr ocessing (Language, Speech \\nand Comm unication),  MIT Press. \\n \\n \\nRosenfield, R. (2000). Two decades of st atisti cal language modeling: where do we go from  here? \\nProceedings of the IEEE. 88, 8, 1270-8. \\n \\nRoux, M.&  Ledoray , V. (2000)  Unders tanding of m edico-technical reports.  Artificial \\nIntelligence in Medicine,  18, 14 9-72  \\n \\nRuiz, M.E. &  Srinivasan, P. (1998).  Cr oss-La nguage Inform ation Retrieval: an analy sis of \\nerrors. Proceedings of t he 61st ASIS Annual Meeting , Pittsburgh, P A, October 25-29, pp.153- 65 \\nSay, B (1999). Modeling cue phrases in Turkish: a case study .  In: V. Matousek, V. et al (Eds.). \\nText, Speech and Dial ogue . Second Inter national Workshop, TDS'99 Proceedings , 13-17 Sept.  \\n1999,     Plze n, Czech Rep ublic.  Berlin:   Springer-Verlag  pp. 337-40      \\nScarlett, E.; & Szpakowicz, S (2000) .  The pow er of the TSNLP: lessons fro m a diagnostic \\nevaluation of a broad-coverage pa rser.  I n: H.J. Ha milton (Ed.) Advances in Artificial \\nIntelligence. 13th Biennial Conference of the Ca nadian Society for Computational Studies of \\nIntelligence, AI 2000 Proceedings, 14-17 May 20 00, Montreal. Berlin: Sprin ger-Verlag  pp. 1 38-\\n50  \\n \\nSchenker, J.L. (2001). The gist of translation: how long will it be be fore machines make the web \\nmultilingual? Time , 158, Ju ly 16,  2001, 54.  \\nScott, J. (199 9). E-m ail Managem ent: the key to reg aining contr ol.  Internet Business, De cember \\n1999 ,     60— 65   \\nSilber, H.G.& McCoy , K.F. (2000) Effi cient text summarization using lexical chains   In: H.  \\nLieber man(Ed.).  Proceedings of  IUI 2000 Inter national Conference on Intelligent User \\nInterfaces,   9-12 Jan. 20 00, New Orleans, LA. New York: ACM pp . 252- 5    \\nSmeaton A.F. (1999) . Using NLP or NLP Resources f or Inform ation Retrieval Tasks. In: T. \\nStrzalkowski (Ed.), Natura l Lang uage I nformation R etrieval , Klu wer Academ ic Publishers, 99-\\n111,  \\nSmeaton, A.F. (1997).  Inf ormation retrie val: still butti ng heads with natural language \\nprocessing?  In: M.T. Pazienza (Ed.). Information Ext raction. A Multidisciplinar y Approach t o an \\nEmerging Inf ormation Technolo gy Internation al Summer School, S CIE-97 ,   14-18 Jul y 1997, \\n 36 Frascati, Italy . Berlin: Springer-Verlag pp. 115-38  \\n \\nSmith, D. (19 98). Com puterizing Com puter Science. Communicatio ns of the AC M, 41, 21- 23  \\nSokol, L .; Murphy , K.; Brooks, W.& Mattox, D. (2 000).   Visualizing text-based data mining  \\nProceedings of the Fourth International Confer ence on the Practica l Application of Knowledge \\nDiscovery  and Data Mining, 11- 13 Apri l 200 0, Manc hester.  Black pool: Practical Application \\nCompany,  pp. 57-61  \\nSong Jin &  Zhao Dong-Y an (2000) . Study of automatic abstracting based on corpus and \\nhierarchical d ictionary. Journal of S oftware,11, 30 8-14 \\nSparck Jones, K. (1999) . What is the role for NLP in te xt retrieval. In T. Strzalko wski (Ed.). \\nNatural lan guage inf ormation retrieval . Kluwer, pp. 1—25. \\nStaab, S.; Braun, C.; Brude r, I.; Dusterhoft, A.; Heuer, A.; Klettke, M.; Neu mann, G.; Prager, B.; \\nPretzel, J.; Schnurr, H.-P.; Studer, R.; Uszkoreit, H.& Wrenger, B. (1999) GETE SS-searching the \\nWeb exploiti ng Germ an texts.  Cooperative Information Agents  III. Third International \\nWorkshop, CIA'99 Proceedings,  31 July-2 Aug. 1 999,     Upp sala, Sweden.  Ber lin: Springer-\\nVerlag  pp. 1 13-24  \\n \\nStock, O. (20 00). Natural language proc essing and int elligent interfaces. Annals of M athematics \\nand Artificial  Intelligence ,     28,  39-41  \\nStrzalkowski, T.;  Fang, L;  Perez-C arballo, J. & Jin, W. (1997). Natural La nguage Informati on \\nRetrieval TREC-6 Report ,  NIST Special  Publicatio n500-24 0: The Sixth Text REtrieval \\nConference ( TREC 6).  [Online]  Available: http://tre c.nist.gov/ pubs/trec6/t6_pr oceedings.ht ml \\nStrzalkowski, T.;  Perez-Ca rballo, J.; Karlgren, J. ; Hul th, A.  Tapanainen, P.; & Lahtinen, T.  \\n(1999).  Natur al language i nformation re trieval: TREC -8 report. NIST Special P ublication 500-\\n246:The Ei ghth Text REtrieval Conference (TREC 8)     [Online]  Available: \\nhttp://trec.nist .gov/ pubs/tre c8/papers/ge8adhoc2.pdf \\nStrzalkowski, T.; Stein, G.; Wise, G.B.; Perez-C arballo, J; Tapanainen, P.; Jarvinen, T.; \\nVoutilainen, A. & Karlgren, J. (1998). Natural languagee inform ation retrieval: TREC-7 report. \\nNIST Special Publication 500-242: The Seventh Text REtrieval Conference (TR EC 7) [Online]  \\nAvailable: http://trec.nist.gov/pubs/trec7/t7_proceedings.htm l \\nTolle, K.M. &  Chen, H. (2000).  Com paring no un phrasing techniques  for use with medical \\ndigital librar y tools. Journ al of the American Socie ty for Information Science , 51, 352-3 70.  \\nTrybula, W.J.  (1997) . Data mining and knowledge dis covery . In: M.E. William s (Ed.). Annual \\nReview of Informat ion Science and Technology (ARIST): Volume 32. M edford, NJ: Learned Information \\nInc. for the American S ociety  for Information  Science , pp.197-2 29. \\nTsuda, K.&  Nakam ura, M . (1999). The extraction method of the w ord meaning class. In: L.C. \\nJain, (Ed.)  Third Internati onal Conference on Knowl edge-Based Intelligent Inf ormation \\nEngineering Systems.  31 Aug.-1 Sept. 1999, Adelaide, SA, Australia.  Piscataway , NJ:     I EEE , \\npp. 5 34-7   \\n \\n 37  38Twenty-One: development of a multimedia information dissemination and transaction tool. \\n[Online] Available:   http://twentyone.tpd.tno.nl/twentyone/ \\nVickery, B. (1997). Knowledge discovery from databases: an introductory review. Journal of \\nDocumentation , 53, 107-122. \\nVoorhees, E. (1999). The TREC-8 question answering track report. [Online] Available: http://trec.nist.gov/pubs/trec8/papers/qa-report.pdf \\nVoorhees, E. (2000). The TREC-9 question answering track report. [Online] Available: http://trec.nist.gov/pubs/trec9/papers/qa-report.pdf \\nWaldrop, M.M (2001). Natural language processing, Technology Review , 104, 107-108 \\nWarner, A. J. (1987). Natural language processi ng. In: Williams, Martha E. ed. Annual Review of \\nInformation Science and Technology (ARIST): Volume 22. Amsterdam, The Netherlands: Elsevier Science \\nPublishers B.V. for the American Society for Information Science, 79-108. \\nWeigard, H.& Hoppenbrouwers, S. (1998). Experiences with a multilingual ontology-based \\nlexicon for news filtering. In: A.M. Tjoa & R.R.  Wagner (Eds.). Proceedings Ninth International \\nWorkshop on Database and Expert Systems Applications,  26-28 Aug. 1998, Vienna. Los \\nAlamitos, CA: IEEE Computer Society  pp. 160-5   \\nWilks, Y. (1996). Natural language processing, Communications of the ACM , 39, 60 \\nYang, Y. & Liu, X (1999). A re-examination of text categorization methods. In: SIGIR ’99 Proceedings of the 22\\nnd Annual International ACM SIGIR Conference on Research and \\nDevelopment in Information Retrieval. ACM, pp. 42-49. \\nZadrozny, W.; Budzikowska, M.; Chai, J.& Kambha tla, N. (2000).  Natural language dialogue for \\npersonalized interaction. Communications of the ACM, 43, 116-120.  \\n \\nZweigenbaum, P.& Grabar, N. (1999) Automa tic acquisition of morphological knowledge for \\nmedical language processing.  In: W. Horn, et al (Eds.). Artificial Intelligence in Medicine. Joint \\nEuropean Conference on Artificial Intelligence in Medicine and Medical Decision Making, \\nAIMDM'99  Proceedings, 20-24 June 1999, Aalborg, Denmark.  Berlin: Springer-Verlag  pp. \\n416-20  \\n \\n \\n \"],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'title': '내논문'}, {'title': 'NLP'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get()    # 저장된 전체 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d86ada9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "results = collection.get(\n",
    "    include=['embeddings', 'documents', 'metadatas']\n",
    ")\n",
    "\n",
    "for emb in results['embeddings']:\n",
    "    print(len(emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf793b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLP'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text = 'Natural Language'\n",
    "query_embedding = model.encode(query_text).tolist()\n",
    "results = collection.query(query_embeddings=[query_embedding], n_results=1)\n",
    "\n",
    "results['metadatas'][0][0]['title']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
